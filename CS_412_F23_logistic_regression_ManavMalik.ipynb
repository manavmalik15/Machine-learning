{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "va6zv-gKhIu8"
      },
      "source": [
        "Name: Manav Malik"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "tuaYthb0hXnU"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QZj93Jcmh8pV"
      },
      "source": [
        "Submission:\n",
        "\n",
        "1- Run all cells (this is important, the results will remain there for us to look)\n",
        "\n",
        "2- Download .ipynb\n",
        "\n",
        "3- Submit your .ipynb on Gradescope\n",
        "\n",
        "4- Double check your submitted file to make sure the submission is correct and it shows all the cell outputs\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jkGXbH9kiQEK",
        "outputId": "9feba335-8987-4923-88da-980bcd6fdab4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "#Mounting Google Drive:\n",
        "#After running this cell a popup window will appear and requesting to select your  Google account and give the access permission.\n",
        "#You can either use your personal Google account or your UIC Google account.\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "K5ljlocpiRxq"
      },
      "outputs": [],
      "source": [
        "#You need to change this path\n",
        "path=\"/content/gdrive/MyDrive/CS412project2/\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "qB86CgDBhIu9"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib import style\n",
        "style.use('ggplot')\n",
        "%matplotlib inline\n",
        "import re\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QhFQTtLWhIu-"
      },
      "source": [
        "Numpy is library for scientific computing in Python. It has efficient implementation of n-dimensional array (tensor) manupulations, which is useful for machine learning applications."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "RZceSJk8hIu-"
      },
      "outputs": [],
      "source": [
        "import numpy as np"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MLJ1LE0RhIu_"
      },
      "source": [
        "We can convert a list into numpy array (tensor)  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UIBuEViJhIu_",
        "outputId": "4ff742f2-8d0e-4206-91c0-69bae233c739"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1, 2, 4],\n",
              "       [2, 6, 9]])"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ],
      "source": [
        "b = [[1, 2, 4], [2, 6, 9]]\n",
        "a = np.array(b)\n",
        "a"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YpaBPUPEhIu_"
      },
      "source": [
        "We can check the dimensions of the array"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fUrF-jvPhIu_",
        "outputId": "8abf93ab-6e2c-4789-ed4c-026a018eb45a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2, 3)"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ],
      "source": [
        "a.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UjUJI4vRhIu_"
      },
      "source": [
        "We can apply simple arithmetic operation on all element of a tensor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VlQlxcGzhIu_",
        "outputId": "faec9757-d4c1-4d06-c568-797841a0740b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 3,  6, 12],\n",
              "       [ 6, 18, 27]])"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ],
      "source": [
        "a * 3"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MHyhHZbghIvA"
      },
      "source": [
        "You can transpose a tensor\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "88ItMKO8hIvA",
        "outputId": "9768db5f-1f9e-43ea-eb28-341c3f45eb3d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(3, 2)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1, 2],\n",
              "       [2, 6],\n",
              "       [4, 9]])"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ],
      "source": [
        "print(a.T.shape)\n",
        "a.T"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x5TsmIfZhIvA"
      },
      "source": [
        "You can apply aggregate functions on the whole tensor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0rHaLkUMhIvA",
        "outputId": "473d31e9-7b8a-4322-ac4a-c73582a9a878"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "24"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ],
      "source": [
        "np.sum(a)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xYoIqupihIvA"
      },
      "source": [
        "or on one dimension of it"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2t74tXHOhIvA",
        "outputId": "2bc76011-4edd-4183-f4a4-1c13684ce011"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 3,  8, 13])"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ],
      "source": [
        "np.sum(a, axis=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9pLDwLh8hIvA",
        "outputId": "87f3075b-8f3b-4c99-fe93-1b5da6176097"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 7, 17])"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ],
      "source": [
        "np.sum(a, axis=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1gQUIziphIvA"
      },
      "source": [
        "We can do element-wise arithmetic operation on two tensors (of the same size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hLcwq4nZhIvA",
        "outputId": "11979455-3313-4c86-a3f5-06df9fdea56d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 2,  6, 20],\n",
              "       [ 2, 12,  9]])"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ],
      "source": [
        "c1 = np.array([[1, 2, 4], [2, 6, 9]])\n",
        "c2 = np.array([[2, 3, 5], [1, 2, 1]])\n",
        "c1 * c2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nTbsvWJxhIvA"
      },
      "source": [
        "If you want to multiply all columns of a tensor by vector (for example if you want to multiply all data features by their lables) you need a trick. This multiplication shows up in calculating the gradients."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VDEbp8nzhIvB",
        "outputId": "b193e3c5-2166-46ba-9838-6ce642b2bd0b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[1 2 4]\n",
            " [2 6 9]]\n",
            "[ 1 -1]\n"
          ]
        }
      ],
      "source": [
        "a = np.array([[1, 2, 4], [2, 6, 9]])\n",
        "b = np.array([1,-1])\n",
        "print(a)\n",
        "print(b)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YHqynmerhIvB"
      },
      "source": [
        "Here we want to multiply the first row of a by 1 and the second row of a by -1. Simply multiplying a by b does not work because a and b do not have the same dimension"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "id": "uMALphCUhIvB"
      },
      "outputs": [],
      "source": [
        "#a * b"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_qkH4wCRhIvB"
      },
      "source": [
        "To do this multiplication we first have to assume b has one column and then repeat the column of b with the number of columns in a. We use tile function to do that"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BK6SI4OqhIvB",
        "outputId": "8250fc92-7d9f-4616-f2c5-6f4cfb2c42f4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(2, 3)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 1,  1,  1],\n",
              "       [-1, -1, -1]])"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ],
      "source": [
        "b_repeat = np.tile(b,  (a.shape[1],1)).T\n",
        "print(b_repeat.shape)\n",
        "b_repeat"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-37pUmo_hIvB"
      },
      "source": [
        "Now we can multiply each column of a by b:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dj57Pxv1hIvB",
        "outputId": "a330bb45-d5ff-4a8c-9a85-304d875ef3c9"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 1,  2,  4],\n",
              "       [-2, -6, -9]])"
            ]
          },
          "metadata": {},
          "execution_count": 53
        }
      ],
      "source": [
        "a * b_repeat"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "njjOZYvHhIvB"
      },
      "source": [
        "You can create inital random vector using numpy (using N(0,1)):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "id": "x8O7pRx5hIvB"
      },
      "outputs": [],
      "source": [
        "mu = 0 #mean\n",
        "sigma = 1 #standard deviation\n",
        "r = np.random.normal(mu,sigma, 1000) #draws 1000 samples from a normal distribution"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f6kyKWMnhIvB"
      },
      "source": [
        "We can apply functions on tensors"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "id": "13oMFM34hIvC"
      },
      "outputs": [],
      "source": [
        "#implementation of Normal distribution\n",
        "def normal(x, mu, sigma):\n",
        "    return np.exp( -0.5 * ((x-mu)/sigma)**2)/np.sqrt(2.0*np.pi*sigma**2)\n",
        "\n",
        "#probability of samples on the Normal distribution\n",
        "probabilities = normal(r, mu, sigma)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hby6OxM2hIvC"
      },
      "source": [
        "Numpy has useful APIs for analysis. Here we plot the histogram of samples and also plot the probabilies to see if the samples follow the normal distribution."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 447
        },
        "id": "Ort_wanOhIvC",
        "outputId": "0587916d-1781-4362-b741-2df3bed751c8"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.collections.PathCollection at 0x7c39172c9090>"
            ]
          },
          "metadata": {},
          "execution_count": 56
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "counts, bins = np.histogram(r,50,density=True)\n",
        "plt.hist(bins[:-1], bins, weights=counts)\n",
        "plt.scatter(r, probabilities, c='b', marker='.')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "id": "1ixKIArxhIvC"
      },
      "outputs": [],
      "source": [
        "def read_data(filename):\n",
        "    f = open(filename, 'r')\n",
        "    p = re.compile(',')\n",
        "    xdata = []\n",
        "    ydata = []\n",
        "    header = f.readline().strip()\n",
        "    varnames = p.split(header)\n",
        "    namehash = {}\n",
        "    for l in f:\n",
        "        li = p.split(l.strip())\n",
        "        xdata.append([float(x) for x in li[:-1]])\n",
        "        ydata.append(float(li[-1]))\n",
        "\n",
        "    return np.array(xdata), np.array(ydata)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ES-3FSlmhIvC"
      },
      "source": [
        "**Assuming** our data is x is available in numpy we use numpy to implement logistic regression\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "id": "SN454nr0hIvC"
      },
      "outputs": [],
      "source": [
        "(xtrain_whole, ytrain_whole) = read_data(path + 'spambase-train.csv')\n",
        "(xtest, ytest) = read_data(path + 'spambase-test.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ciUpv-cGhIvC",
        "outputId": "a5937faa-108d-4d60-d52e-5014727070fa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The shape of xtrain: (3601, 54)\n",
            "The shape of ytrain: (3601,)\n",
            "The shape of xtest: (1000, 54)\n",
            "The shape of ytest: (1000,)\n"
          ]
        }
      ],
      "source": [
        "print(\"The shape of xtrain:\", xtrain_whole.shape)\n",
        "print(\"The shape of ytrain:\", ytrain_whole.shape)\n",
        "print(\"The shape of xtest:\", xtest.shape)\n",
        "print(\"The shape of ytest:\", ytest.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QW3mxkkahIvC"
      },
      "source": [
        "before training we normalize the input data (features)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "id": "whv7x-gthIvD"
      },
      "outputs": [],
      "source": [
        "xmean = np.mean(xtrain_whole, axis=0)\n",
        "xstd = np.std(xtrain_whole, axis=0)\n",
        "xtrain_normal_whole = (xtrain_whole-xmean) / xstd\n",
        "xtest_normal = (xtest-xmean) / xstd"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wu6SLWKFhIvD"
      },
      "source": [
        "We need to create a validation set. We create an array of indecies and permute it."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "id": "QcTRxtqohIvD"
      },
      "outputs": [],
      "source": [
        "premute_indicies = np.random.permutation(np.arange(xtrain_whole.shape[0]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rols6OsxhIvD"
      },
      "source": [
        "We keep the first 2600 data points as the training data and rest as the validation data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "id": "DP87ZxqhhIvD"
      },
      "outputs": [],
      "source": [
        "xtrain_normal = xtrain_normal_whole[premute_indicies[:2600]]\n",
        "ytrain = ytrain_whole[premute_indicies[:2600]]\n",
        "xval_normal = xtrain_normal_whole[premute_indicies[2600:]]\n",
        "yval = ytrain_whole[premute_indicies[2600:]]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OcY4MTtKhIvD"
      },
      "source": [
        "Initiallizing the weights and bias with random values from N(0,1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {
        "id": "GSZd1VgGhIvD"
      },
      "outputs": [],
      "source": [
        "weights = np.random.normal(0, 1, xtrain_normal.shape[1]);\n",
        "bias = np.random.normal(0,1,1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {
        "id": "2wT420TChIvD"
      },
      "outputs": [],
      "source": [
        "#the sigmoid function\n",
        "def sigmoid(v):\n",
        "    #return np.exp(-np.logaddexp(0, -v)) #numerically stable implementation of sigmoid function\n",
        "    return 1.0 / (1+np.exp(-v))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oe6TnxiBhIvD"
      },
      "source": [
        "We can use dot-product from numpy to calculate the margin and pass it to the sigmoid function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {
        "id": "YzLLEHfihIvD"
      },
      "outputs": [],
      "source": [
        "#w: weight vector (numpy array of size n)\n",
        "#b: numpy array of size 1\n",
        "#returns p(y=1|x, w, b)\n",
        "def prob(x, w, b):\n",
        "    return sigmoid(np.dot(x,w) + b);"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6HJuk25jhIvD"
      },
      "source": [
        "You can also calculate $l_2$ penalty using linalg library of numpy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TC70IRw9hIvD",
        "outputId": "c206cf8f-ccdd-4ada-d0c5-9e5bbd072cd7"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "6.44147033142516"
            ]
          },
          "metadata": {},
          "execution_count": 66
        }
      ],
      "source": [
        "np.linalg.norm(weights)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bVsllOx5hIvD"
      },
      "source": [
        "$$\\text{Cross Entropy Loss} = -\\frac{1}{|D|}[\\sum_{(y^i,\\mathbf{x}^i)\\in\\mathcal{D}}\n",
        " y^i \\log p(y=1|\\mathbf{x}^i;\\mathbf{w},b)  +  (1-y^i) \\log (1 - p(y=1|\\mathbf{x}^i;\\mathbf{w},b))]+\\frac{\\lambda}{2} \\|\\mathbf{w}\\|^2 $$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {
        "id": "4i4BmNq4z4ZF"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {
        "id": "iI64I76vhIvE"
      },
      "outputs": [],
      "source": [
        "#w: weight vector (numpy array of size n)\n",
        "#x: training data points (only attributes)\n",
        "#y_prob: p(y|x, w, b)\n",
        "#y_true: class variable data\n",
        "#lambda_: l2 penalty coefficient\n",
        "#returns the cross entropy loss\n",
        "def loss(w, x, y_prob, y_true, lambda_):\n",
        "    m = y_true.shape[0]\n",
        "\n",
        "    ce_loss = -np.sum(y_true * np.log(y_prob + 1e-15) + (1 - y_true) * np.log(1 - y_prob + 1e-15)) / m\n",
        "\n",
        "    l2_reg = (lambda_ / 2) * np.sum(w ** 2)\n",
        "\n",
        "    return ce_loss + l2_reg\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {
        "id": "hN3S3kGnhIvE"
      },
      "outputs": [],
      "source": [
        "#x: input variables (data of size m x n with m data point and n features)\n",
        "#w: weight vector (numpy array of size n)\n",
        "#y_prob: p(y|x, w, b)\n",
        "#y_true: class variable data\n",
        "#lambda_: l2 penalty coefficient\n",
        "#returns tuple of gradient w.r.t w and w.r.t to bias\n",
        "\n",
        "def grad_w_b(x, w, y_prob, y_true, lambda_):\n",
        "\n",
        "    m = y_true.shape[0]\n",
        "\n",
        "    grad_w = (np.dot(x.T, (y_prob - y_true)) / m) + (lambda_ * w)\n",
        "\n",
        "    grad_b = np.sum(y_prob - y_true) / m\n",
        "\n",
        "    return (grad_w, grad_b)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {
        "id": "4tGaJCDjhIvE",
        "scrolled": false
      },
      "outputs": [],
      "source": [
        "\n",
        "#lambda_ is the coeffienct of l2 norm penalty\n",
        "#learning_rate is learning rate of gradient descent algorithm\n",
        "#max_iter determines the maximum number of iterations if the gradients descent does not converge.\n",
        "#continue the training while gradient > 0.1 or the number steps is less max_iter\n",
        "\n",
        "#returns model as tuple of (weights,bias)\n",
        "\n",
        "def fit(x, y_true, learning_rate, lambda_, max_iter, verbose=0):\n",
        "    weights = np.random.normal(0, 1, x.shape[1]);\n",
        "    bias = np.random.normal(0,1,1)\n",
        "    # raise NotImplementedError\n",
        "    # #change the condition appropriately\n",
        "    # while True:\n",
        "\n",
        "    #     if verbose: #verbose is used for debugging purposes\n",
        "    #         #print iteration number, loss, l2 norm of gradients, l2 norm of weights\n",
        "    #         pass\n",
        "    # return (weights, bias)\n",
        "\n",
        "    for i in range(max_iter):\n",
        "      y_prob = prob(x, weights, bias)\n",
        "\n",
        "      grad_w, grad_b = grad_w_b(x, weights, y_prob, y_true, lambda_)\n",
        "\n",
        "      grad_norm = np.linalg.norm(grad_w) + abs(grad_b)\n",
        "\n",
        "      # Update weights and bias\n",
        "      weights -= learning_rate * grad_w\n",
        "      bias -= learning_rate * grad_b\n",
        "\n",
        "      if verbose:\n",
        "          loss_value = loss(weights, x, y_prob, y_true, lambda_)\n",
        "          weight_norm = np.linalg.norm(weights)\n",
        "          print(f\"Iteration {i+1}: Loss = {loss_value:.4f}, ||Grad|| = {grad_norm:.4f}, ||W|| = {weight_norm:.4f}\")\n",
        "\n",
        "      # Stop\n",
        "      if grad_norm < 0.1:\n",
        "          break\n",
        "\n",
        "    return weights, bias"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {
        "id": "55TdlFeyhIvE"
      },
      "outputs": [],
      "source": [
        "def accuracy(x, y_true, model):\n",
        "    w, b = model\n",
        "    return np.sum((prob(x, w, b)>0.5).astype(float) == y_true)  / y_true.shape[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "DZlAxkr2hIvE",
        "outputId": "cb2a47b0-26ad-4e43-8c2a-2180c583f751"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iteration 1: Loss = 32.0634, ||Grad|| = 8.0214, ||W|| = 7.8146\n",
            "Iteration 2: Loss = 31.9993, ||Grad|| = 8.0134, ||W|| = 7.8066\n",
            "Iteration 3: Loss = 31.9353, ||Grad|| = 8.0053, ||W|| = 7.7986\n",
            "Iteration 4: Loss = 31.8714, ||Grad|| = 7.9973, ||W|| = 7.7906\n",
            "Iteration 5: Loss = 31.8076, ||Grad|| = 7.9893, ||W|| = 7.7827\n",
            "Iteration 6: Loss = 31.7440, ||Grad|| = 7.9813, ||W|| = 7.7747\n",
            "Iteration 7: Loss = 31.6805, ||Grad|| = 7.9734, ||W|| = 7.7667\n",
            "Iteration 8: Loss = 31.6172, ||Grad|| = 7.9654, ||W|| = 7.7588\n",
            "Iteration 9: Loss = 31.5539, ||Grad|| = 7.9574, ||W|| = 7.7509\n",
            "Iteration 10: Loss = 31.4908, ||Grad|| = 7.9495, ||W|| = 7.7429\n",
            "Iteration 11: Loss = 31.4279, ||Grad|| = 7.9415, ||W|| = 7.7350\n",
            "Iteration 12: Loss = 31.3650, ||Grad|| = 7.9336, ||W|| = 7.7271\n",
            "Iteration 13: Loss = 31.3023, ||Grad|| = 7.9257, ||W|| = 7.7192\n",
            "Iteration 14: Loss = 31.2397, ||Grad|| = 7.9177, ||W|| = 7.7113\n",
            "Iteration 15: Loss = 31.1772, ||Grad|| = 7.9098, ||W|| = 7.7034\n",
            "Iteration 16: Loss = 31.1148, ||Grad|| = 7.9019, ||W|| = 7.6955\n",
            "Iteration 17: Loss = 31.0526, ||Grad|| = 7.8940, ||W|| = 7.6876\n",
            "Iteration 18: Loss = 30.9905, ||Grad|| = 7.8861, ||W|| = 7.6798\n",
            "Iteration 19: Loss = 30.9286, ||Grad|| = 7.8782, ||W|| = 7.6719\n",
            "Iteration 20: Loss = 30.8667, ||Grad|| = 7.8703, ||W|| = 7.6641\n",
            "Iteration 21: Loss = 30.8050, ||Grad|| = 7.8625, ||W|| = 7.6562\n",
            "Iteration 22: Loss = 30.7434, ||Grad|| = 7.8546, ||W|| = 7.6484\n",
            "Iteration 23: Loss = 30.6819, ||Grad|| = 7.8468, ||W|| = 7.6406\n",
            "Iteration 24: Loss = 30.6205, ||Grad|| = 7.8389, ||W|| = 7.6327\n",
            "Iteration 25: Loss = 30.5593, ||Grad|| = 7.8311, ||W|| = 7.6249\n",
            "Iteration 26: Loss = 30.4982, ||Grad|| = 7.8232, ||W|| = 7.6171\n",
            "Iteration 27: Loss = 30.4372, ||Grad|| = 7.8154, ||W|| = 7.6093\n",
            "Iteration 28: Loss = 30.3763, ||Grad|| = 7.8076, ||W|| = 7.6015\n",
            "Iteration 29: Loss = 30.3156, ||Grad|| = 7.7998, ||W|| = 7.5938\n",
            "Iteration 30: Loss = 30.2549, ||Grad|| = 7.7920, ||W|| = 7.5860\n",
            "Iteration 31: Loss = 30.1945, ||Grad|| = 7.7842, ||W|| = 7.5782\n",
            "Iteration 32: Loss = 30.1341, ||Grad|| = 7.7764, ||W|| = 7.5705\n",
            "Iteration 33: Loss = 30.0738, ||Grad|| = 7.7687, ||W|| = 7.5627\n",
            "Iteration 34: Loss = 30.0137, ||Grad|| = 7.7609, ||W|| = 7.5550\n",
            "Iteration 35: Loss = 29.9537, ||Grad|| = 7.7531, ||W|| = 7.5473\n",
            "Iteration 36: Loss = 29.8937, ||Grad|| = 7.7454, ||W|| = 7.5395\n",
            "Iteration 37: Loss = 29.8339, ||Grad|| = 7.7376, ||W|| = 7.5318\n",
            "Iteration 38: Loss = 29.7742, ||Grad|| = 7.7299, ||W|| = 7.5241\n",
            "Iteration 39: Loss = 29.7147, ||Grad|| = 7.7222, ||W|| = 7.5164\n",
            "Iteration 40: Loss = 29.6553, ||Grad|| = 7.7144, ||W|| = 7.5087\n",
            "Iteration 41: Loss = 29.5960, ||Grad|| = 7.7067, ||W|| = 7.5010\n",
            "Iteration 42: Loss = 29.5368, ||Grad|| = 7.6990, ||W|| = 7.4933\n",
            "Iteration 43: Loss = 29.4777, ||Grad|| = 7.6913, ||W|| = 7.4857\n",
            "Iteration 44: Loss = 29.4188, ||Grad|| = 7.6836, ||W|| = 7.4780\n",
            "Iteration 45: Loss = 29.3600, ||Grad|| = 7.6759, ||W|| = 7.4703\n",
            "Iteration 46: Loss = 29.3012, ||Grad|| = 7.6683, ||W|| = 7.4627\n",
            "Iteration 47: Loss = 29.2427, ||Grad|| = 7.6606, ||W|| = 7.4551\n",
            "Iteration 48: Loss = 29.1842, ||Grad|| = 7.6529, ||W|| = 7.4474\n",
            "Iteration 49: Loss = 29.1258, ||Grad|| = 7.6453, ||W|| = 7.4398\n",
            "Iteration 50: Loss = 29.0676, ||Grad|| = 7.6376, ||W|| = 7.4322\n",
            "Iteration 51: Loss = 29.0095, ||Grad|| = 7.6300, ||W|| = 7.4246\n",
            "Iteration 52: Loss = 28.9515, ||Grad|| = 7.6224, ||W|| = 7.4170\n",
            "Iteration 53: Loss = 28.8936, ||Grad|| = 7.6148, ||W|| = 7.4094\n",
            "Iteration 54: Loss = 28.8358, ||Grad|| = 7.6071, ||W|| = 7.4018\n",
            "Iteration 55: Loss = 28.7781, ||Grad|| = 7.5995, ||W|| = 7.3942\n",
            "Iteration 56: Loss = 28.7206, ||Grad|| = 7.5919, ||W|| = 7.3866\n",
            "Iteration 57: Loss = 28.6632, ||Grad|| = 7.5843, ||W|| = 7.3791\n",
            "Iteration 58: Loss = 28.6059, ||Grad|| = 7.5768, ||W|| = 7.3715\n",
            "Iteration 59: Loss = 28.5487, ||Grad|| = 7.5692, ||W|| = 7.3640\n",
            "Iteration 60: Loss = 28.4916, ||Grad|| = 7.5616, ||W|| = 7.3564\n",
            "Iteration 61: Loss = 28.4346, ||Grad|| = 7.5541, ||W|| = 7.3489\n",
            "Iteration 62: Loss = 28.3778, ||Grad|| = 7.5465, ||W|| = 7.3414\n",
            "Iteration 63: Loss = 28.3210, ||Grad|| = 7.5390, ||W|| = 7.3339\n",
            "Iteration 64: Loss = 28.2643, ||Grad|| = 7.5314, ||W|| = 7.3264\n",
            "Iteration 65: Loss = 28.2078, ||Grad|| = 7.5239, ||W|| = 7.3189\n",
            "Iteration 66: Loss = 28.1514, ||Grad|| = 7.5164, ||W|| = 7.3114\n",
            "Iteration 67: Loss = 28.0951, ||Grad|| = 7.5088, ||W|| = 7.3039\n",
            "Iteration 68: Loss = 28.0390, ||Grad|| = 7.5013, ||W|| = 7.2964\n",
            "Iteration 69: Loss = 27.9829, ||Grad|| = 7.4938, ||W|| = 7.2889\n",
            "Iteration 70: Loss = 27.9270, ||Grad|| = 7.4863, ||W|| = 7.2815\n",
            "Iteration 71: Loss = 27.8711, ||Grad|| = 7.4789, ||W|| = 7.2740\n",
            "Iteration 72: Loss = 27.8154, ||Grad|| = 7.4714, ||W|| = 7.2665\n",
            "Iteration 73: Loss = 27.7598, ||Grad|| = 7.4639, ||W|| = 7.2591\n",
            "Iteration 74: Loss = 27.7043, ||Grad|| = 7.4564, ||W|| = 7.2517\n",
            "Iteration 75: Loss = 27.6489, ||Grad|| = 7.4490, ||W|| = 7.2442\n",
            "Iteration 76: Loss = 27.5936, ||Grad|| = 7.4415, ||W|| = 7.2368\n",
            "Iteration 77: Loss = 27.5384, ||Grad|| = 7.4341, ||W|| = 7.2294\n",
            "Iteration 78: Loss = 27.4834, ||Grad|| = 7.4267, ||W|| = 7.2220\n",
            "Iteration 79: Loss = 27.4284, ||Grad|| = 7.4192, ||W|| = 7.2146\n",
            "Iteration 80: Loss = 27.3736, ||Grad|| = 7.4118, ||W|| = 7.2072\n",
            "Iteration 81: Loss = 27.3189, ||Grad|| = 7.4044, ||W|| = 7.1998\n",
            "Iteration 82: Loss = 27.2643, ||Grad|| = 7.3970, ||W|| = 7.1925\n",
            "Iteration 83: Loss = 27.2097, ||Grad|| = 7.3896, ||W|| = 7.1851\n",
            "Iteration 84: Loss = 27.1553, ||Grad|| = 7.3822, ||W|| = 7.1777\n",
            "Iteration 85: Loss = 27.1010, ||Grad|| = 7.3748, ||W|| = 7.1704\n",
            "Iteration 86: Loss = 27.0468, ||Grad|| = 7.3675, ||W|| = 7.1630\n",
            "Iteration 87: Loss = 26.9928, ||Grad|| = 7.3601, ||W|| = 7.1557\n",
            "Iteration 88: Loss = 26.9388, ||Grad|| = 7.3527, ||W|| = 7.1484\n",
            "Iteration 89: Loss = 26.8850, ||Grad|| = 7.3454, ||W|| = 7.1410\n",
            "Iteration 90: Loss = 26.8312, ||Grad|| = 7.3380, ||W|| = 7.1337\n",
            "Iteration 91: Loss = 26.7775, ||Grad|| = 7.3307, ||W|| = 7.1264\n",
            "Iteration 92: Loss = 26.7240, ||Grad|| = 7.3234, ||W|| = 7.1191\n",
            "Iteration 93: Loss = 26.6706, ||Grad|| = 7.3160, ||W|| = 7.1118\n",
            "Iteration 94: Loss = 26.6173, ||Grad|| = 7.3087, ||W|| = 7.1045\n",
            "Iteration 95: Loss = 26.5640, ||Grad|| = 7.3014, ||W|| = 7.0973\n",
            "Iteration 96: Loss = 26.5109, ||Grad|| = 7.2941, ||W|| = 7.0900\n",
            "Iteration 97: Loss = 26.4580, ||Grad|| = 7.2868, ||W|| = 7.0827\n",
            "Iteration 98: Loss = 26.4051, ||Grad|| = 7.2795, ||W|| = 7.0755\n",
            "Iteration 99: Loss = 26.3523, ||Grad|| = 7.2723, ||W|| = 7.0682\n",
            "Iteration 100: Loss = 26.2996, ||Grad|| = 7.2650, ||W|| = 7.0610\n",
            "Iteration 101: Loss = 26.2470, ||Grad|| = 7.2577, ||W|| = 7.0537\n",
            "Iteration 102: Loss = 26.1945, ||Grad|| = 7.2505, ||W|| = 7.0465\n",
            "Iteration 103: Loss = 26.1422, ||Grad|| = 7.2432, ||W|| = 7.0393\n",
            "Iteration 104: Loss = 26.0899, ||Grad|| = 7.2360, ||W|| = 7.0321\n",
            "Iteration 105: Loss = 26.0378, ||Grad|| = 7.2287, ||W|| = 7.0249\n",
            "Iteration 106: Loss = 25.9857, ||Grad|| = 7.2215, ||W|| = 7.0177\n",
            "Iteration 107: Loss = 25.9338, ||Grad|| = 7.2143, ||W|| = 7.0105\n",
            "Iteration 108: Loss = 25.8819, ||Grad|| = 7.2071, ||W|| = 7.0033\n",
            "Iteration 109: Loss = 25.8302, ||Grad|| = 7.1999, ||W|| = 6.9961\n",
            "Iteration 110: Loss = 25.7785, ||Grad|| = 7.1927, ||W|| = 6.9890\n",
            "Iteration 111: Loss = 25.7270, ||Grad|| = 7.1855, ||W|| = 6.9818\n",
            "Iteration 112: Loss = 25.6756, ||Grad|| = 7.1783, ||W|| = 6.9746\n",
            "Iteration 113: Loss = 25.6243, ||Grad|| = 7.1711, ||W|| = 6.9675\n",
            "Iteration 114: Loss = 25.5730, ||Grad|| = 7.1639, ||W|| = 6.9604\n",
            "Iteration 115: Loss = 25.5219, ||Grad|| = 7.1568, ||W|| = 6.9532\n",
            "Iteration 116: Loss = 25.4709, ||Grad|| = 7.1496, ||W|| = 6.9461\n",
            "Iteration 117: Loss = 25.4200, ||Grad|| = 7.1425, ||W|| = 6.9390\n",
            "Iteration 118: Loss = 25.3692, ||Grad|| = 7.1353, ||W|| = 6.9319\n",
            "Iteration 119: Loss = 25.3185, ||Grad|| = 7.1282, ||W|| = 6.9248\n",
            "Iteration 120: Loss = 25.2678, ||Grad|| = 7.1211, ||W|| = 6.9177\n",
            "Iteration 121: Loss = 25.2174, ||Grad|| = 7.1139, ||W|| = 6.9106\n",
            "Iteration 122: Loss = 25.1669, ||Grad|| = 7.1068, ||W|| = 6.9035\n",
            "Iteration 123: Loss = 25.1166, ||Grad|| = 7.0997, ||W|| = 6.8964\n",
            "Iteration 124: Loss = 25.0664, ||Grad|| = 7.0926, ||W|| = 6.8893\n",
            "Iteration 125: Loss = 25.0163, ||Grad|| = 7.0855, ||W|| = 6.8823\n",
            "Iteration 126: Loss = 24.9663, ||Grad|| = 7.0784, ||W|| = 6.8752\n",
            "Iteration 127: Loss = 24.9164, ||Grad|| = 7.0714, ||W|| = 6.8682\n",
            "Iteration 128: Loss = 24.8666, ||Grad|| = 7.0643, ||W|| = 6.8611\n",
            "Iteration 129: Loss = 24.8169, ||Grad|| = 7.0572, ||W|| = 6.8541\n",
            "Iteration 130: Loss = 24.7673, ||Grad|| = 7.0502, ||W|| = 6.8471\n",
            "Iteration 131: Loss = 24.7178, ||Grad|| = 7.0431, ||W|| = 6.8401\n",
            "Iteration 132: Loss = 24.6684, ||Grad|| = 7.0361, ||W|| = 6.8330\n",
            "Iteration 133: Loss = 24.6191, ||Grad|| = 7.0290, ||W|| = 6.8260\n",
            "Iteration 134: Loss = 24.5699, ||Grad|| = 7.0220, ||W|| = 6.8190\n",
            "Iteration 135: Loss = 24.5208, ||Grad|| = 7.0150, ||W|| = 6.8121\n",
            "Iteration 136: Loss = 24.4718, ||Grad|| = 7.0080, ||W|| = 6.8051\n",
            "Iteration 137: Loss = 24.4229, ||Grad|| = 7.0010, ||W|| = 6.7981\n",
            "Iteration 138: Loss = 24.3741, ||Grad|| = 6.9940, ||W|| = 6.7911\n",
            "Iteration 139: Loss = 24.3254, ||Grad|| = 6.9870, ||W|| = 6.7842\n",
            "Iteration 140: Loss = 24.2767, ||Grad|| = 6.9800, ||W|| = 6.7772\n",
            "Iteration 141: Loss = 24.2282, ||Grad|| = 6.9730, ||W|| = 6.7703\n",
            "Iteration 142: Loss = 24.1798, ||Grad|| = 6.9660, ||W|| = 6.7633\n",
            "Iteration 143: Loss = 24.1315, ||Grad|| = 6.9591, ||W|| = 6.7564\n",
            "Iteration 144: Loss = 24.0833, ||Grad|| = 6.9521, ||W|| = 6.7494\n",
            "Iteration 145: Loss = 24.0351, ||Grad|| = 6.9451, ||W|| = 6.7425\n",
            "Iteration 146: Loss = 23.9871, ||Grad|| = 6.9382, ||W|| = 6.7356\n",
            "Iteration 147: Loss = 23.9392, ||Grad|| = 6.9313, ||W|| = 6.7287\n",
            "Iteration 148: Loss = 23.8913, ||Grad|| = 6.9243, ||W|| = 6.7218\n",
            "Iteration 149: Loss = 23.8436, ||Grad|| = 6.9174, ||W|| = 6.7149\n",
            "Iteration 150: Loss = 23.7959, ||Grad|| = 6.9105, ||W|| = 6.7080\n",
            "Iteration 151: Loss = 23.7484, ||Grad|| = 6.9036, ||W|| = 6.7012\n",
            "Iteration 152: Loss = 23.7009, ||Grad|| = 6.8967, ||W|| = 6.6943\n",
            "Iteration 153: Loss = 23.6536, ||Grad|| = 6.8898, ||W|| = 6.6874\n",
            "Iteration 154: Loss = 23.6063, ||Grad|| = 6.8829, ||W|| = 6.6806\n",
            "Iteration 155: Loss = 23.5591, ||Grad|| = 6.8760, ||W|| = 6.6737\n",
            "Iteration 156: Loss = 23.5120, ||Grad|| = 6.8691, ||W|| = 6.6669\n",
            "Iteration 157: Loss = 23.4651, ||Grad|| = 6.8622, ||W|| = 6.6600\n",
            "Iteration 158: Loss = 23.4182, ||Grad|| = 6.8554, ||W|| = 6.6532\n",
            "Iteration 159: Loss = 23.3714, ||Grad|| = 6.8485, ||W|| = 6.6464\n",
            "Iteration 160: Loss = 23.3247, ||Grad|| = 6.8417, ||W|| = 6.6396\n",
            "Iteration 161: Loss = 23.2781, ||Grad|| = 6.8348, ||W|| = 6.6327\n",
            "Iteration 162: Loss = 23.2316, ||Grad|| = 6.8280, ||W|| = 6.6259\n",
            "Iteration 163: Loss = 23.1852, ||Grad|| = 6.8212, ||W|| = 6.6191\n",
            "Iteration 164: Loss = 23.1388, ||Grad|| = 6.8144, ||W|| = 6.6124\n",
            "Iteration 165: Loss = 23.0926, ||Grad|| = 6.8075, ||W|| = 6.6056\n",
            "Iteration 166: Loss = 23.0465, ||Grad|| = 6.8007, ||W|| = 6.5988\n",
            "Iteration 167: Loss = 23.0004, ||Grad|| = 6.7939, ||W|| = 6.5920\n",
            "Iteration 168: Loss = 22.9545, ||Grad|| = 6.7871, ||W|| = 6.5853\n",
            "Iteration 169: Loss = 22.9086, ||Grad|| = 6.7803, ||W|| = 6.5785\n",
            "Iteration 170: Loss = 22.8628, ||Grad|| = 6.7736, ||W|| = 6.5718\n",
            "Iteration 171: Loss = 22.8171, ||Grad|| = 6.7668, ||W|| = 6.5650\n",
            "Iteration 172: Loss = 22.7716, ||Grad|| = 6.7600, ||W|| = 6.5583\n",
            "Iteration 173: Loss = 22.7261, ||Grad|| = 6.7533, ||W|| = 6.5516\n",
            "Iteration 174: Loss = 22.6807, ||Grad|| = 6.7465, ||W|| = 6.5448\n",
            "Iteration 175: Loss = 22.6354, ||Grad|| = 6.7398, ||W|| = 6.5381\n",
            "Iteration 176: Loss = 22.5901, ||Grad|| = 6.7330, ||W|| = 6.5314\n",
            "Iteration 177: Loss = 22.5450, ||Grad|| = 6.7263, ||W|| = 6.5247\n",
            "Iteration 178: Loss = 22.5000, ||Grad|| = 6.7196, ||W|| = 6.5180\n",
            "Iteration 179: Loss = 22.4550, ||Grad|| = 6.7128, ||W|| = 6.5113\n",
            "Iteration 180: Loss = 22.4102, ||Grad|| = 6.7061, ||W|| = 6.5047\n",
            "Iteration 181: Loss = 22.3654, ||Grad|| = 6.6994, ||W|| = 6.4980\n",
            "Iteration 182: Loss = 22.3207, ||Grad|| = 6.6927, ||W|| = 6.4913\n",
            "Iteration 183: Loss = 22.2761, ||Grad|| = 6.6860, ||W|| = 6.4847\n",
            "Iteration 184: Loss = 22.2316, ||Grad|| = 6.6793, ||W|| = 6.4780\n",
            "Iteration 185: Loss = 22.1872, ||Grad|| = 6.6726, ||W|| = 6.4714\n",
            "Iteration 186: Loss = 22.1429, ||Grad|| = 6.6660, ||W|| = 6.4647\n",
            "Iteration 187: Loss = 22.0987, ||Grad|| = 6.6593, ||W|| = 6.4581\n",
            "Iteration 188: Loss = 22.0545, ||Grad|| = 6.6526, ||W|| = 6.4515\n",
            "Iteration 189: Loss = 22.0105, ||Grad|| = 6.6460, ||W|| = 6.4448\n",
            "Iteration 190: Loss = 21.9665, ||Grad|| = 6.6393, ||W|| = 6.4382\n",
            "Iteration 191: Loss = 21.9226, ||Grad|| = 6.6327, ||W|| = 6.4316\n",
            "Iteration 192: Loss = 21.8788, ||Grad|| = 6.6261, ||W|| = 6.4250\n",
            "Iteration 193: Loss = 21.8351, ||Grad|| = 6.6194, ||W|| = 6.4184\n",
            "Iteration 194: Loss = 21.7915, ||Grad|| = 6.6128, ||W|| = 6.4118\n",
            "Iteration 195: Loss = 21.7480, ||Grad|| = 6.6062, ||W|| = 6.4053\n",
            "Iteration 196: Loss = 21.7046, ||Grad|| = 6.5996, ||W|| = 6.3987\n",
            "Iteration 197: Loss = 21.6612, ||Grad|| = 6.5930, ||W|| = 6.3921\n",
            "Iteration 198: Loss = 21.6180, ||Grad|| = 6.5864, ||W|| = 6.3856\n",
            "Iteration 199: Loss = 21.5748, ||Grad|| = 6.5798, ||W|| = 6.3790\n",
            "Iteration 200: Loss = 21.5317, ||Grad|| = 6.5732, ||W|| = 6.3725\n",
            "Iteration 201: Loss = 21.4887, ||Grad|| = 6.5667, ||W|| = 6.3659\n",
            "Iteration 202: Loss = 21.4458, ||Grad|| = 6.5601, ||W|| = 6.3594\n",
            "Iteration 203: Loss = 21.4030, ||Grad|| = 6.5535, ||W|| = 6.3529\n",
            "Iteration 204: Loss = 21.3602, ||Grad|| = 6.5470, ||W|| = 6.3463\n",
            "Iteration 205: Loss = 21.3176, ||Grad|| = 6.5404, ||W|| = 6.3398\n",
            "Iteration 206: Loss = 21.2750, ||Grad|| = 6.5339, ||W|| = 6.3333\n",
            "Iteration 207: Loss = 21.2325, ||Grad|| = 6.5273, ||W|| = 6.3268\n",
            "Iteration 208: Loss = 21.1901, ||Grad|| = 6.5208, ||W|| = 6.3203\n",
            "Iteration 209: Loss = 21.1478, ||Grad|| = 6.5143, ||W|| = 6.3138\n",
            "Iteration 210: Loss = 21.1056, ||Grad|| = 6.5078, ||W|| = 6.3074\n",
            "Iteration 211: Loss = 21.0634, ||Grad|| = 6.5013, ||W|| = 6.3009\n",
            "Iteration 212: Loss = 21.0214, ||Grad|| = 6.4948, ||W|| = 6.2944\n",
            "Iteration 213: Loss = 20.9794, ||Grad|| = 6.4883, ||W|| = 6.2879\n",
            "Iteration 214: Loss = 20.9375, ||Grad|| = 6.4818, ||W|| = 6.2815\n",
            "Iteration 215: Loss = 20.8957, ||Grad|| = 6.4753, ||W|| = 6.2750\n",
            "Iteration 216: Loss = 20.8540, ||Grad|| = 6.4688, ||W|| = 6.2686\n",
            "Iteration 217: Loss = 20.8123, ||Grad|| = 6.4623, ||W|| = 6.2622\n",
            "Iteration 218: Loss = 20.7708, ||Grad|| = 6.4559, ||W|| = 6.2557\n",
            "Iteration 219: Loss = 20.7293, ||Grad|| = 6.4494, ||W|| = 6.2493\n",
            "Iteration 220: Loss = 20.6879, ||Grad|| = 6.4430, ||W|| = 6.2429\n",
            "Iteration 221: Loss = 20.6466, ||Grad|| = 6.4365, ||W|| = 6.2365\n",
            "Iteration 222: Loss = 20.6054, ||Grad|| = 6.4301, ||W|| = 6.2301\n",
            "Iteration 223: Loss = 20.5642, ||Grad|| = 6.4237, ||W|| = 6.2237\n",
            "Iteration 224: Loss = 20.5232, ||Grad|| = 6.4172, ||W|| = 6.2173\n",
            "Iteration 225: Loss = 20.4822, ||Grad|| = 6.4108, ||W|| = 6.2109\n",
            "Iteration 226: Loss = 20.4413, ||Grad|| = 6.4044, ||W|| = 6.2045\n",
            "Iteration 227: Loss = 20.4005, ||Grad|| = 6.3980, ||W|| = 6.1982\n",
            "Iteration 228: Loss = 20.3598, ||Grad|| = 6.3916, ||W|| = 6.1918\n",
            "Iteration 229: Loss = 20.3191, ||Grad|| = 6.3852, ||W|| = 6.1854\n",
            "Iteration 230: Loss = 20.2786, ||Grad|| = 6.3788, ||W|| = 6.1791\n",
            "Iteration 231: Loss = 20.2381, ||Grad|| = 6.3724, ||W|| = 6.1728\n",
            "Iteration 232: Loss = 20.1977, ||Grad|| = 6.3661, ||W|| = 6.1664\n",
            "Iteration 233: Loss = 20.1574, ||Grad|| = 6.3597, ||W|| = 6.1601\n",
            "Iteration 234: Loss = 20.1171, ||Grad|| = 6.3533, ||W|| = 6.1538\n",
            "Iteration 235: Loss = 20.0770, ||Grad|| = 6.3470, ||W|| = 6.1474\n",
            "Iteration 236: Loss = 20.0369, ||Grad|| = 6.3406, ||W|| = 6.1411\n",
            "Iteration 237: Loss = 19.9969, ||Grad|| = 6.3343, ||W|| = 6.1348\n",
            "Iteration 238: Loss = 19.9570, ||Grad|| = 6.3279, ||W|| = 6.1285\n",
            "Iteration 239: Loss = 19.9172, ||Grad|| = 6.3216, ||W|| = 6.1222\n",
            "Iteration 240: Loss = 19.8774, ||Grad|| = 6.3153, ||W|| = 6.1159\n",
            "Iteration 241: Loss = 19.8377, ||Grad|| = 6.3090, ||W|| = 6.1097\n",
            "Iteration 242: Loss = 19.7981, ||Grad|| = 6.3027, ||W|| = 6.1034\n",
            "Iteration 243: Loss = 19.7586, ||Grad|| = 6.2964, ||W|| = 6.0971\n",
            "Iteration 244: Loss = 19.7192, ||Grad|| = 6.2901, ||W|| = 6.0909\n",
            "Iteration 245: Loss = 19.6798, ||Grad|| = 6.2838, ||W|| = 6.0846\n",
            "Iteration 246: Loss = 19.6406, ||Grad|| = 6.2775, ||W|| = 6.0783\n",
            "Iteration 247: Loss = 19.6014, ||Grad|| = 6.2712, ||W|| = 6.0721\n",
            "Iteration 248: Loss = 19.5622, ||Grad|| = 6.2649, ||W|| = 6.0659\n",
            "Iteration 249: Loss = 19.5232, ||Grad|| = 6.2587, ||W|| = 6.0596\n",
            "Iteration 250: Loss = 19.4842, ||Grad|| = 6.2524, ||W|| = 6.0534\n",
            "Iteration 251: Loss = 19.4454, ||Grad|| = 6.2461, ||W|| = 6.0472\n",
            "Iteration 252: Loss = 19.4066, ||Grad|| = 6.2399, ||W|| = 6.0410\n",
            "Iteration 253: Loss = 19.3678, ||Grad|| = 6.2336, ||W|| = 6.0348\n",
            "Iteration 254: Loss = 19.3292, ||Grad|| = 6.2274, ||W|| = 6.0286\n",
            "Iteration 255: Loss = 19.2906, ||Grad|| = 6.2212, ||W|| = 6.0224\n",
            "Iteration 256: Loss = 19.2521, ||Grad|| = 6.2150, ||W|| = 6.0162\n",
            "Iteration 257: Loss = 19.2137, ||Grad|| = 6.2087, ||W|| = 6.0100\n",
            "Iteration 258: Loss = 19.1754, ||Grad|| = 6.2025, ||W|| = 6.0038\n",
            "Iteration 259: Loss = 19.1371, ||Grad|| = 6.1963, ||W|| = 5.9977\n",
            "Iteration 260: Loss = 19.0989, ||Grad|| = 6.1901, ||W|| = 5.9915\n",
            "Iteration 261: Loss = 19.0608, ||Grad|| = 6.1839, ||W|| = 5.9854\n",
            "Iteration 262: Loss = 19.0228, ||Grad|| = 6.1777, ||W|| = 5.9792\n",
            "Iteration 263: Loss = 18.9848, ||Grad|| = 6.1716, ||W|| = 5.9731\n",
            "Iteration 264: Loss = 18.9469, ||Grad|| = 6.1654, ||W|| = 5.9669\n",
            "Iteration 265: Loss = 18.9091, ||Grad|| = 6.1592, ||W|| = 5.9608\n",
            "Iteration 266: Loss = 18.8714, ||Grad|| = 6.1531, ||W|| = 5.9547\n",
            "Iteration 267: Loss = 18.8338, ||Grad|| = 6.1469, ||W|| = 5.9486\n",
            "Iteration 268: Loss = 18.7962, ||Grad|| = 6.1407, ||W|| = 5.9425\n",
            "Iteration 269: Loss = 18.7587, ||Grad|| = 6.1346, ||W|| = 5.9363\n",
            "Iteration 270: Loss = 18.7213, ||Grad|| = 6.1285, ||W|| = 5.9302\n",
            "Iteration 271: Loss = 18.6839, ||Grad|| = 6.1223, ||W|| = 5.9242\n",
            "Iteration 272: Loss = 18.6466, ||Grad|| = 6.1162, ||W|| = 5.9181\n",
            "Iteration 273: Loss = 18.6095, ||Grad|| = 6.1101, ||W|| = 5.9120\n",
            "Iteration 274: Loss = 18.5723, ||Grad|| = 6.1040, ||W|| = 5.9059\n",
            "Iteration 275: Loss = 18.5353, ||Grad|| = 6.0979, ||W|| = 5.8998\n",
            "Iteration 276: Loss = 18.4983, ||Grad|| = 6.0918, ||W|| = 5.8938\n",
            "Iteration 277: Loss = 18.4614, ||Grad|| = 6.0857, ||W|| = 5.8877\n",
            "Iteration 278: Loss = 18.4246, ||Grad|| = 6.0796, ||W|| = 5.8817\n",
            "Iteration 279: Loss = 18.3878, ||Grad|| = 6.0735, ||W|| = 5.8756\n",
            "Iteration 280: Loss = 18.3512, ||Grad|| = 6.0674, ||W|| = 5.8696\n",
            "Iteration 281: Loss = 18.3146, ||Grad|| = 6.0613, ||W|| = 5.8636\n",
            "Iteration 282: Loss = 18.2780, ||Grad|| = 6.0553, ||W|| = 5.8575\n",
            "Iteration 283: Loss = 18.2416, ||Grad|| = 6.0492, ||W|| = 5.8515\n",
            "Iteration 284: Loss = 18.2052, ||Grad|| = 6.0432, ||W|| = 5.8455\n",
            "Iteration 285: Loss = 18.1689, ||Grad|| = 6.0371, ||W|| = 5.8395\n",
            "Iteration 286: Loss = 18.1326, ||Grad|| = 6.0311, ||W|| = 5.8335\n",
            "Iteration 287: Loss = 18.0965, ||Grad|| = 6.0250, ||W|| = 5.8275\n",
            "Iteration 288: Loss = 18.0604, ||Grad|| = 6.0190, ||W|| = 5.8215\n",
            "Iteration 289: Loss = 18.0244, ||Grad|| = 6.0130, ||W|| = 5.8155\n",
            "Iteration 290: Loss = 17.9884, ||Grad|| = 6.0070, ||W|| = 5.8095\n",
            "Iteration 291: Loss = 17.9526, ||Grad|| = 6.0010, ||W|| = 5.8036\n",
            "Iteration 292: Loss = 17.9168, ||Grad|| = 5.9950, ||W|| = 5.7976\n",
            "Iteration 293: Loss = 17.8810, ||Grad|| = 5.9890, ||W|| = 5.7917\n",
            "Iteration 294: Loss = 17.8454, ||Grad|| = 5.9830, ||W|| = 5.7857\n",
            "Iteration 295: Loss = 17.8098, ||Grad|| = 5.9770, ||W|| = 5.7798\n",
            "Iteration 296: Loss = 17.7743, ||Grad|| = 5.9710, ||W|| = 5.7738\n",
            "Iteration 297: Loss = 17.7388, ||Grad|| = 5.9650, ||W|| = 5.7679\n",
            "Iteration 298: Loss = 17.7035, ||Grad|| = 5.9591, ||W|| = 5.7619\n",
            "Iteration 299: Loss = 17.6682, ||Grad|| = 5.9531, ||W|| = 5.7560\n",
            "Iteration 300: Loss = 17.6329, ||Grad|| = 5.9471, ||W|| = 5.7501\n",
            "Iteration 301: Loss = 17.5978, ||Grad|| = 5.9412, ||W|| = 5.7442\n",
            "Iteration 302: Loss = 17.5627, ||Grad|| = 5.9352, ||W|| = 5.7383\n",
            "Iteration 303: Loss = 17.5277, ||Grad|| = 5.9293, ||W|| = 5.7324\n",
            "Iteration 304: Loss = 17.4927, ||Grad|| = 5.9234, ||W|| = 5.7265\n",
            "Iteration 305: Loss = 17.4579, ||Grad|| = 5.9174, ||W|| = 5.7206\n",
            "Iteration 306: Loss = 17.4231, ||Grad|| = 5.9115, ||W|| = 5.7147\n",
            "Iteration 307: Loss = 17.3883, ||Grad|| = 5.9056, ||W|| = 5.7089\n",
            "Iteration 308: Loss = 17.3537, ||Grad|| = 5.8997, ||W|| = 5.7030\n",
            "Iteration 309: Loss = 17.3191, ||Grad|| = 5.8938, ||W|| = 5.6971\n",
            "Iteration 310: Loss = 17.2846, ||Grad|| = 5.8879, ||W|| = 5.6913\n",
            "Iteration 311: Loss = 17.2501, ||Grad|| = 5.8820, ||W|| = 5.6854\n",
            "Iteration 312: Loss = 17.2157, ||Grad|| = 5.8761, ||W|| = 5.6796\n",
            "Iteration 313: Loss = 17.1814, ||Grad|| = 5.8702, ||W|| = 5.6737\n",
            "Iteration 314: Loss = 17.1472, ||Grad|| = 5.8644, ||W|| = 5.6679\n",
            "Iteration 315: Loss = 17.1130, ||Grad|| = 5.8585, ||W|| = 5.6621\n",
            "Iteration 316: Loss = 17.0789, ||Grad|| = 5.8526, ||W|| = 5.6563\n",
            "Iteration 317: Loss = 17.0448, ||Grad|| = 5.8468, ||W|| = 5.6504\n",
            "Iteration 318: Loss = 17.0109, ||Grad|| = 5.8409, ||W|| = 5.6446\n",
            "Iteration 319: Loss = 16.9770, ||Grad|| = 5.8351, ||W|| = 5.6388\n",
            "Iteration 320: Loss = 16.9431, ||Grad|| = 5.8292, ||W|| = 5.6330\n",
            "Iteration 321: Loss = 16.9094, ||Grad|| = 5.8234, ||W|| = 5.6272\n",
            "Iteration 322: Loss = 16.8757, ||Grad|| = 5.8176, ||W|| = 5.6214\n",
            "Iteration 323: Loss = 16.8420, ||Grad|| = 5.8117, ||W|| = 5.6157\n",
            "Iteration 324: Loss = 16.8085, ||Grad|| = 5.8059, ||W|| = 5.6099\n",
            "Iteration 325: Loss = 16.7750, ||Grad|| = 5.8001, ||W|| = 5.6041\n",
            "Iteration 326: Loss = 16.7415, ||Grad|| = 5.7943, ||W|| = 5.5984\n",
            "Iteration 327: Loss = 16.7082, ||Grad|| = 5.7885, ||W|| = 5.5926\n",
            "Iteration 328: Loss = 16.6749, ||Grad|| = 5.7827, ||W|| = 5.5868\n",
            "Iteration 329: Loss = 16.6417, ||Grad|| = 5.7769, ||W|| = 5.5811\n",
            "Iteration 330: Loss = 16.6085, ||Grad|| = 5.7711, ||W|| = 5.5754\n",
            "Iteration 331: Loss = 16.5754, ||Grad|| = 5.7654, ||W|| = 5.5696\n",
            "Iteration 332: Loss = 16.5424, ||Grad|| = 5.7596, ||W|| = 5.5639\n",
            "Iteration 333: Loss = 16.5094, ||Grad|| = 5.7538, ||W|| = 5.5582\n",
            "Iteration 334: Loss = 16.4765, ||Grad|| = 5.7481, ||W|| = 5.5525\n",
            "Iteration 335: Loss = 16.4437, ||Grad|| = 5.7423, ||W|| = 5.5468\n",
            "Iteration 336: Loss = 16.4109, ||Grad|| = 5.7366, ||W|| = 5.5410\n",
            "Iteration 337: Loss = 16.3782, ||Grad|| = 5.7308, ||W|| = 5.5353\n",
            "Iteration 338: Loss = 16.3456, ||Grad|| = 5.7251, ||W|| = 5.5297\n",
            "Iteration 339: Loss = 16.3131, ||Grad|| = 5.7194, ||W|| = 5.5240\n",
            "Iteration 340: Loss = 16.2806, ||Grad|| = 5.7136, ||W|| = 5.5183\n",
            "Iteration 341: Loss = 16.2481, ||Grad|| = 5.7079, ||W|| = 5.5126\n",
            "Iteration 342: Loss = 16.2158, ||Grad|| = 5.7022, ||W|| = 5.5069\n",
            "Iteration 343: Loss = 16.1835, ||Grad|| = 5.6965, ||W|| = 5.5013\n",
            "Iteration 344: Loss = 16.1512, ||Grad|| = 5.6908, ||W|| = 5.4956\n",
            "Iteration 345: Loss = 16.1191, ||Grad|| = 5.6851, ||W|| = 5.4900\n",
            "Iteration 346: Loss = 16.0870, ||Grad|| = 5.6794, ||W|| = 5.4843\n",
            "Iteration 347: Loss = 16.0549, ||Grad|| = 5.6737, ||W|| = 5.4787\n",
            "Iteration 348: Loss = 16.0229, ||Grad|| = 5.6680, ||W|| = 5.4730\n",
            "Iteration 349: Loss = 15.9910, ||Grad|| = 5.6624, ||W|| = 5.4674\n",
            "Iteration 350: Loss = 15.9592, ||Grad|| = 5.6567, ||W|| = 5.4618\n",
            "Iteration 351: Loss = 15.9274, ||Grad|| = 5.6510, ||W|| = 5.4562\n",
            "Iteration 352: Loss = 15.8957, ||Grad|| = 5.6454, ||W|| = 5.4505\n",
            "Iteration 353: Loss = 15.8640, ||Grad|| = 5.6397, ||W|| = 5.4449\n",
            "Iteration 354: Loss = 15.8324, ||Grad|| = 5.6341, ||W|| = 5.4393\n",
            "Iteration 355: Loss = 15.8009, ||Grad|| = 5.6284, ||W|| = 5.4337\n",
            "Iteration 356: Loss = 15.7694, ||Grad|| = 5.6228, ||W|| = 5.4282\n",
            "Iteration 357: Loss = 15.7380, ||Grad|| = 5.6172, ||W|| = 5.4226\n",
            "Iteration 358: Loss = 15.7067, ||Grad|| = 5.6116, ||W|| = 5.4170\n",
            "Iteration 359: Loss = 15.6754, ||Grad|| = 5.6059, ||W|| = 5.4114\n",
            "Iteration 360: Loss = 15.6442, ||Grad|| = 5.6003, ||W|| = 5.4058\n",
            "Iteration 361: Loss = 15.6131, ||Grad|| = 5.5947, ||W|| = 5.4003\n",
            "Iteration 362: Loss = 15.5820, ||Grad|| = 5.5891, ||W|| = 5.3947\n",
            "Iteration 363: Loss = 15.5509, ||Grad|| = 5.5835, ||W|| = 5.3892\n",
            "Iteration 364: Loss = 15.5200, ||Grad|| = 5.5779, ||W|| = 5.3836\n",
            "Iteration 365: Loss = 15.4891, ||Grad|| = 5.5723, ||W|| = 5.3781\n",
            "Iteration 366: Loss = 15.4583, ||Grad|| = 5.5668, ||W|| = 5.3726\n",
            "Iteration 367: Loss = 15.4275, ||Grad|| = 5.5612, ||W|| = 5.3670\n",
            "Iteration 368: Loss = 15.3968, ||Grad|| = 5.5556, ||W|| = 5.3615\n",
            "Iteration 369: Loss = 15.3661, ||Grad|| = 5.5501, ||W|| = 5.3560\n",
            "Iteration 370: Loss = 15.3355, ||Grad|| = 5.5445, ||W|| = 5.3505\n",
            "Iteration 371: Loss = 15.3050, ||Grad|| = 5.5390, ||W|| = 5.3450\n",
            "Iteration 372: Loss = 15.2745, ||Grad|| = 5.5334, ||W|| = 5.3395\n",
            "Iteration 373: Loss = 15.2441, ||Grad|| = 5.5279, ||W|| = 5.3340\n",
            "Iteration 374: Loss = 15.2138, ||Grad|| = 5.5223, ||W|| = 5.3285\n",
            "Iteration 375: Loss = 15.1835, ||Grad|| = 5.5168, ||W|| = 5.3230\n",
            "Iteration 376: Loss = 15.1533, ||Grad|| = 5.5113, ||W|| = 5.3175\n",
            "Iteration 377: Loss = 15.1231, ||Grad|| = 5.5058, ||W|| = 5.3121\n",
            "Iteration 378: Loss = 15.0930, ||Grad|| = 5.5003, ||W|| = 5.3066\n",
            "Iteration 379: Loss = 15.0630, ||Grad|| = 5.4947, ||W|| = 5.3011\n",
            "Iteration 380: Loss = 15.0330, ||Grad|| = 5.4892, ||W|| = 5.2957\n",
            "Iteration 381: Loss = 15.0031, ||Grad|| = 5.4837, ||W|| = 5.2902\n",
            "Iteration 382: Loss = 14.9732, ||Grad|| = 5.4783, ||W|| = 5.2848\n",
            "Iteration 383: Loss = 14.9435, ||Grad|| = 5.4728, ||W|| = 5.2793\n",
            "Iteration 384: Loss = 14.9137, ||Grad|| = 5.4673, ||W|| = 5.2739\n",
            "Iteration 385: Loss = 14.8840, ||Grad|| = 5.4618, ||W|| = 5.2685\n",
            "Iteration 386: Loss = 14.8544, ||Grad|| = 5.4563, ||W|| = 5.2630\n",
            "Iteration 387: Loss = 14.8249, ||Grad|| = 5.4509, ||W|| = 5.2576\n",
            "Iteration 388: Loss = 14.7954, ||Grad|| = 5.4454, ||W|| = 5.2522\n",
            "Iteration 389: Loss = 14.7659, ||Grad|| = 5.4400, ||W|| = 5.2468\n",
            "Iteration 390: Loss = 14.7366, ||Grad|| = 5.4345, ||W|| = 5.2414\n",
            "Iteration 391: Loss = 14.7072, ||Grad|| = 5.4291, ||W|| = 5.2360\n",
            "Iteration 392: Loss = 14.6780, ||Grad|| = 5.4236, ||W|| = 5.2306\n",
            "Iteration 393: Loss = 14.6488, ||Grad|| = 5.4182, ||W|| = 5.2252\n",
            "Iteration 394: Loss = 14.6196, ||Grad|| = 5.4128, ||W|| = 5.2199\n",
            "Iteration 395: Loss = 14.5906, ||Grad|| = 5.4074, ||W|| = 5.2145\n",
            "Iteration 396: Loss = 14.5615, ||Grad|| = 5.4020, ||W|| = 5.2091\n",
            "Iteration 397: Loss = 14.5326, ||Grad|| = 5.3965, ||W|| = 5.2038\n",
            "Iteration 398: Loss = 14.5037, ||Grad|| = 5.3911, ||W|| = 5.1984\n",
            "Iteration 399: Loss = 14.4748, ||Grad|| = 5.3857, ||W|| = 5.1931\n",
            "Iteration 400: Loss = 14.4460, ||Grad|| = 5.3803, ||W|| = 5.1877\n",
            "Iteration 401: Loss = 14.4173, ||Grad|| = 5.3750, ||W|| = 5.1824\n",
            "Iteration 402: Loss = 14.3886, ||Grad|| = 5.3696, ||W|| = 5.1770\n",
            "Iteration 403: Loss = 14.3600, ||Grad|| = 5.3642, ||W|| = 5.1717\n",
            "Iteration 404: Loss = 14.3314, ||Grad|| = 5.3588, ||W|| = 5.1664\n",
            "Iteration 405: Loss = 14.3029, ||Grad|| = 5.3535, ||W|| = 5.1611\n",
            "Iteration 406: Loss = 14.2745, ||Grad|| = 5.3481, ||W|| = 5.1557\n",
            "Iteration 407: Loss = 14.2461, ||Grad|| = 5.3427, ||W|| = 5.1504\n",
            "Iteration 408: Loss = 14.2178, ||Grad|| = 5.3374, ||W|| = 5.1451\n",
            "Iteration 409: Loss = 14.1895, ||Grad|| = 5.3320, ||W|| = 5.1398\n",
            "Iteration 410: Loss = 14.1613, ||Grad|| = 5.3267, ||W|| = 5.1345\n",
            "Iteration 411: Loss = 14.1331, ||Grad|| = 5.3214, ||W|| = 5.1293\n",
            "Iteration 412: Loss = 14.1050, ||Grad|| = 5.3160, ||W|| = 5.1240\n",
            "Iteration 413: Loss = 14.0770, ||Grad|| = 5.3107, ||W|| = 5.1187\n",
            "Iteration 414: Loss = 14.0490, ||Grad|| = 5.3054, ||W|| = 5.1134\n",
            "Iteration 415: Loss = 14.0211, ||Grad|| = 5.3001, ||W|| = 5.1082\n",
            "Iteration 416: Loss = 13.9932, ||Grad|| = 5.2948, ||W|| = 5.1029\n",
            "Iteration 417: Loss = 13.9654, ||Grad|| = 5.2895, ||W|| = 5.0976\n",
            "Iteration 418: Loss = 13.9376, ||Grad|| = 5.2842, ||W|| = 5.0924\n",
            "Iteration 419: Loss = 13.9099, ||Grad|| = 5.2789, ||W|| = 5.0871\n",
            "Iteration 420: Loss = 13.8823, ||Grad|| = 5.2736, ||W|| = 5.0819\n",
            "Iteration 421: Loss = 13.8547, ||Grad|| = 5.2683, ||W|| = 5.0767\n",
            "Iteration 422: Loss = 13.8271, ||Grad|| = 5.2630, ||W|| = 5.0714\n",
            "Iteration 423: Loss = 13.7997, ||Grad|| = 5.2578, ||W|| = 5.0662\n",
            "Iteration 424: Loss = 13.7722, ||Grad|| = 5.2525, ||W|| = 5.0610\n",
            "Iteration 425: Loss = 13.7449, ||Grad|| = 5.2472, ||W|| = 5.0558\n",
            "Iteration 426: Loss = 13.7175, ||Grad|| = 5.2420, ||W|| = 5.0506\n",
            "Iteration 427: Loss = 13.6903, ||Grad|| = 5.2367, ||W|| = 5.0454\n",
            "Iteration 428: Loss = 13.6631, ||Grad|| = 5.2315, ||W|| = 5.0402\n",
            "Iteration 429: Loss = 13.6359, ||Grad|| = 5.2262, ||W|| = 5.0350\n",
            "Iteration 430: Loss = 13.6088, ||Grad|| = 5.2210, ||W|| = 5.0298\n",
            "Iteration 431: Loss = 13.5818, ||Grad|| = 5.2158, ||W|| = 5.0246\n",
            "Iteration 432: Loss = 13.5548, ||Grad|| = 5.2105, ||W|| = 5.0195\n",
            "Iteration 433: Loss = 13.5279, ||Grad|| = 5.2053, ||W|| = 5.0143\n",
            "Iteration 434: Loss = 13.5010, ||Grad|| = 5.2001, ||W|| = 5.0091\n",
            "Iteration 435: Loss = 13.4742, ||Grad|| = 5.1949, ||W|| = 5.0040\n",
            "Iteration 436: Loss = 13.4474, ||Grad|| = 5.1897, ||W|| = 4.9988\n",
            "Iteration 437: Loss = 13.4207, ||Grad|| = 5.1845, ||W|| = 4.9937\n",
            "Iteration 438: Loss = 13.3940, ||Grad|| = 5.1793, ||W|| = 4.9885\n",
            "Iteration 439: Loss = 13.3674, ||Grad|| = 5.1741, ||W|| = 4.9834\n",
            "Iteration 440: Loss = 13.3408, ||Grad|| = 5.1689, ||W|| = 4.9782\n",
            "Iteration 441: Loss = 13.3143, ||Grad|| = 5.1637, ||W|| = 4.9731\n",
            "Iteration 442: Loss = 13.2879, ||Grad|| = 5.1586, ||W|| = 4.9680\n",
            "Iteration 443: Loss = 13.2615, ||Grad|| = 5.1534, ||W|| = 4.9629\n",
            "Iteration 444: Loss = 13.2352, ||Grad|| = 5.1482, ||W|| = 4.9578\n",
            "Iteration 445: Loss = 13.2089, ||Grad|| = 5.1431, ||W|| = 4.9527\n",
            "Iteration 446: Loss = 13.1826, ||Grad|| = 5.1379, ||W|| = 4.9476\n",
            "Iteration 447: Loss = 13.1565, ||Grad|| = 5.1328, ||W|| = 4.9425\n",
            "Iteration 448: Loss = 13.1303, ||Grad|| = 5.1276, ||W|| = 4.9374\n",
            "Iteration 449: Loss = 13.1043, ||Grad|| = 5.1225, ||W|| = 4.9323\n",
            "Iteration 450: Loss = 13.0782, ||Grad|| = 5.1174, ||W|| = 4.9272\n",
            "Iteration 451: Loss = 13.0523, ||Grad|| = 5.1122, ||W|| = 4.9221\n",
            "Iteration 452: Loss = 13.0263, ||Grad|| = 5.1071, ||W|| = 4.9170\n",
            "Iteration 453: Loss = 13.0005, ||Grad|| = 5.1020, ||W|| = 4.9120\n",
            "Iteration 454: Loss = 12.9747, ||Grad|| = 5.0969, ||W|| = 4.9069\n",
            "Iteration 455: Loss = 12.9489, ||Grad|| = 5.0918, ||W|| = 4.9019\n",
            "Iteration 456: Loss = 12.9232, ||Grad|| = 5.0867, ||W|| = 4.8968\n",
            "Iteration 457: Loss = 12.8975, ||Grad|| = 5.0816, ||W|| = 4.8918\n",
            "Iteration 458: Loss = 12.8719, ||Grad|| = 5.0765, ||W|| = 4.8867\n",
            "Iteration 459: Loss = 12.8464, ||Grad|| = 5.0714, ||W|| = 4.8817\n",
            "Iteration 460: Loss = 12.8209, ||Grad|| = 5.0663, ||W|| = 4.8767\n",
            "Iteration 461: Loss = 12.7954, ||Grad|| = 5.0612, ||W|| = 4.8716\n",
            "Iteration 462: Loss = 12.7700, ||Grad|| = 5.0562, ||W|| = 4.8666\n",
            "Iteration 463: Loss = 12.7447, ||Grad|| = 5.0511, ||W|| = 4.8616\n",
            "Iteration 464: Loss = 12.7194, ||Grad|| = 5.0460, ||W|| = 4.8566\n",
            "Iteration 465: Loss = 12.6941, ||Grad|| = 5.0410, ||W|| = 4.8516\n",
            "Iteration 466: Loss = 12.6689, ||Grad|| = 5.0359, ||W|| = 4.8466\n",
            "Iteration 467: Loss = 12.6438, ||Grad|| = 5.0309, ||W|| = 4.8416\n",
            "Iteration 468: Loss = 12.6187, ||Grad|| = 5.0258, ||W|| = 4.8366\n",
            "Iteration 469: Loss = 12.5937, ||Grad|| = 5.0208, ||W|| = 4.8316\n",
            "Iteration 470: Loss = 12.5687, ||Grad|| = 5.0158, ||W|| = 4.8266\n",
            "Iteration 471: Loss = 12.5437, ||Grad|| = 5.0107, ||W|| = 4.8217\n",
            "Iteration 472: Loss = 12.5188, ||Grad|| = 5.0057, ||W|| = 4.8167\n",
            "Iteration 473: Loss = 12.4940, ||Grad|| = 5.0007, ||W|| = 4.8117\n",
            "Iteration 474: Loss = 12.4692, ||Grad|| = 4.9957, ||W|| = 4.8068\n",
            "Iteration 475: Loss = 12.4445, ||Grad|| = 4.9907, ||W|| = 4.8018\n",
            "Iteration 476: Loss = 12.4198, ||Grad|| = 4.9857, ||W|| = 4.7969\n",
            "Iteration 477: Loss = 12.3951, ||Grad|| = 4.9807, ||W|| = 4.7919\n",
            "Iteration 478: Loss = 12.3705, ||Grad|| = 4.9757, ||W|| = 4.7870\n",
            "Iteration 479: Loss = 12.3460, ||Grad|| = 4.9707, ||W|| = 4.7821\n",
            "Iteration 480: Loss = 12.3215, ||Grad|| = 4.9657, ||W|| = 4.7771\n",
            "Iteration 481: Loss = 12.2971, ||Grad|| = 4.9607, ||W|| = 4.7722\n",
            "Iteration 482: Loss = 12.2727, ||Grad|| = 4.9558, ||W|| = 4.7673\n",
            "Iteration 483: Loss = 12.2483, ||Grad|| = 4.9508, ||W|| = 4.7624\n",
            "Iteration 484: Loss = 12.2240, ||Grad|| = 4.9458, ||W|| = 4.7575\n",
            "Iteration 485: Loss = 12.1998, ||Grad|| = 4.9409, ||W|| = 4.7526\n",
            "Iteration 486: Loss = 12.1756, ||Grad|| = 4.9359, ||W|| = 4.7477\n",
            "Iteration 487: Loss = 12.1515, ||Grad|| = 4.9310, ||W|| = 4.7428\n",
            "Iteration 488: Loss = 12.1274, ||Grad|| = 4.9260, ||W|| = 4.7379\n",
            "Iteration 489: Loss = 12.1033, ||Grad|| = 4.9211, ||W|| = 4.7330\n",
            "Iteration 490: Loss = 12.0793, ||Grad|| = 4.9162, ||W|| = 4.7281\n",
            "Iteration 491: Loss = 12.0554, ||Grad|| = 4.9112, ||W|| = 4.7232\n",
            "Iteration 492: Loss = 12.0314, ||Grad|| = 4.9063, ||W|| = 4.7184\n",
            "Iteration 493: Loss = 12.0076, ||Grad|| = 4.9014, ||W|| = 4.7135\n",
            "Iteration 494: Loss = 11.9838, ||Grad|| = 4.8965, ||W|| = 4.7086\n",
            "Iteration 495: Loss = 11.9600, ||Grad|| = 4.8916, ||W|| = 4.7038\n",
            "Iteration 496: Loss = 11.9363, ||Grad|| = 4.8867, ||W|| = 4.6989\n",
            "Iteration 497: Loss = 11.9127, ||Grad|| = 4.8818, ||W|| = 4.6941\n",
            "Iteration 498: Loss = 11.8890, ||Grad|| = 4.8769, ||W|| = 4.6893\n",
            "Iteration 499: Loss = 11.8655, ||Grad|| = 4.8720, ||W|| = 4.6844\n",
            "Iteration 500: Loss = 11.8420, ||Grad|| = 4.8671, ||W|| = 4.6796\n",
            "Iteration 501: Loss = 11.8185, ||Grad|| = 4.8622, ||W|| = 4.6748\n",
            "Iteration 502: Loss = 11.7951, ||Grad|| = 4.8574, ||W|| = 4.6700\n",
            "Iteration 503: Loss = 11.7717, ||Grad|| = 4.8525, ||W|| = 4.6651\n",
            "Iteration 504: Loss = 11.7483, ||Grad|| = 4.8476, ||W|| = 4.6603\n",
            "Iteration 505: Loss = 11.7251, ||Grad|| = 4.8428, ||W|| = 4.6555\n",
            "Iteration 506: Loss = 11.7018, ||Grad|| = 4.8379, ||W|| = 4.6507\n",
            "Iteration 507: Loss = 11.6786, ||Grad|| = 4.8330, ||W|| = 4.6459\n",
            "Iteration 508: Loss = 11.6555, ||Grad|| = 4.8282, ||W|| = 4.6411\n",
            "Iteration 509: Loss = 11.6324, ||Grad|| = 4.8234, ||W|| = 4.6364\n",
            "Iteration 510: Loss = 11.6094, ||Grad|| = 4.8185, ||W|| = 4.6316\n",
            "Iteration 511: Loss = 11.5864, ||Grad|| = 4.8137, ||W|| = 4.6268\n",
            "Iteration 512: Loss = 11.5634, ||Grad|| = 4.8089, ||W|| = 4.6220\n",
            "Iteration 513: Loss = 11.5405, ||Grad|| = 4.8040, ||W|| = 4.6173\n",
            "Iteration 514: Loss = 11.5176, ||Grad|| = 4.7992, ||W|| = 4.6125\n",
            "Iteration 515: Loss = 11.4948, ||Grad|| = 4.7944, ||W|| = 4.6077\n",
            "Iteration 516: Loss = 11.4720, ||Grad|| = 4.7896, ||W|| = 4.6030\n",
            "Iteration 517: Loss = 11.4493, ||Grad|| = 4.7848, ||W|| = 4.5982\n",
            "Iteration 518: Loss = 11.4266, ||Grad|| = 4.7800, ||W|| = 4.5935\n",
            "Iteration 519: Loss = 11.4040, ||Grad|| = 4.7752, ||W|| = 4.5888\n",
            "Iteration 520: Loss = 11.3814, ||Grad|| = 4.7704, ||W|| = 4.5840\n",
            "Iteration 521: Loss = 11.3589, ||Grad|| = 4.7656, ||W|| = 4.5793\n",
            "Iteration 522: Loss = 11.3364, ||Grad|| = 4.7609, ||W|| = 4.5746\n",
            "Iteration 523: Loss = 11.3139, ||Grad|| = 4.7561, ||W|| = 4.5699\n",
            "Iteration 524: Loss = 11.2915, ||Grad|| = 4.7513, ||W|| = 4.5652\n",
            "Iteration 525: Loss = 11.2692, ||Grad|| = 4.7465, ||W|| = 4.5604\n",
            "Iteration 526: Loss = 11.2469, ||Grad|| = 4.7418, ||W|| = 4.5557\n",
            "Iteration 527: Loss = 11.2246, ||Grad|| = 4.7370, ||W|| = 4.5510\n",
            "Iteration 528: Loss = 11.2024, ||Grad|| = 4.7323, ||W|| = 4.5464\n",
            "Iteration 529: Loss = 11.1802, ||Grad|| = 4.7275, ||W|| = 4.5417\n",
            "Iteration 530: Loss = 11.1581, ||Grad|| = 4.7228, ||W|| = 4.5370\n",
            "Iteration 531: Loss = 11.1360, ||Grad|| = 4.7180, ||W|| = 4.5323\n",
            "Iteration 532: Loss = 11.1139, ||Grad|| = 4.7133, ||W|| = 4.5276\n",
            "Iteration 533: Loss = 11.0919, ||Grad|| = 4.7086, ||W|| = 4.5230\n",
            "Iteration 534: Loss = 11.0700, ||Grad|| = 4.7039, ||W|| = 4.5183\n",
            "Iteration 535: Loss = 11.0481, ||Grad|| = 4.6991, ||W|| = 4.5136\n",
            "Iteration 536: Loss = 11.0262, ||Grad|| = 4.6944, ||W|| = 4.5090\n",
            "Iteration 537: Loss = 11.0044, ||Grad|| = 4.6897, ||W|| = 4.5043\n",
            "Iteration 538: Loss = 10.9826, ||Grad|| = 4.6850, ||W|| = 4.4997\n",
            "Iteration 539: Loss = 10.9609, ||Grad|| = 4.6803, ||W|| = 4.4950\n",
            "Iteration 540: Loss = 10.9392, ||Grad|| = 4.6756, ||W|| = 4.4904\n",
            "Iteration 541: Loss = 10.9175, ||Grad|| = 4.6709, ||W|| = 4.4858\n",
            "Iteration 542: Loss = 10.8959, ||Grad|| = 4.6662, ||W|| = 4.4811\n",
            "Iteration 543: Loss = 10.8744, ||Grad|| = 4.6616, ||W|| = 4.4765\n",
            "Iteration 544: Loss = 10.8529, ||Grad|| = 4.6569, ||W|| = 4.4719\n",
            "Iteration 545: Loss = 10.8314, ||Grad|| = 4.6522, ||W|| = 4.4673\n",
            "Iteration 546: Loss = 10.8100, ||Grad|| = 4.6475, ||W|| = 4.4627\n",
            "Iteration 547: Loss = 10.7886, ||Grad|| = 4.6429, ||W|| = 4.4581\n",
            "Iteration 548: Loss = 10.7672, ||Grad|| = 4.6382, ||W|| = 4.4535\n",
            "Iteration 549: Loss = 10.7459, ||Grad|| = 4.6336, ||W|| = 4.4489\n",
            "Iteration 550: Loss = 10.7247, ||Grad|| = 4.6289, ||W|| = 4.4443\n",
            "Iteration 551: Loss = 10.7035, ||Grad|| = 4.6243, ||W|| = 4.4397\n",
            "Iteration 552: Loss = 10.6823, ||Grad|| = 4.6196, ||W|| = 4.4351\n",
            "Iteration 553: Loss = 10.6612, ||Grad|| = 4.6150, ||W|| = 4.4306\n",
            "Iteration 554: Loss = 10.6401, ||Grad|| = 4.6104, ||W|| = 4.4260\n",
            "Iteration 555: Loss = 10.6191, ||Grad|| = 4.6057, ||W|| = 4.4214\n",
            "Iteration 556: Loss = 10.5981, ||Grad|| = 4.6011, ||W|| = 4.4169\n",
            "Iteration 557: Loss = 10.5771, ||Grad|| = 4.5965, ||W|| = 4.4123\n",
            "Iteration 558: Loss = 10.5562, ||Grad|| = 4.5919, ||W|| = 4.4078\n",
            "Iteration 559: Loss = 10.5353, ||Grad|| = 4.5873, ||W|| = 4.4032\n",
            "Iteration 560: Loss = 10.5145, ||Grad|| = 4.5827, ||W|| = 4.3987\n",
            "Iteration 561: Loss = 10.4937, ||Grad|| = 4.5781, ||W|| = 4.3941\n",
            "Iteration 562: Loss = 10.4730, ||Grad|| = 4.5735, ||W|| = 4.3896\n",
            "Iteration 563: Loss = 10.4523, ||Grad|| = 4.5689, ||W|| = 4.3851\n",
            "Iteration 564: Loss = 10.4316, ||Grad|| = 4.5643, ||W|| = 4.3805\n",
            "Iteration 565: Loss = 10.4110, ||Grad|| = 4.5597, ||W|| = 4.3760\n",
            "Iteration 566: Loss = 10.3904, ||Grad|| = 4.5552, ||W|| = 4.3715\n",
            "Iteration 567: Loss = 10.3699, ||Grad|| = 4.5506, ||W|| = 4.3670\n",
            "Iteration 568: Loss = 10.3494, ||Grad|| = 4.5460, ||W|| = 4.3625\n",
            "Iteration 569: Loss = 10.3289, ||Grad|| = 4.5415, ||W|| = 4.3580\n",
            "Iteration 570: Loss = 10.3085, ||Grad|| = 4.5369, ||W|| = 4.3535\n",
            "Iteration 571: Loss = 10.2882, ||Grad|| = 4.5323, ||W|| = 4.3490\n",
            "Iteration 572: Loss = 10.2678, ||Grad|| = 4.5278, ||W|| = 4.3445\n",
            "Iteration 573: Loss = 10.2475, ||Grad|| = 4.5232, ||W|| = 4.3400\n",
            "Iteration 574: Loss = 10.2273, ||Grad|| = 4.5187, ||W|| = 4.3355\n",
            "Iteration 575: Loss = 10.2071, ||Grad|| = 4.5142, ||W|| = 4.3311\n",
            "Iteration 576: Loss = 10.1869, ||Grad|| = 4.5096, ||W|| = 4.3266\n",
            "Iteration 577: Loss = 10.1668, ||Grad|| = 4.5051, ||W|| = 4.3221\n",
            "Iteration 578: Loss = 10.1467, ||Grad|| = 4.5006, ||W|| = 4.3177\n",
            "Iteration 579: Loss = 10.1267, ||Grad|| = 4.4961, ||W|| = 4.3132\n",
            "Iteration 580: Loss = 10.1067, ||Grad|| = 4.4916, ||W|| = 4.3088\n",
            "Iteration 581: Loss = 10.0867, ||Grad|| = 4.4870, ||W|| = 4.3043\n",
            "Iteration 582: Loss = 10.0668, ||Grad|| = 4.4825, ||W|| = 4.2999\n",
            "Iteration 583: Loss = 10.0469, ||Grad|| = 4.4780, ||W|| = 4.2954\n",
            "Iteration 584: Loss = 10.0271, ||Grad|| = 4.4735, ||W|| = 4.2910\n",
            "Iteration 585: Loss = 10.0073, ||Grad|| = 4.4691, ||W|| = 4.2866\n",
            "Iteration 586: Loss = 9.9875, ||Grad|| = 4.4646, ||W|| = 4.2822\n",
            "Iteration 587: Loss = 9.9678, ||Grad|| = 4.4601, ||W|| = 4.2777\n",
            "Iteration 588: Loss = 9.9481, ||Grad|| = 4.4556, ||W|| = 4.2733\n",
            "Iteration 589: Loss = 9.9285, ||Grad|| = 4.4511, ||W|| = 4.2689\n",
            "Iteration 590: Loss = 9.9089, ||Grad|| = 4.4467, ||W|| = 4.2645\n",
            "Iteration 591: Loss = 9.8894, ||Grad|| = 4.4422, ||W|| = 4.2601\n",
            "Iteration 592: Loss = 9.8698, ||Grad|| = 4.4377, ||W|| = 4.2557\n",
            "Iteration 593: Loss = 9.8504, ||Grad|| = 4.4333, ||W|| = 4.2513\n",
            "Iteration 594: Loss = 9.8309, ||Grad|| = 4.4288, ||W|| = 4.2469\n",
            "Iteration 595: Loss = 9.8115, ||Grad|| = 4.4244, ||W|| = 4.2426\n",
            "Iteration 596: Loss = 9.7922, ||Grad|| = 4.4199, ||W|| = 4.2382\n",
            "Iteration 597: Loss = 9.7728, ||Grad|| = 4.4155, ||W|| = 4.2338\n",
            "Iteration 598: Loss = 9.7536, ||Grad|| = 4.4111, ||W|| = 4.2294\n",
            "Iteration 599: Loss = 9.7343, ||Grad|| = 4.4066, ||W|| = 4.2251\n",
            "Iteration 600: Loss = 9.7151, ||Grad|| = 4.4022, ||W|| = 4.2207\n",
            "Iteration 601: Loss = 9.6959, ||Grad|| = 4.3978, ||W|| = 4.2163\n",
            "Iteration 602: Loss = 9.6768, ||Grad|| = 4.3934, ||W|| = 4.2120\n",
            "Iteration 603: Loss = 9.6577, ||Grad|| = 4.3890, ||W|| = 4.2076\n",
            "Iteration 604: Loss = 9.6387, ||Grad|| = 4.3846, ||W|| = 4.2033\n",
            "Iteration 605: Loss = 9.6197, ||Grad|| = 4.3801, ||W|| = 4.1990\n",
            "Iteration 606: Loss = 9.6007, ||Grad|| = 4.3757, ||W|| = 4.1946\n",
            "Iteration 607: Loss = 9.5818, ||Grad|| = 4.3714, ||W|| = 4.1903\n",
            "Iteration 608: Loss = 9.5629, ||Grad|| = 4.3670, ||W|| = 4.1860\n",
            "Iteration 609: Loss = 9.5440, ||Grad|| = 4.3626, ||W|| = 4.1817\n",
            "Iteration 610: Loss = 9.5252, ||Grad|| = 4.3582, ||W|| = 4.1773\n",
            "Iteration 611: Loss = 9.5064, ||Grad|| = 4.3538, ||W|| = 4.1730\n",
            "Iteration 612: Loss = 9.4877, ||Grad|| = 4.3494, ||W|| = 4.1687\n",
            "Iteration 613: Loss = 9.4690, ||Grad|| = 4.3451, ||W|| = 4.1644\n",
            "Iteration 614: Loss = 9.4503, ||Grad|| = 4.3407, ||W|| = 4.1601\n",
            "Iteration 615: Loss = 9.4317, ||Grad|| = 4.3364, ||W|| = 4.1558\n",
            "Iteration 616: Loss = 9.4131, ||Grad|| = 4.3320, ||W|| = 4.1515\n",
            "Iteration 617: Loss = 9.3945, ||Grad|| = 4.3276, ||W|| = 4.1472\n",
            "Iteration 618: Loss = 9.3760, ||Grad|| = 4.3233, ||W|| = 4.1430\n",
            "Iteration 619: Loss = 9.3575, ||Grad|| = 4.3190, ||W|| = 4.1387\n",
            "Iteration 620: Loss = 9.3391, ||Grad|| = 4.3146, ||W|| = 4.1344\n",
            "Iteration 621: Loss = 9.3207, ||Grad|| = 4.3103, ||W|| = 4.1301\n",
            "Iteration 622: Loss = 9.3023, ||Grad|| = 4.3059, ||W|| = 4.1259\n",
            "Iteration 623: Loss = 9.2840, ||Grad|| = 4.3016, ||W|| = 4.1216\n",
            "Iteration 624: Loss = 9.2657, ||Grad|| = 4.2973, ||W|| = 4.1174\n",
            "Iteration 625: Loss = 9.2475, ||Grad|| = 4.2930, ||W|| = 4.1131\n",
            "Iteration 626: Loss = 9.2292, ||Grad|| = 4.2887, ||W|| = 4.1089\n",
            "Iteration 627: Loss = 9.2111, ||Grad|| = 4.2844, ||W|| = 4.1046\n",
            "Iteration 628: Loss = 9.1929, ||Grad|| = 4.2801, ||W|| = 4.1004\n",
            "Iteration 629: Loss = 9.1748, ||Grad|| = 4.2758, ||W|| = 4.0962\n",
            "Iteration 630: Loss = 9.1567, ||Grad|| = 4.2715, ||W|| = 4.0919\n",
            "Iteration 631: Loss = 9.1387, ||Grad|| = 4.2672, ||W|| = 4.0877\n",
            "Iteration 632: Loss = 9.1207, ||Grad|| = 4.2629, ||W|| = 4.0835\n",
            "Iteration 633: Loss = 9.1028, ||Grad|| = 4.2586, ||W|| = 4.0793\n",
            "Iteration 634: Loss = 9.0848, ||Grad|| = 4.2543, ||W|| = 4.0751\n",
            "Iteration 635: Loss = 9.0670, ||Grad|| = 4.2500, ||W|| = 4.0708\n",
            "Iteration 636: Loss = 9.0491, ||Grad|| = 4.2458, ||W|| = 4.0666\n",
            "Iteration 637: Loss = 9.0313, ||Grad|| = 4.2415, ||W|| = 4.0624\n",
            "Iteration 638: Loss = 9.0135, ||Grad|| = 4.2372, ||W|| = 4.0582\n",
            "Iteration 639: Loss = 8.9958, ||Grad|| = 4.2330, ||W|| = 4.0541\n",
            "Iteration 640: Loss = 8.9781, ||Grad|| = 4.2287, ||W|| = 4.0499\n",
            "Iteration 641: Loss = 8.9604, ||Grad|| = 4.2245, ||W|| = 4.0457\n",
            "Iteration 642: Loss = 8.9428, ||Grad|| = 4.2202, ||W|| = 4.0415\n",
            "Iteration 643: Loss = 8.9252, ||Grad|| = 4.2160, ||W|| = 4.0373\n",
            "Iteration 644: Loss = 8.9076, ||Grad|| = 4.2117, ||W|| = 4.0332\n",
            "Iteration 645: Loss = 8.8901, ||Grad|| = 4.2075, ||W|| = 4.0290\n",
            "Iteration 646: Loss = 8.8726, ||Grad|| = 4.2033, ||W|| = 4.0248\n",
            "Iteration 647: Loss = 8.8551, ||Grad|| = 4.1991, ||W|| = 4.0207\n",
            "Iteration 648: Loss = 8.8377, ||Grad|| = 4.1948, ||W|| = 4.0165\n",
            "Iteration 649: Loss = 8.8203, ||Grad|| = 4.1906, ||W|| = 4.0124\n",
            "Iteration 650: Loss = 8.8030, ||Grad|| = 4.1864, ||W|| = 4.0082\n",
            "Iteration 651: Loss = 8.7857, ||Grad|| = 4.1822, ||W|| = 4.0041\n",
            "Iteration 652: Loss = 8.7684, ||Grad|| = 4.1780, ||W|| = 4.0000\n",
            "Iteration 653: Loss = 8.7511, ||Grad|| = 4.1738, ||W|| = 3.9958\n",
            "Iteration 654: Loss = 8.7339, ||Grad|| = 4.1696, ||W|| = 3.9917\n",
            "Iteration 655: Loss = 8.7168, ||Grad|| = 4.1654, ||W|| = 3.9876\n",
            "Iteration 656: Loss = 8.6996, ||Grad|| = 4.1612, ||W|| = 3.9835\n",
            "Iteration 657: Loss = 8.6825, ||Grad|| = 4.1570, ||W|| = 3.9794\n",
            "Iteration 658: Loss = 8.6654, ||Grad|| = 4.1529, ||W|| = 3.9753\n",
            "Iteration 659: Loss = 8.6484, ||Grad|| = 4.1487, ||W|| = 3.9711\n",
            "Iteration 660: Loss = 8.6314, ||Grad|| = 4.1445, ||W|| = 3.9670\n",
            "Iteration 661: Loss = 8.6144, ||Grad|| = 4.1403, ||W|| = 3.9630\n",
            "Iteration 662: Loss = 8.5975, ||Grad|| = 4.1362, ||W|| = 3.9589\n",
            "Iteration 663: Loss = 8.5806, ||Grad|| = 4.1320, ||W|| = 3.9548\n",
            "Iteration 664: Loss = 8.5638, ||Grad|| = 4.1279, ||W|| = 3.9507\n",
            "Iteration 665: Loss = 8.5469, ||Grad|| = 4.1237, ||W|| = 3.9466\n",
            "Iteration 666: Loss = 8.5301, ||Grad|| = 4.1196, ||W|| = 3.9425\n",
            "Iteration 667: Loss = 8.5134, ||Grad|| = 4.1154, ||W|| = 3.9385\n",
            "Iteration 668: Loss = 8.4966, ||Grad|| = 4.1113, ||W|| = 3.9344\n",
            "Iteration 669: Loss = 8.4800, ||Grad|| = 4.1072, ||W|| = 3.9303\n",
            "Iteration 670: Loss = 8.4633, ||Grad|| = 4.1030, ||W|| = 3.9263\n",
            "Iteration 671: Loss = 8.4467, ||Grad|| = 4.0989, ||W|| = 3.9222\n",
            "Iteration 672: Loss = 8.4301, ||Grad|| = 4.0948, ||W|| = 3.9182\n",
            "Iteration 673: Loss = 8.4135, ||Grad|| = 4.0907, ||W|| = 3.9141\n",
            "Iteration 674: Loss = 8.3970, ||Grad|| = 4.0865, ||W|| = 3.9101\n",
            "Iteration 675: Loss = 8.3805, ||Grad|| = 4.0824, ||W|| = 3.9060\n",
            "Iteration 676: Loss = 8.3641, ||Grad|| = 4.0783, ||W|| = 3.9020\n",
            "Iteration 677: Loss = 8.3476, ||Grad|| = 4.0742, ||W|| = 3.8980\n",
            "Iteration 678: Loss = 8.3312, ||Grad|| = 4.0701, ||W|| = 3.8939\n",
            "Iteration 679: Loss = 8.3149, ||Grad|| = 4.0660, ||W|| = 3.8899\n",
            "Iteration 680: Loss = 8.2986, ||Grad|| = 4.0619, ||W|| = 3.8859\n",
            "Iteration 681: Loss = 8.2823, ||Grad|| = 4.0578, ||W|| = 3.8819\n",
            "Iteration 682: Loss = 8.2660, ||Grad|| = 4.0538, ||W|| = 3.8779\n",
            "Iteration 683: Loss = 8.2498, ||Grad|| = 4.0497, ||W|| = 3.8739\n",
            "Iteration 684: Loss = 8.2336, ||Grad|| = 4.0456, ||W|| = 3.8699\n",
            "Iteration 685: Loss = 8.2175, ||Grad|| = 4.0415, ||W|| = 3.8659\n",
            "Iteration 686: Loss = 8.2013, ||Grad|| = 4.0375, ||W|| = 3.8619\n",
            "Iteration 687: Loss = 8.1852, ||Grad|| = 4.0334, ||W|| = 3.8579\n",
            "Iteration 688: Loss = 8.1692, ||Grad|| = 4.0294, ||W|| = 3.8539\n",
            "Iteration 689: Loss = 8.1532, ||Grad|| = 4.0253, ||W|| = 3.8499\n",
            "Iteration 690: Loss = 8.1372, ||Grad|| = 4.0213, ||W|| = 3.8460\n",
            "Iteration 691: Loss = 8.1212, ||Grad|| = 4.0172, ||W|| = 3.8420\n",
            "Iteration 692: Loss = 8.1053, ||Grad|| = 4.0132, ||W|| = 3.8380\n",
            "Iteration 693: Loss = 8.0894, ||Grad|| = 4.0091, ||W|| = 3.8340\n",
            "Iteration 694: Loss = 8.0735, ||Grad|| = 4.0051, ||W|| = 3.8301\n",
            "Iteration 695: Loss = 8.0577, ||Grad|| = 4.0011, ||W|| = 3.8261\n",
            "Iteration 696: Loss = 8.0419, ||Grad|| = 3.9970, ||W|| = 3.8222\n",
            "Iteration 697: Loss = 8.0261, ||Grad|| = 3.9930, ||W|| = 3.8182\n",
            "Iteration 698: Loss = 8.0104, ||Grad|| = 3.9890, ||W|| = 3.8143\n",
            "Iteration 699: Loss = 7.9947, ||Grad|| = 3.9850, ||W|| = 3.8103\n",
            "Iteration 700: Loss = 7.9790, ||Grad|| = 3.9810, ||W|| = 3.8064\n",
            "Iteration 701: Loss = 7.9634, ||Grad|| = 3.9770, ||W|| = 3.8025\n",
            "Iteration 702: Loss = 7.9478, ||Grad|| = 3.9730, ||W|| = 3.7985\n",
            "Iteration 703: Loss = 7.9322, ||Grad|| = 3.9690, ||W|| = 3.7946\n",
            "Iteration 704: Loss = 7.9166, ||Grad|| = 3.9650, ||W|| = 3.7907\n",
            "Iteration 705: Loss = 7.9011, ||Grad|| = 3.9610, ||W|| = 3.7868\n",
            "Iteration 706: Loss = 7.8857, ||Grad|| = 3.9570, ||W|| = 3.7829\n",
            "Iteration 707: Loss = 7.8702, ||Grad|| = 3.9530, ||W|| = 3.7790\n",
            "Iteration 708: Loss = 7.8548, ||Grad|| = 3.9490, ||W|| = 3.7751\n",
            "Iteration 709: Loss = 7.8394, ||Grad|| = 3.9451, ||W|| = 3.7712\n",
            "Iteration 710: Loss = 7.8240, ||Grad|| = 3.9411, ||W|| = 3.7673\n",
            "Iteration 711: Loss = 7.8087, ||Grad|| = 3.9371, ||W|| = 3.7634\n",
            "Iteration 712: Loss = 7.7934, ||Grad|| = 3.9332, ||W|| = 3.7595\n",
            "Iteration 713: Loss = 7.7782, ||Grad|| = 3.9292, ||W|| = 3.7556\n",
            "Iteration 714: Loss = 7.7629, ||Grad|| = 3.9252, ||W|| = 3.7517\n",
            "Iteration 715: Loss = 7.7477, ||Grad|| = 3.9213, ||W|| = 3.7479\n",
            "Iteration 716: Loss = 7.7326, ||Grad|| = 3.9173, ||W|| = 3.7440\n",
            "Iteration 717: Loss = 7.7174, ||Grad|| = 3.9134, ||W|| = 3.7401\n",
            "Iteration 718: Loss = 7.7023, ||Grad|| = 3.9095, ||W|| = 3.7362\n",
            "Iteration 719: Loss = 7.6873, ||Grad|| = 3.9055, ||W|| = 3.7324\n",
            "Iteration 720: Loss = 7.6722, ||Grad|| = 3.9016, ||W|| = 3.7285\n",
            "Iteration 721: Loss = 7.6572, ||Grad|| = 3.8977, ||W|| = 3.7247\n",
            "Iteration 722: Loss = 7.6422, ||Grad|| = 3.8937, ||W|| = 3.7208\n",
            "Iteration 723: Loss = 7.6273, ||Grad|| = 3.8898, ||W|| = 3.7170\n",
            "Iteration 724: Loss = 7.6123, ||Grad|| = 3.8859, ||W|| = 3.7131\n",
            "Iteration 725: Loss = 7.5974, ||Grad|| = 3.8820, ||W|| = 3.7093\n",
            "Iteration 726: Loss = 7.5826, ||Grad|| = 3.8781, ||W|| = 3.7055\n",
            "Iteration 727: Loss = 7.5677, ||Grad|| = 3.8742, ||W|| = 3.7016\n",
            "Iteration 728: Loss = 7.5529, ||Grad|| = 3.8703, ||W|| = 3.6978\n",
            "Iteration 729: Loss = 7.5382, ||Grad|| = 3.8664, ||W|| = 3.6940\n",
            "Iteration 730: Loss = 7.5234, ||Grad|| = 3.8625, ||W|| = 3.6902\n",
            "Iteration 731: Loss = 7.5087, ||Grad|| = 3.8586, ||W|| = 3.6864\n",
            "Iteration 732: Loss = 7.4940, ||Grad|| = 3.8547, ||W|| = 3.6826\n",
            "Iteration 733: Loss = 7.4794, ||Grad|| = 3.8508, ||W|| = 3.6788\n",
            "Iteration 734: Loss = 7.4648, ||Grad|| = 3.8469, ||W|| = 3.6750\n",
            "Iteration 735: Loss = 7.4502, ||Grad|| = 3.8431, ||W|| = 3.6712\n",
            "Iteration 736: Loss = 7.4356, ||Grad|| = 3.8392, ||W|| = 3.6674\n",
            "Iteration 737: Loss = 7.4211, ||Grad|| = 3.8353, ||W|| = 3.6636\n",
            "Iteration 738: Loss = 7.4066, ||Grad|| = 3.8315, ||W|| = 3.6598\n",
            "Iteration 739: Loss = 7.3921, ||Grad|| = 3.8276, ||W|| = 3.6560\n",
            "Iteration 740: Loss = 7.3777, ||Grad|| = 3.8237, ||W|| = 3.6522\n",
            "Iteration 741: Loss = 7.3632, ||Grad|| = 3.8199, ||W|| = 3.6485\n",
            "Iteration 742: Loss = 7.3489, ||Grad|| = 3.8160, ||W|| = 3.6447\n",
            "Iteration 743: Loss = 7.3345, ||Grad|| = 3.8122, ||W|| = 3.6409\n",
            "Iteration 744: Loss = 7.3202, ||Grad|| = 3.8084, ||W|| = 3.6372\n",
            "Iteration 745: Loss = 7.3059, ||Grad|| = 3.8045, ||W|| = 3.6334\n",
            "Iteration 746: Loss = 7.2916, ||Grad|| = 3.8007, ||W|| = 3.6297\n",
            "Iteration 747: Loss = 7.2774, ||Grad|| = 3.7969, ||W|| = 3.6259\n",
            "Iteration 748: Loss = 7.2632, ||Grad|| = 3.7930, ||W|| = 3.6222\n",
            "Iteration 749: Loss = 7.2490, ||Grad|| = 3.7892, ||W|| = 3.6184\n",
            "Iteration 750: Loss = 7.2348, ||Grad|| = 3.7854, ||W|| = 3.6147\n",
            "Iteration 751: Loss = 7.2207, ||Grad|| = 3.7816, ||W|| = 3.6109\n",
            "Iteration 752: Loss = 7.2066, ||Grad|| = 3.7778, ||W|| = 3.6072\n",
            "Iteration 753: Loss = 7.1926, ||Grad|| = 3.7740, ||W|| = 3.6035\n",
            "Iteration 754: Loss = 7.1785, ||Grad|| = 3.7702, ||W|| = 3.5998\n",
            "Iteration 755: Loss = 7.1645, ||Grad|| = 3.7664, ||W|| = 3.5960\n",
            "Iteration 756: Loss = 7.1505, ||Grad|| = 3.7626, ||W|| = 3.5923\n",
            "Iteration 757: Loss = 7.1366, ||Grad|| = 3.7588, ||W|| = 3.5886\n",
            "Iteration 758: Loss = 7.1227, ||Grad|| = 3.7550, ||W|| = 3.5849\n",
            "Iteration 759: Loss = 7.1088, ||Grad|| = 3.7512, ||W|| = 3.5812\n",
            "Iteration 760: Loss = 7.0949, ||Grad|| = 3.7474, ||W|| = 3.5775\n",
            "Iteration 761: Loss = 7.0811, ||Grad|| = 3.7436, ||W|| = 3.5738\n",
            "Iteration 762: Loss = 7.0672, ||Grad|| = 3.7399, ||W|| = 3.5701\n",
            "Iteration 763: Loss = 7.0535, ||Grad|| = 3.7361, ||W|| = 3.5664\n",
            "Iteration 764: Loss = 7.0397, ||Grad|| = 3.7323, ||W|| = 3.5627\n",
            "Iteration 765: Loss = 7.0260, ||Grad|| = 3.7286, ||W|| = 3.5591\n",
            "Iteration 766: Loss = 7.0123, ||Grad|| = 3.7248, ||W|| = 3.5554\n",
            "Iteration 767: Loss = 6.9986, ||Grad|| = 3.7210, ||W|| = 3.5517\n",
            "Iteration 768: Loss = 6.9850, ||Grad|| = 3.7173, ||W|| = 3.5480\n",
            "Iteration 769: Loss = 6.9714, ||Grad|| = 3.7135, ||W|| = 3.5444\n",
            "Iteration 770: Loss = 6.9578, ||Grad|| = 3.7098, ||W|| = 3.5407\n",
            "Iteration 771: Loss = 6.9442, ||Grad|| = 3.7061, ||W|| = 3.5370\n",
            "Iteration 772: Loss = 6.9307, ||Grad|| = 3.7023, ||W|| = 3.5334\n",
            "Iteration 773: Loss = 6.9172, ||Grad|| = 3.6986, ||W|| = 3.5297\n",
            "Iteration 774: Loss = 6.9037, ||Grad|| = 3.6949, ||W|| = 3.5261\n",
            "Iteration 775: Loss = 6.8903, ||Grad|| = 3.6911, ||W|| = 3.5224\n",
            "Iteration 776: Loss = 6.8768, ||Grad|| = 3.6874, ||W|| = 3.5188\n",
            "Iteration 777: Loss = 6.8634, ||Grad|| = 3.6837, ||W|| = 3.5152\n",
            "Iteration 778: Loss = 6.8501, ||Grad|| = 3.6800, ||W|| = 3.5115\n",
            "Iteration 779: Loss = 6.8367, ||Grad|| = 3.6763, ||W|| = 3.5079\n",
            "Iteration 780: Loss = 6.8234, ||Grad|| = 3.6726, ||W|| = 3.5043\n",
            "Iteration 781: Loss = 6.8102, ||Grad|| = 3.6689, ||W|| = 3.5007\n",
            "Iteration 782: Loss = 6.7969, ||Grad|| = 3.6652, ||W|| = 3.4970\n",
            "Iteration 783: Loss = 6.7837, ||Grad|| = 3.6615, ||W|| = 3.4934\n",
            "Iteration 784: Loss = 6.7705, ||Grad|| = 3.6578, ||W|| = 3.4898\n",
            "Iteration 785: Loss = 6.7573, ||Grad|| = 3.6541, ||W|| = 3.4862\n",
            "Iteration 786: Loss = 6.7441, ||Grad|| = 3.6504, ||W|| = 3.4826\n",
            "Iteration 787: Loss = 6.7310, ||Grad|| = 3.6467, ||W|| = 3.4790\n",
            "Iteration 788: Loss = 6.7179, ||Grad|| = 3.6430, ||W|| = 3.4754\n",
            "Iteration 789: Loss = 6.7049, ||Grad|| = 3.6394, ||W|| = 3.4718\n",
            "Iteration 790: Loss = 6.6918, ||Grad|| = 3.6357, ||W|| = 3.4682\n",
            "Iteration 791: Loss = 6.6788, ||Grad|| = 3.6320, ||W|| = 3.4647\n",
            "Iteration 792: Loss = 6.6658, ||Grad|| = 3.6284, ||W|| = 3.4611\n",
            "Iteration 793: Loss = 6.6528, ||Grad|| = 3.6247, ||W|| = 3.4575\n",
            "Iteration 794: Loss = 6.6399, ||Grad|| = 3.6210, ||W|| = 3.4539\n",
            "Iteration 795: Loss = 6.6270, ||Grad|| = 3.6174, ||W|| = 3.4504\n",
            "Iteration 796: Loss = 6.6141, ||Grad|| = 3.6137, ||W|| = 3.4468\n",
            "Iteration 797: Loss = 6.6013, ||Grad|| = 3.6101, ||W|| = 3.4432\n",
            "Iteration 798: Loss = 6.5884, ||Grad|| = 3.6064, ||W|| = 3.4397\n",
            "Iteration 799: Loss = 6.5756, ||Grad|| = 3.6028, ||W|| = 3.4361\n",
            "Iteration 800: Loss = 6.5628, ||Grad|| = 3.5992, ||W|| = 3.4326\n",
            "Iteration 801: Loss = 6.5501, ||Grad|| = 3.5955, ||W|| = 3.4290\n",
            "Iteration 802: Loss = 6.5374, ||Grad|| = 3.5919, ||W|| = 3.4255\n",
            "Iteration 803: Loss = 6.5247, ||Grad|| = 3.5883, ||W|| = 3.4219\n",
            "Iteration 804: Loss = 6.5120, ||Grad|| = 3.5847, ||W|| = 3.4184\n",
            "Iteration 805: Loss = 6.4993, ||Grad|| = 3.5810, ||W|| = 3.4149\n",
            "Iteration 806: Loss = 6.4867, ||Grad|| = 3.5774, ||W|| = 3.4113\n",
            "Iteration 807: Loss = 6.4741, ||Grad|| = 3.5738, ||W|| = 3.4078\n",
            "Iteration 808: Loss = 6.4616, ||Grad|| = 3.5702, ||W|| = 3.4043\n",
            "Iteration 809: Loss = 6.4490, ||Grad|| = 3.5666, ||W|| = 3.4008\n",
            "Iteration 810: Loss = 6.4365, ||Grad|| = 3.5630, ||W|| = 3.3973\n",
            "Iteration 811: Loss = 6.4240, ||Grad|| = 3.5594, ||W|| = 3.3938\n",
            "Iteration 812: Loss = 6.4115, ||Grad|| = 3.5558, ||W|| = 3.3902\n",
            "Iteration 813: Loss = 6.3991, ||Grad|| = 3.5522, ||W|| = 3.3867\n",
            "Iteration 814: Loss = 6.3867, ||Grad|| = 3.5486, ||W|| = 3.3832\n",
            "Iteration 815: Loss = 6.3743, ||Grad|| = 3.5451, ||W|| = 3.3797\n",
            "Iteration 816: Loss = 6.3619, ||Grad|| = 3.5415, ||W|| = 3.3763\n",
            "Iteration 817: Loss = 6.3496, ||Grad|| = 3.5379, ||W|| = 3.3728\n",
            "Iteration 818: Loss = 6.3373, ||Grad|| = 3.5343, ||W|| = 3.3693\n",
            "Iteration 819: Loss = 6.3250, ||Grad|| = 3.5308, ||W|| = 3.3658\n",
            "Iteration 820: Loss = 6.3127, ||Grad|| = 3.5272, ||W|| = 3.3623\n",
            "Iteration 821: Loss = 6.3005, ||Grad|| = 3.5236, ||W|| = 3.3588\n",
            "Iteration 822: Loss = 6.2882, ||Grad|| = 3.5201, ||W|| = 3.3554\n",
            "Iteration 823: Loss = 6.2761, ||Grad|| = 3.5165, ||W|| = 3.3519\n",
            "Iteration 824: Loss = 6.2639, ||Grad|| = 3.5130, ||W|| = 3.3484\n",
            "Iteration 825: Loss = 6.2518, ||Grad|| = 3.5094, ||W|| = 3.3450\n",
            "Iteration 826: Loss = 6.2396, ||Grad|| = 3.5059, ||W|| = 3.3415\n",
            "Iteration 827: Loss = 6.2275, ||Grad|| = 3.5023, ||W|| = 3.3381\n",
            "Iteration 828: Loss = 6.2155, ||Grad|| = 3.4988, ||W|| = 3.3346\n",
            "Iteration 829: Loss = 6.2034, ||Grad|| = 3.4953, ||W|| = 3.3312\n",
            "Iteration 830: Loss = 6.1914, ||Grad|| = 3.4917, ||W|| = 3.3277\n",
            "Iteration 831: Loss = 6.1794, ||Grad|| = 3.4882, ||W|| = 3.3243\n",
            "Iteration 832: Loss = 6.1675, ||Grad|| = 3.4847, ||W|| = 3.3209\n",
            "Iteration 833: Loss = 6.1555, ||Grad|| = 3.4812, ||W|| = 3.3174\n",
            "Iteration 834: Loss = 6.1436, ||Grad|| = 3.4777, ||W|| = 3.3140\n",
            "Iteration 835: Loss = 6.1317, ||Grad|| = 3.4741, ||W|| = 3.3106\n",
            "Iteration 836: Loss = 6.1198, ||Grad|| = 3.4706, ||W|| = 3.3072\n",
            "Iteration 837: Loss = 6.1080, ||Grad|| = 3.4671, ||W|| = 3.3037\n",
            "Iteration 838: Loss = 6.0962, ||Grad|| = 3.4636, ||W|| = 3.3003\n",
            "Iteration 839: Loss = 6.0844, ||Grad|| = 3.4601, ||W|| = 3.2969\n",
            "Iteration 840: Loss = 6.0726, ||Grad|| = 3.4566, ||W|| = 3.2935\n",
            "Iteration 841: Loss = 6.0608, ||Grad|| = 3.4531, ||W|| = 3.2901\n",
            "Iteration 842: Loss = 6.0491, ||Grad|| = 3.4497, ||W|| = 3.2867\n",
            "Iteration 843: Loss = 6.0374, ||Grad|| = 3.4462, ||W|| = 3.2833\n",
            "Iteration 844: Loss = 6.0257, ||Grad|| = 3.4427, ||W|| = 3.2799\n",
            "Iteration 845: Loss = 6.0141, ||Grad|| = 3.4392, ||W|| = 3.2765\n",
            "Iteration 846: Loss = 6.0025, ||Grad|| = 3.4357, ||W|| = 3.2731\n",
            "Iteration 847: Loss = 5.9909, ||Grad|| = 3.4323, ||W|| = 3.2698\n",
            "Iteration 848: Loss = 5.9793, ||Grad|| = 3.4288, ||W|| = 3.2664\n",
            "Iteration 849: Loss = 5.9677, ||Grad|| = 3.4253, ||W|| = 3.2630\n",
            "Iteration 850: Loss = 5.9562, ||Grad|| = 3.4219, ||W|| = 3.2596\n",
            "Iteration 851: Loss = 5.9447, ||Grad|| = 3.4184, ||W|| = 3.2563\n",
            "Iteration 852: Loss = 5.9332, ||Grad|| = 3.4149, ||W|| = 3.2529\n",
            "Iteration 853: Loss = 5.9217, ||Grad|| = 3.4115, ||W|| = 3.2495\n",
            "Iteration 854: Loss = 5.9103, ||Grad|| = 3.4081, ||W|| = 3.2462\n",
            "Iteration 855: Loss = 5.8989, ||Grad|| = 3.4046, ||W|| = 3.2428\n",
            "Iteration 856: Loss = 5.8875, ||Grad|| = 3.4012, ||W|| = 3.2395\n",
            "Iteration 857: Loss = 5.8761, ||Grad|| = 3.3977, ||W|| = 3.2361\n",
            "Iteration 858: Loss = 5.8647, ||Grad|| = 3.3943, ||W|| = 3.2328\n",
            "Iteration 859: Loss = 5.8534, ||Grad|| = 3.3909, ||W|| = 3.2294\n",
            "Iteration 860: Loss = 5.8421, ||Grad|| = 3.3874, ||W|| = 3.2261\n",
            "Iteration 861: Loss = 5.8308, ||Grad|| = 3.3840, ||W|| = 3.2228\n",
            "Iteration 862: Loss = 5.8196, ||Grad|| = 3.3806, ||W|| = 3.2194\n",
            "Iteration 863: Loss = 5.8084, ||Grad|| = 3.3772, ||W|| = 3.2161\n",
            "Iteration 864: Loss = 5.7972, ||Grad|| = 3.3738, ||W|| = 3.2128\n",
            "Iteration 865: Loss = 5.7860, ||Grad|| = 3.3703, ||W|| = 3.2095\n",
            "Iteration 866: Loss = 5.7748, ||Grad|| = 3.3669, ||W|| = 3.2062\n",
            "Iteration 867: Loss = 5.7637, ||Grad|| = 3.3635, ||W|| = 3.2028\n",
            "Iteration 868: Loss = 5.7525, ||Grad|| = 3.3601, ||W|| = 3.1995\n",
            "Iteration 869: Loss = 5.7415, ||Grad|| = 3.3567, ||W|| = 3.1962\n",
            "Iteration 870: Loss = 5.7304, ||Grad|| = 3.3533, ||W|| = 3.1929\n",
            "Iteration 871: Loss = 5.7193, ||Grad|| = 3.3499, ||W|| = 3.1896\n",
            "Iteration 872: Loss = 5.7083, ||Grad|| = 3.3466, ||W|| = 3.1863\n",
            "Iteration 873: Loss = 5.6973, ||Grad|| = 3.3432, ||W|| = 3.1830\n",
            "Iteration 874: Loss = 5.6863, ||Grad|| = 3.3398, ||W|| = 3.1797\n",
            "Iteration 875: Loss = 5.6754, ||Grad|| = 3.3364, ||W|| = 3.1765\n",
            "Iteration 876: Loss = 5.6644, ||Grad|| = 3.3330, ||W|| = 3.1732\n",
            "Iteration 877: Loss = 5.6535, ||Grad|| = 3.3297, ||W|| = 3.1699\n",
            "Iteration 878: Loss = 5.6426, ||Grad|| = 3.3263, ||W|| = 3.1666\n",
            "Iteration 879: Loss = 5.6318, ||Grad|| = 3.3229, ||W|| = 3.1634\n",
            "Iteration 880: Loss = 5.6209, ||Grad|| = 3.3196, ||W|| = 3.1601\n",
            "Iteration 881: Loss = 5.6101, ||Grad|| = 3.3162, ||W|| = 3.1568\n",
            "Iteration 882: Loss = 5.5993, ||Grad|| = 3.3129, ||W|| = 3.1536\n",
            "Iteration 883: Loss = 5.5885, ||Grad|| = 3.3095, ||W|| = 3.1503\n",
            "Iteration 884: Loss = 5.5777, ||Grad|| = 3.3062, ||W|| = 3.1470\n",
            "Iteration 885: Loss = 5.5670, ||Grad|| = 3.3028, ||W|| = 3.1438\n",
            "Iteration 886: Loss = 5.5563, ||Grad|| = 3.2995, ||W|| = 3.1405\n",
            "Iteration 887: Loss = 5.5456, ||Grad|| = 3.2961, ||W|| = 3.1373\n",
            "Iteration 888: Loss = 5.5349, ||Grad|| = 3.2928, ||W|| = 3.1341\n",
            "Iteration 889: Loss = 5.5243, ||Grad|| = 3.2895, ||W|| = 3.1308\n",
            "Iteration 890: Loss = 5.5137, ||Grad|| = 3.2861, ||W|| = 3.1276\n",
            "Iteration 891: Loss = 5.5031, ||Grad|| = 3.2828, ||W|| = 3.1244\n",
            "Iteration 892: Loss = 5.4925, ||Grad|| = 3.2795, ||W|| = 3.1211\n",
            "Iteration 893: Loss = 5.4819, ||Grad|| = 3.2762, ||W|| = 3.1179\n",
            "Iteration 894: Loss = 5.4714, ||Grad|| = 3.2729, ||W|| = 3.1147\n",
            "Iteration 895: Loss = 5.4609, ||Grad|| = 3.2695, ||W|| = 3.1115\n",
            "Iteration 896: Loss = 5.4504, ||Grad|| = 3.2662, ||W|| = 3.1083\n",
            "Iteration 897: Loss = 5.4399, ||Grad|| = 3.2629, ||W|| = 3.1050\n",
            "Iteration 898: Loss = 5.4294, ||Grad|| = 3.2596, ||W|| = 3.1018\n",
            "Iteration 899: Loss = 5.4190, ||Grad|| = 3.2563, ||W|| = 3.0986\n",
            "Iteration 900: Loss = 5.4086, ||Grad|| = 3.2530, ||W|| = 3.0954\n",
            "Iteration 901: Loss = 5.3982, ||Grad|| = 3.2497, ||W|| = 3.0922\n",
            "Iteration 902: Loss = 5.3878, ||Grad|| = 3.2464, ||W|| = 3.0890\n",
            "Iteration 903: Loss = 5.3775, ||Grad|| = 3.2432, ||W|| = 3.0858\n",
            "Iteration 904: Loss = 5.3672, ||Grad|| = 3.2399, ||W|| = 3.0827\n",
            "Iteration 905: Loss = 5.3569, ||Grad|| = 3.2366, ||W|| = 3.0795\n",
            "Iteration 906: Loss = 5.3466, ||Grad|| = 3.2333, ||W|| = 3.0763\n",
            "Iteration 907: Loss = 5.3363, ||Grad|| = 3.2300, ||W|| = 3.0731\n",
            "Iteration 908: Loss = 5.3261, ||Grad|| = 3.2268, ||W|| = 3.0699\n",
            "Iteration 909: Loss = 5.3159, ||Grad|| = 3.2235, ||W|| = 3.0668\n",
            "Iteration 910: Loss = 5.3057, ||Grad|| = 3.2202, ||W|| = 3.0636\n",
            "Iteration 911: Loss = 5.2955, ||Grad|| = 3.2170, ||W|| = 3.0604\n",
            "Iteration 912: Loss = 5.2853, ||Grad|| = 3.2137, ||W|| = 3.0573\n",
            "Iteration 913: Loss = 5.2752, ||Grad|| = 3.2105, ||W|| = 3.0541\n",
            "Iteration 914: Loss = 5.2651, ||Grad|| = 3.2072, ||W|| = 3.0510\n",
            "Iteration 915: Loss = 5.2550, ||Grad|| = 3.2040, ||W|| = 3.0478\n",
            "Iteration 916: Loss = 5.2449, ||Grad|| = 3.2007, ||W|| = 3.0447\n",
            "Iteration 917: Loss = 5.2349, ||Grad|| = 3.1975, ||W|| = 3.0415\n",
            "Iteration 918: Loss = 5.2248, ||Grad|| = 3.1942, ||W|| = 3.0384\n",
            "Iteration 919: Loss = 5.2148, ||Grad|| = 3.1910, ||W|| = 3.0352\n",
            "Iteration 920: Loss = 5.2048, ||Grad|| = 3.1878, ||W|| = 3.0321\n",
            "Iteration 921: Loss = 5.1949, ||Grad|| = 3.1845, ||W|| = 3.0290\n",
            "Iteration 922: Loss = 5.1849, ||Grad|| = 3.1813, ||W|| = 3.0258\n",
            "Iteration 923: Loss = 5.1750, ||Grad|| = 3.1781, ||W|| = 3.0227\n",
            "Iteration 924: Loss = 5.1651, ||Grad|| = 3.1749, ||W|| = 3.0196\n",
            "Iteration 925: Loss = 5.1552, ||Grad|| = 3.1717, ||W|| = 3.0165\n",
            "Iteration 926: Loss = 5.1453, ||Grad|| = 3.1684, ||W|| = 3.0134\n",
            "Iteration 927: Loss = 5.1355, ||Grad|| = 3.1652, ||W|| = 3.0102\n",
            "Iteration 928: Loss = 5.1256, ||Grad|| = 3.1620, ||W|| = 3.0071\n",
            "Iteration 929: Loss = 5.1158, ||Grad|| = 3.1588, ||W|| = 3.0040\n",
            "Iteration 930: Loss = 5.1061, ||Grad|| = 3.1556, ||W|| = 3.0009\n",
            "Iteration 931: Loss = 5.0963, ||Grad|| = 3.1524, ||W|| = 2.9978\n",
            "Iteration 932: Loss = 5.0865, ||Grad|| = 3.1492, ||W|| = 2.9947\n",
            "Iteration 933: Loss = 5.0768, ||Grad|| = 3.1460, ||W|| = 2.9916\n",
            "Iteration 934: Loss = 5.0671, ||Grad|| = 3.1428, ||W|| = 2.9885\n",
            "Iteration 935: Loss = 5.0574, ||Grad|| = 3.1397, ||W|| = 2.9855\n",
            "Iteration 936: Loss = 5.0478, ||Grad|| = 3.1365, ||W|| = 2.9824\n",
            "Iteration 937: Loss = 5.0381, ||Grad|| = 3.1333, ||W|| = 2.9793\n",
            "Iteration 938: Loss = 5.0285, ||Grad|| = 3.1301, ||W|| = 2.9762\n",
            "Iteration 939: Loss = 5.0189, ||Grad|| = 3.1270, ||W|| = 2.9731\n",
            "Iteration 940: Loss = 5.0093, ||Grad|| = 3.1238, ||W|| = 2.9701\n",
            "Iteration 941: Loss = 4.9997, ||Grad|| = 3.1206, ||W|| = 2.9670\n",
            "Iteration 942: Loss = 4.9902, ||Grad|| = 3.1175, ||W|| = 2.9639\n",
            "Iteration 943: Loss = 4.9806, ||Grad|| = 3.1143, ||W|| = 2.9609\n",
            "Iteration 944: Loss = 4.9711, ||Grad|| = 3.1111, ||W|| = 2.9578\n",
            "Iteration 945: Loss = 4.9616, ||Grad|| = 3.1080, ||W|| = 2.9548\n",
            "Iteration 946: Loss = 4.9522, ||Grad|| = 3.1048, ||W|| = 2.9517\n",
            "Iteration 947: Loss = 4.9427, ||Grad|| = 3.1017, ||W|| = 2.9487\n",
            "Iteration 948: Loss = 4.9333, ||Grad|| = 3.0985, ||W|| = 2.9456\n",
            "Iteration 949: Loss = 4.9239, ||Grad|| = 3.0954, ||W|| = 2.9426\n",
            "Iteration 950: Loss = 4.9145, ||Grad|| = 3.0923, ||W|| = 2.9395\n",
            "Iteration 951: Loss = 4.9051, ||Grad|| = 3.0891, ||W|| = 2.9365\n",
            "Iteration 952: Loss = 4.8958, ||Grad|| = 3.0860, ||W|| = 2.9335\n",
            "Iteration 953: Loss = 4.8864, ||Grad|| = 3.0829, ||W|| = 2.9305\n",
            "Iteration 954: Loss = 4.8771, ||Grad|| = 3.0797, ||W|| = 2.9274\n",
            "Iteration 955: Loss = 4.8678, ||Grad|| = 3.0766, ||W|| = 2.9244\n",
            "Iteration 956: Loss = 4.8585, ||Grad|| = 3.0735, ||W|| = 2.9214\n",
            "Iteration 957: Loss = 4.8493, ||Grad|| = 3.0704, ||W|| = 2.9184\n",
            "Iteration 958: Loss = 4.8400, ||Grad|| = 3.0673, ||W|| = 2.9154\n",
            "Iteration 959: Loss = 4.8308, ||Grad|| = 3.0641, ||W|| = 2.9123\n",
            "Iteration 960: Loss = 4.8216, ||Grad|| = 3.0610, ||W|| = 2.9093\n",
            "Iteration 961: Loss = 4.8124, ||Grad|| = 3.0579, ||W|| = 2.9063\n",
            "Iteration 962: Loss = 4.8033, ||Grad|| = 3.0548, ||W|| = 2.9033\n",
            "Iteration 963: Loss = 4.7941, ||Grad|| = 3.0517, ||W|| = 2.9003\n",
            "Iteration 964: Loss = 4.7850, ||Grad|| = 3.0486, ||W|| = 2.8973\n",
            "Iteration 965: Loss = 4.7759, ||Grad|| = 3.0455, ||W|| = 2.8943\n",
            "Iteration 966: Loss = 4.7668, ||Grad|| = 3.0424, ||W|| = 2.8914\n",
            "Iteration 967: Loss = 4.7577, ||Grad|| = 3.0394, ||W|| = 2.8884\n",
            "Iteration 968: Loss = 4.7487, ||Grad|| = 3.0363, ||W|| = 2.8854\n",
            "Iteration 969: Loss = 4.7397, ||Grad|| = 3.0332, ||W|| = 2.8824\n",
            "Iteration 970: Loss = 4.7307, ||Grad|| = 3.0301, ||W|| = 2.8794\n",
            "Iteration 971: Loss = 4.7217, ||Grad|| = 3.0270, ||W|| = 2.8765\n",
            "Iteration 972: Loss = 4.7127, ||Grad|| = 3.0240, ||W|| = 2.8735\n",
            "Iteration 973: Loss = 4.7037, ||Grad|| = 3.0209, ||W|| = 2.8705\n",
            "Iteration 974: Loss = 4.6948, ||Grad|| = 3.0178, ||W|| = 2.8676\n",
            "Iteration 975: Loss = 4.6859, ||Grad|| = 3.0148, ||W|| = 2.8646\n",
            "Iteration 976: Loss = 4.6770, ||Grad|| = 3.0117, ||W|| = 2.8617\n",
            "Iteration 977: Loss = 4.6681, ||Grad|| = 3.0086, ||W|| = 2.8587\n",
            "Iteration 978: Loss = 4.6592, ||Grad|| = 3.0056, ||W|| = 2.8557\n",
            "Iteration 979: Loss = 4.6504, ||Grad|| = 3.0025, ||W|| = 2.8528\n",
            "Iteration 980: Loss = 4.6415, ||Grad|| = 2.9995, ||W|| = 2.8499\n",
            "Iteration 981: Loss = 4.6327, ||Grad|| = 2.9965, ||W|| = 2.8469\n",
            "Iteration 982: Loss = 4.6239, ||Grad|| = 2.9934, ||W|| = 2.8440\n",
            "Iteration 983: Loss = 4.6152, ||Grad|| = 2.9904, ||W|| = 2.8410\n",
            "Iteration 984: Loss = 4.6064, ||Grad|| = 2.9873, ||W|| = 2.8381\n",
            "Iteration 985: Loss = 4.5977, ||Grad|| = 2.9843, ||W|| = 2.8352\n",
            "Iteration 986: Loss = 4.5889, ||Grad|| = 2.9813, ||W|| = 2.8322\n",
            "Iteration 987: Loss = 4.5802, ||Grad|| = 2.9782, ||W|| = 2.8293\n",
            "Iteration 988: Loss = 4.5716, ||Grad|| = 2.9752, ||W|| = 2.8264\n",
            "Iteration 989: Loss = 4.5629, ||Grad|| = 2.9722, ||W|| = 2.8235\n",
            "Iteration 990: Loss = 4.5542, ||Grad|| = 2.9692, ||W|| = 2.8206\n",
            "Iteration 991: Loss = 4.5456, ||Grad|| = 2.9662, ||W|| = 2.8177\n",
            "Iteration 992: Loss = 4.5370, ||Grad|| = 2.9631, ||W|| = 2.8148\n",
            "Iteration 993: Loss = 4.5284, ||Grad|| = 2.9601, ||W|| = 2.8119\n",
            "Iteration 994: Loss = 4.5198, ||Grad|| = 2.9571, ||W|| = 2.8089\n",
            "Iteration 995: Loss = 4.5113, ||Grad|| = 2.9541, ||W|| = 2.8061\n",
            "Iteration 996: Loss = 4.5027, ||Grad|| = 2.9511, ||W|| = 2.8032\n",
            "Iteration 997: Loss = 4.4942, ||Grad|| = 2.9481, ||W|| = 2.8003\n",
            "Iteration 998: Loss = 4.4857, ||Grad|| = 2.9451, ||W|| = 2.7974\n",
            "Iteration 999: Loss = 4.4772, ||Grad|| = 2.9421, ||W|| = 2.7945\n",
            "Iteration 1000: Loss = 4.4687, ||Grad|| = 2.9392, ||W|| = 2.7916\n",
            "Iteration 1001: Loss = 4.4603, ||Grad|| = 2.9362, ||W|| = 2.7887\n",
            "Iteration 1002: Loss = 4.4518, ||Grad|| = 2.9332, ||W|| = 2.7858\n",
            "Iteration 1003: Loss = 4.4434, ||Grad|| = 2.9302, ||W|| = 2.7830\n",
            "Iteration 1004: Loss = 4.4350, ||Grad|| = 2.9272, ||W|| = 2.7801\n",
            "Iteration 1005: Loss = 4.4266, ||Grad|| = 2.9242, ||W|| = 2.7772\n",
            "Iteration 1006: Loss = 4.4183, ||Grad|| = 2.9213, ||W|| = 2.7744\n",
            "Iteration 1007: Loss = 4.4099, ||Grad|| = 2.9183, ||W|| = 2.7715\n",
            "Iteration 1008: Loss = 4.4016, ||Grad|| = 2.9153, ||W|| = 2.7686\n",
            "Iteration 1009: Loss = 4.3933, ||Grad|| = 2.9124, ||W|| = 2.7658\n",
            "Iteration 1010: Loss = 4.3850, ||Grad|| = 2.9094, ||W|| = 2.7629\n",
            "Iteration 1011: Loss = 4.3767, ||Grad|| = 2.9065, ||W|| = 2.7601\n",
            "Iteration 1012: Loss = 4.3684, ||Grad|| = 2.9035, ||W|| = 2.7572\n",
            "Iteration 1013: Loss = 4.3602, ||Grad|| = 2.9006, ||W|| = 2.7544\n",
            "Iteration 1014: Loss = 4.3520, ||Grad|| = 2.8976, ||W|| = 2.7515\n",
            "Iteration 1015: Loss = 4.3437, ||Grad|| = 2.8947, ||W|| = 2.7487\n",
            "Iteration 1016: Loss = 4.3355, ||Grad|| = 2.8917, ||W|| = 2.7459\n",
            "Iteration 1017: Loss = 4.3274, ||Grad|| = 2.8888, ||W|| = 2.7430\n",
            "Iteration 1018: Loss = 4.3192, ||Grad|| = 2.8858, ||W|| = 2.7402\n",
            "Iteration 1019: Loss = 4.3111, ||Grad|| = 2.8829, ||W|| = 2.7374\n",
            "Iteration 1020: Loss = 4.3029, ||Grad|| = 2.8800, ||W|| = 2.7346\n",
            "Iteration 1021: Loss = 4.2948, ||Grad|| = 2.8770, ||W|| = 2.7317\n",
            "Iteration 1022: Loss = 4.2867, ||Grad|| = 2.8741, ||W|| = 2.7289\n",
            "Iteration 1023: Loss = 4.2786, ||Grad|| = 2.8712, ||W|| = 2.7261\n",
            "Iteration 1024: Loss = 4.2706, ||Grad|| = 2.8683, ||W|| = 2.7233\n",
            "Iteration 1025: Loss = 4.2625, ||Grad|| = 2.8654, ||W|| = 2.7205\n",
            "Iteration 1026: Loss = 4.2545, ||Grad|| = 2.8624, ||W|| = 2.7177\n",
            "Iteration 1027: Loss = 4.2465, ||Grad|| = 2.8595, ||W|| = 2.7149\n",
            "Iteration 1028: Loss = 4.2385, ||Grad|| = 2.8566, ||W|| = 2.7121\n",
            "Iteration 1029: Loss = 4.2305, ||Grad|| = 2.8537, ||W|| = 2.7093\n",
            "Iteration 1030: Loss = 4.2226, ||Grad|| = 2.8508, ||W|| = 2.7065\n",
            "Iteration 1031: Loss = 4.2146, ||Grad|| = 2.8479, ||W|| = 2.7037\n",
            "Iteration 1032: Loss = 4.2067, ||Grad|| = 2.8450, ||W|| = 2.7009\n",
            "Iteration 1033: Loss = 4.1988, ||Grad|| = 2.8421, ||W|| = 2.6981\n",
            "Iteration 1034: Loss = 4.1909, ||Grad|| = 2.8392, ||W|| = 2.6953\n",
            "Iteration 1035: Loss = 4.1830, ||Grad|| = 2.8363, ||W|| = 2.6926\n",
            "Iteration 1036: Loss = 4.1751, ||Grad|| = 2.8335, ||W|| = 2.6898\n",
            "Iteration 1037: Loss = 4.1673, ||Grad|| = 2.8306, ||W|| = 2.6870\n",
            "Iteration 1038: Loss = 4.1595, ||Grad|| = 2.8277, ||W|| = 2.6842\n",
            "Iteration 1039: Loss = 4.1516, ||Grad|| = 2.8248, ||W|| = 2.6815\n",
            "Iteration 1040: Loss = 4.1438, ||Grad|| = 2.8219, ||W|| = 2.6787\n",
            "Iteration 1041: Loss = 4.1361, ||Grad|| = 2.8191, ||W|| = 2.6759\n",
            "Iteration 1042: Loss = 4.1283, ||Grad|| = 2.8162, ||W|| = 2.6732\n",
            "Iteration 1043: Loss = 4.1205, ||Grad|| = 2.8133, ||W|| = 2.6704\n",
            "Iteration 1044: Loss = 4.1128, ||Grad|| = 2.8105, ||W|| = 2.6677\n",
            "Iteration 1045: Loss = 4.1051, ||Grad|| = 2.8076, ||W|| = 2.6649\n",
            "Iteration 1046: Loss = 4.0974, ||Grad|| = 2.8048, ||W|| = 2.6622\n",
            "Iteration 1047: Loss = 4.0897, ||Grad|| = 2.8019, ||W|| = 2.6594\n",
            "Iteration 1048: Loss = 4.0820, ||Grad|| = 2.7991, ||W|| = 2.6567\n",
            "Iteration 1049: Loss = 4.0744, ||Grad|| = 2.7962, ||W|| = 2.6539\n",
            "Iteration 1050: Loss = 4.0667, ||Grad|| = 2.7934, ||W|| = 2.6512\n",
            "Iteration 1051: Loss = 4.0591, ||Grad|| = 2.7905, ||W|| = 2.6485\n",
            "Iteration 1052: Loss = 4.0515, ||Grad|| = 2.7877, ||W|| = 2.6457\n",
            "Iteration 1053: Loss = 4.0439, ||Grad|| = 2.7848, ||W|| = 2.6430\n",
            "Iteration 1054: Loss = 4.0363, ||Grad|| = 2.7820, ||W|| = 2.6403\n",
            "Iteration 1055: Loss = 4.0288, ||Grad|| = 2.7792, ||W|| = 2.6376\n",
            "Iteration 1056: Loss = 4.0212, ||Grad|| = 2.7763, ||W|| = 2.6349\n",
            "Iteration 1057: Loss = 4.0137, ||Grad|| = 2.7735, ||W|| = 2.6321\n",
            "Iteration 1058: Loss = 4.0062, ||Grad|| = 2.7707, ||W|| = 2.6294\n",
            "Iteration 1059: Loss = 3.9987, ||Grad|| = 2.7679, ||W|| = 2.6267\n",
            "Iteration 1060: Loss = 3.9912, ||Grad|| = 2.7650, ||W|| = 2.6240\n",
            "Iteration 1061: Loss = 3.9837, ||Grad|| = 2.7622, ||W|| = 2.6213\n",
            "Iteration 1062: Loss = 3.9763, ||Grad|| = 2.7594, ||W|| = 2.6186\n",
            "Iteration 1063: Loss = 3.9689, ||Grad|| = 2.7566, ||W|| = 2.6159\n",
            "Iteration 1064: Loss = 3.9614, ||Grad|| = 2.7538, ||W|| = 2.6132\n",
            "Iteration 1065: Loss = 3.9540, ||Grad|| = 2.7510, ||W|| = 2.6105\n",
            "Iteration 1066: Loss = 3.9466, ||Grad|| = 2.7482, ||W|| = 2.6078\n",
            "Iteration 1067: Loss = 3.9393, ||Grad|| = 2.7454, ||W|| = 2.6051\n",
            "Iteration 1068: Loss = 3.9319, ||Grad|| = 2.7426, ||W|| = 2.6025\n",
            "Iteration 1069: Loss = 3.9246, ||Grad|| = 2.7398, ||W|| = 2.5998\n",
            "Iteration 1070: Loss = 3.9172, ||Grad|| = 2.7370, ||W|| = 2.5971\n",
            "Iteration 1071: Loss = 3.9099, ||Grad|| = 2.7342, ||W|| = 2.5944\n",
            "Iteration 1072: Loss = 3.9026, ||Grad|| = 2.7314, ||W|| = 2.5917\n",
            "Iteration 1073: Loss = 3.8953, ||Grad|| = 2.7286, ||W|| = 2.5891\n",
            "Iteration 1074: Loss = 3.8881, ||Grad|| = 2.7259, ||W|| = 2.5864\n",
            "Iteration 1075: Loss = 3.8808, ||Grad|| = 2.7231, ||W|| = 2.5837\n",
            "Iteration 1076: Loss = 3.8736, ||Grad|| = 2.7203, ||W|| = 2.5811\n",
            "Iteration 1077: Loss = 3.8664, ||Grad|| = 2.7175, ||W|| = 2.5784\n",
            "Iteration 1078: Loss = 3.8592, ||Grad|| = 2.7148, ||W|| = 2.5758\n",
            "Iteration 1079: Loss = 3.8520, ||Grad|| = 2.7120, ||W|| = 2.5731\n",
            "Iteration 1080: Loss = 3.8448, ||Grad|| = 2.7092, ||W|| = 2.5705\n",
            "Iteration 1081: Loss = 3.8376, ||Grad|| = 2.7065, ||W|| = 2.5678\n",
            "Iteration 1082: Loss = 3.8305, ||Grad|| = 2.7037, ||W|| = 2.5652\n",
            "Iteration 1083: Loss = 3.8233, ||Grad|| = 2.7010, ||W|| = 2.5625\n",
            "Iteration 1084: Loss = 3.8162, ||Grad|| = 2.6982, ||W|| = 2.5599\n",
            "Iteration 1085: Loss = 3.8091, ||Grad|| = 2.6955, ||W|| = 2.5572\n",
            "Iteration 1086: Loss = 3.8020, ||Grad|| = 2.6927, ||W|| = 2.5546\n",
            "Iteration 1087: Loss = 3.7950, ||Grad|| = 2.6900, ||W|| = 2.5520\n",
            "Iteration 1088: Loss = 3.7879, ||Grad|| = 2.6872, ||W|| = 2.5494\n",
            "Iteration 1089: Loss = 3.7808, ||Grad|| = 2.6845, ||W|| = 2.5467\n",
            "Iteration 1090: Loss = 3.7738, ||Grad|| = 2.6817, ||W|| = 2.5441\n",
            "Iteration 1091: Loss = 3.7668, ||Grad|| = 2.6790, ||W|| = 2.5415\n",
            "Iteration 1092: Loss = 3.7598, ||Grad|| = 2.6763, ||W|| = 2.5389\n",
            "Iteration 1093: Loss = 3.7528, ||Grad|| = 2.6735, ||W|| = 2.5363\n",
            "Iteration 1094: Loss = 3.7458, ||Grad|| = 2.6708, ||W|| = 2.5336\n",
            "Iteration 1095: Loss = 3.7389, ||Grad|| = 2.6681, ||W|| = 2.5310\n",
            "Iteration 1096: Loss = 3.7319, ||Grad|| = 2.6654, ||W|| = 2.5284\n",
            "Iteration 1097: Loss = 3.7250, ||Grad|| = 2.6627, ||W|| = 2.5258\n",
            "Iteration 1098: Loss = 3.7181, ||Grad|| = 2.6599, ||W|| = 2.5232\n",
            "Iteration 1099: Loss = 3.7112, ||Grad|| = 2.6572, ||W|| = 2.5206\n",
            "Iteration 1100: Loss = 3.7043, ||Grad|| = 2.6545, ||W|| = 2.5180\n",
            "Iteration 1101: Loss = 3.6974, ||Grad|| = 2.6518, ||W|| = 2.5154\n",
            "Iteration 1102: Loss = 3.6906, ||Grad|| = 2.6491, ||W|| = 2.5128\n",
            "Iteration 1103: Loss = 3.6837, ||Grad|| = 2.6464, ||W|| = 2.5103\n",
            "Iteration 1104: Loss = 3.6769, ||Grad|| = 2.6437, ||W|| = 2.5077\n",
            "Iteration 1105: Loss = 3.6701, ||Grad|| = 2.6410, ||W|| = 2.5051\n",
            "Iteration 1106: Loss = 3.6633, ||Grad|| = 2.6383, ||W|| = 2.5025\n",
            "Iteration 1107: Loss = 3.6565, ||Grad|| = 2.6356, ||W|| = 2.4999\n",
            "Iteration 1108: Loss = 3.6497, ||Grad|| = 2.6329, ||W|| = 2.4974\n",
            "Iteration 1109: Loss = 3.6430, ||Grad|| = 2.6302, ||W|| = 2.4948\n",
            "Iteration 1110: Loss = 3.6362, ||Grad|| = 2.6276, ||W|| = 2.4922\n",
            "Iteration 1111: Loss = 3.6295, ||Grad|| = 2.6249, ||W|| = 2.4897\n",
            "Iteration 1112: Loss = 3.6228, ||Grad|| = 2.6222, ||W|| = 2.4871\n",
            "Iteration 1113: Loss = 3.6161, ||Grad|| = 2.6195, ||W|| = 2.4845\n",
            "Iteration 1114: Loss = 3.6094, ||Grad|| = 2.6168, ||W|| = 2.4820\n",
            "Iteration 1115: Loss = 3.6027, ||Grad|| = 2.6142, ||W|| = 2.4794\n",
            "Iteration 1116: Loss = 3.5961, ||Grad|| = 2.6115, ||W|| = 2.4769\n",
            "Iteration 1117: Loss = 3.5894, ||Grad|| = 2.6088, ||W|| = 2.4743\n",
            "Iteration 1118: Loss = 3.5828, ||Grad|| = 2.6062, ||W|| = 2.4718\n",
            "Iteration 1119: Loss = 3.5762, ||Grad|| = 2.6035, ||W|| = 2.4692\n",
            "Iteration 1120: Loss = 3.5696, ||Grad|| = 2.6009, ||W|| = 2.4667\n",
            "Iteration 1121: Loss = 3.5630, ||Grad|| = 2.5982, ||W|| = 2.4642\n",
            "Iteration 1122: Loss = 3.5564, ||Grad|| = 2.5955, ||W|| = 2.4616\n",
            "Iteration 1123: Loss = 3.5498, ||Grad|| = 2.5929, ||W|| = 2.4591\n",
            "Iteration 1124: Loss = 3.5433, ||Grad|| = 2.5902, ||W|| = 2.4566\n",
            "Iteration 1125: Loss = 3.5367, ||Grad|| = 2.5876, ||W|| = 2.4540\n",
            "Iteration 1126: Loss = 3.5302, ||Grad|| = 2.5850, ||W|| = 2.4515\n",
            "Iteration 1127: Loss = 3.5237, ||Grad|| = 2.5823, ||W|| = 2.4490\n",
            "Iteration 1128: Loss = 3.5172, ||Grad|| = 2.5797, ||W|| = 2.4465\n",
            "Iteration 1129: Loss = 3.5107, ||Grad|| = 2.5770, ||W|| = 2.4439\n",
            "Iteration 1130: Loss = 3.5042, ||Grad|| = 2.5744, ||W|| = 2.4414\n",
            "Iteration 1131: Loss = 3.4978, ||Grad|| = 2.5718, ||W|| = 2.4389\n",
            "Iteration 1132: Loss = 3.4914, ||Grad|| = 2.5692, ||W|| = 2.4364\n",
            "Iteration 1133: Loss = 3.4849, ||Grad|| = 2.5665, ||W|| = 2.4339\n",
            "Iteration 1134: Loss = 3.4785, ||Grad|| = 2.5639, ||W|| = 2.4314\n",
            "Iteration 1135: Loss = 3.4721, ||Grad|| = 2.5613, ||W|| = 2.4289\n",
            "Iteration 1136: Loss = 3.4657, ||Grad|| = 2.5587, ||W|| = 2.4264\n",
            "Iteration 1137: Loss = 3.4593, ||Grad|| = 2.5561, ||W|| = 2.4239\n",
            "Iteration 1138: Loss = 3.4530, ||Grad|| = 2.5534, ||W|| = 2.4214\n",
            "Iteration 1139: Loss = 3.4466, ||Grad|| = 2.5508, ||W|| = 2.4189\n",
            "Iteration 1140: Loss = 3.4403, ||Grad|| = 2.5482, ||W|| = 2.4164\n",
            "Iteration 1141: Loss = 3.4340, ||Grad|| = 2.5456, ||W|| = 2.4140\n",
            "Iteration 1142: Loss = 3.4277, ||Grad|| = 2.5430, ||W|| = 2.4115\n",
            "Iteration 1143: Loss = 3.4214, ||Grad|| = 2.5404, ||W|| = 2.4090\n",
            "Iteration 1144: Loss = 3.4151, ||Grad|| = 2.5378, ||W|| = 2.4065\n",
            "Iteration 1145: Loss = 3.4088, ||Grad|| = 2.5352, ||W|| = 2.4040\n",
            "Iteration 1146: Loss = 3.4026, ||Grad|| = 2.5326, ||W|| = 2.4016\n",
            "Iteration 1147: Loss = 3.3963, ||Grad|| = 2.5301, ||W|| = 2.3991\n",
            "Iteration 1148: Loss = 3.3901, ||Grad|| = 2.5275, ||W|| = 2.3966\n",
            "Iteration 1149: Loss = 3.3839, ||Grad|| = 2.5249, ||W|| = 2.3942\n",
            "Iteration 1150: Loss = 3.3777, ||Grad|| = 2.5223, ||W|| = 2.3917\n",
            "Iteration 1151: Loss = 3.3715, ||Grad|| = 2.5197, ||W|| = 2.3893\n",
            "Iteration 1152: Loss = 3.3653, ||Grad|| = 2.5172, ||W|| = 2.3868\n",
            "Iteration 1153: Loss = 3.3591, ||Grad|| = 2.5146, ||W|| = 2.3843\n",
            "Iteration 1154: Loss = 3.3530, ||Grad|| = 2.5120, ||W|| = 2.3819\n",
            "Iteration 1155: Loss = 3.3468, ||Grad|| = 2.5094, ||W|| = 2.3794\n",
            "Iteration 1156: Loss = 3.3407, ||Grad|| = 2.5069, ||W|| = 2.3770\n",
            "Iteration 1157: Loss = 3.3346, ||Grad|| = 2.5043, ||W|| = 2.3746\n",
            "Iteration 1158: Loss = 3.3285, ||Grad|| = 2.5017, ||W|| = 2.3721\n",
            "Iteration 1159: Loss = 3.3224, ||Grad|| = 2.4992, ||W|| = 2.3697\n",
            "Iteration 1160: Loss = 3.3163, ||Grad|| = 2.4966, ||W|| = 2.3672\n",
            "Iteration 1161: Loss = 3.3102, ||Grad|| = 2.4941, ||W|| = 2.3648\n",
            "Iteration 1162: Loss = 3.3042, ||Grad|| = 2.4915, ||W|| = 2.3624\n",
            "Iteration 1163: Loss = 3.2982, ||Grad|| = 2.4890, ||W|| = 2.3600\n",
            "Iteration 1164: Loss = 3.2921, ||Grad|| = 2.4864, ||W|| = 2.3575\n",
            "Iteration 1165: Loss = 3.2861, ||Grad|| = 2.4839, ||W|| = 2.3551\n",
            "Iteration 1166: Loss = 3.2801, ||Grad|| = 2.4813, ||W|| = 2.3527\n",
            "Iteration 1167: Loss = 3.2741, ||Grad|| = 2.4788, ||W|| = 2.3503\n",
            "Iteration 1168: Loss = 3.2681, ||Grad|| = 2.4763, ||W|| = 2.3479\n",
            "Iteration 1169: Loss = 3.2622, ||Grad|| = 2.4737, ||W|| = 2.3454\n",
            "Iteration 1170: Loss = 3.2562, ||Grad|| = 2.4712, ||W|| = 2.3430\n",
            "Iteration 1171: Loss = 3.2503, ||Grad|| = 2.4687, ||W|| = 2.3406\n",
            "Iteration 1172: Loss = 3.2444, ||Grad|| = 2.4662, ||W|| = 2.3382\n",
            "Iteration 1173: Loss = 3.2385, ||Grad|| = 2.4636, ||W|| = 2.3358\n",
            "Iteration 1174: Loss = 3.2326, ||Grad|| = 2.4611, ||W|| = 2.3334\n",
            "Iteration 1175: Loss = 3.2267, ||Grad|| = 2.4586, ||W|| = 2.3310\n",
            "Iteration 1176: Loss = 3.2208, ||Grad|| = 2.4561, ||W|| = 2.3286\n",
            "Iteration 1177: Loss = 3.2149, ||Grad|| = 2.4536, ||W|| = 2.3262\n",
            "Iteration 1178: Loss = 3.2091, ||Grad|| = 2.4510, ||W|| = 2.3239\n",
            "Iteration 1179: Loss = 3.2032, ||Grad|| = 2.4485, ||W|| = 2.3215\n",
            "Iteration 1180: Loss = 3.1974, ||Grad|| = 2.4460, ||W|| = 2.3191\n",
            "Iteration 1181: Loss = 3.1916, ||Grad|| = 2.4435, ||W|| = 2.3167\n",
            "Iteration 1182: Loss = 3.1858, ||Grad|| = 2.4410, ||W|| = 2.3143\n",
            "Iteration 1183: Loss = 3.1800, ||Grad|| = 2.4385, ||W|| = 2.3119\n",
            "Iteration 1184: Loss = 3.1742, ||Grad|| = 2.4360, ||W|| = 2.3096\n",
            "Iteration 1185: Loss = 3.1684, ||Grad|| = 2.4335, ||W|| = 2.3072\n",
            "Iteration 1186: Loss = 3.1627, ||Grad|| = 2.4310, ||W|| = 2.3048\n",
            "Iteration 1187: Loss = 3.1569, ||Grad|| = 2.4286, ||W|| = 2.3025\n",
            "Iteration 1188: Loss = 3.1512, ||Grad|| = 2.4261, ||W|| = 2.3001\n",
            "Iteration 1189: Loss = 3.1455, ||Grad|| = 2.4236, ||W|| = 2.2977\n",
            "Iteration 1190: Loss = 3.1398, ||Grad|| = 2.4211, ||W|| = 2.2954\n",
            "Iteration 1191: Loss = 3.1341, ||Grad|| = 2.4186, ||W|| = 2.2930\n",
            "Iteration 1192: Loss = 3.1284, ||Grad|| = 2.4161, ||W|| = 2.2907\n",
            "Iteration 1193: Loss = 3.1227, ||Grad|| = 2.4137, ||W|| = 2.2883\n",
            "Iteration 1194: Loss = 3.1171, ||Grad|| = 2.4112, ||W|| = 2.2860\n",
            "Iteration 1195: Loss = 3.1114, ||Grad|| = 2.4087, ||W|| = 2.2836\n",
            "Iteration 1196: Loss = 3.1058, ||Grad|| = 2.4063, ||W|| = 2.2813\n",
            "Iteration 1197: Loss = 3.1002, ||Grad|| = 2.4038, ||W|| = 2.2789\n",
            "Iteration 1198: Loss = 3.0945, ||Grad|| = 2.4013, ||W|| = 2.2766\n",
            "Iteration 1199: Loss = 3.0889, ||Grad|| = 2.3989, ||W|| = 2.2743\n",
            "Iteration 1200: Loss = 3.0834, ||Grad|| = 2.3964, ||W|| = 2.2719\n",
            "Iteration 1201: Loss = 3.0778, ||Grad|| = 2.3940, ||W|| = 2.2696\n",
            "Iteration 1202: Loss = 3.0722, ||Grad|| = 2.3915, ||W|| = 2.2673\n",
            "Iteration 1203: Loss = 3.0667, ||Grad|| = 2.3891, ||W|| = 2.2650\n",
            "Iteration 1204: Loss = 3.0611, ||Grad|| = 2.3866, ||W|| = 2.2626\n",
            "Iteration 1205: Loss = 3.0556, ||Grad|| = 2.3842, ||W|| = 2.2603\n",
            "Iteration 1206: Loss = 3.0501, ||Grad|| = 2.3817, ||W|| = 2.2580\n",
            "Iteration 1207: Loss = 3.0446, ||Grad|| = 2.3793, ||W|| = 2.2557\n",
            "Iteration 1208: Loss = 3.0391, ||Grad|| = 2.3768, ||W|| = 2.2534\n",
            "Iteration 1209: Loss = 3.0336, ||Grad|| = 2.3744, ||W|| = 2.2511\n",
            "Iteration 1210: Loss = 3.0281, ||Grad|| = 2.3720, ||W|| = 2.2487\n",
            "Iteration 1211: Loss = 3.0226, ||Grad|| = 2.3695, ||W|| = 2.2464\n",
            "Iteration 1212: Loss = 3.0172, ||Grad|| = 2.3671, ||W|| = 2.2441\n",
            "Iteration 1213: Loss = 3.0117, ||Grad|| = 2.3647, ||W|| = 2.2418\n",
            "Iteration 1214: Loss = 3.0063, ||Grad|| = 2.3623, ||W|| = 2.2395\n",
            "Iteration 1215: Loss = 3.0009, ||Grad|| = 2.3598, ||W|| = 2.2372\n",
            "Iteration 1216: Loss = 2.9955, ||Grad|| = 2.3574, ||W|| = 2.2349\n",
            "Iteration 1217: Loss = 2.9901, ||Grad|| = 2.3550, ||W|| = 2.2327\n",
            "Iteration 1218: Loss = 2.9847, ||Grad|| = 2.3526, ||W|| = 2.2304\n",
            "Iteration 1219: Loss = 2.9793, ||Grad|| = 2.3502, ||W|| = 2.2281\n",
            "Iteration 1220: Loss = 2.9740, ||Grad|| = 2.3478, ||W|| = 2.2258\n",
            "Iteration 1221: Loss = 2.9686, ||Grad|| = 2.3454, ||W|| = 2.2235\n",
            "Iteration 1222: Loss = 2.9633, ||Grad|| = 2.3430, ||W|| = 2.2212\n",
            "Iteration 1223: Loss = 2.9580, ||Grad|| = 2.3405, ||W|| = 2.2190\n",
            "Iteration 1224: Loss = 2.9527, ||Grad|| = 2.3381, ||W|| = 2.2167\n",
            "Iteration 1225: Loss = 2.9474, ||Grad|| = 2.3358, ||W|| = 2.2144\n",
            "Iteration 1226: Loss = 2.9421, ||Grad|| = 2.3334, ||W|| = 2.2121\n",
            "Iteration 1227: Loss = 2.9368, ||Grad|| = 2.3310, ||W|| = 2.2099\n",
            "Iteration 1228: Loss = 2.9315, ||Grad|| = 2.3286, ||W|| = 2.2076\n",
            "Iteration 1229: Loss = 2.9262, ||Grad|| = 2.3262, ||W|| = 2.2053\n",
            "Iteration 1230: Loss = 2.9210, ||Grad|| = 2.3238, ||W|| = 2.2031\n",
            "Iteration 1231: Loss = 2.9158, ||Grad|| = 2.3214, ||W|| = 2.2008\n",
            "Iteration 1232: Loss = 2.9105, ||Grad|| = 2.3190, ||W|| = 2.1986\n",
            "Iteration 1233: Loss = 2.9053, ||Grad|| = 2.3167, ||W|| = 2.1963\n",
            "Iteration 1234: Loss = 2.9001, ||Grad|| = 2.3143, ||W|| = 2.1941\n",
            "Iteration 1235: Loss = 2.8949, ||Grad|| = 2.3119, ||W|| = 2.1918\n",
            "Iteration 1236: Loss = 2.8897, ||Grad|| = 2.3095, ||W|| = 2.1896\n",
            "Iteration 1237: Loss = 2.8846, ||Grad|| = 2.3072, ||W|| = 2.1873\n",
            "Iteration 1238: Loss = 2.8794, ||Grad|| = 2.3048, ||W|| = 2.1851\n",
            "Iteration 1239: Loss = 2.8742, ||Grad|| = 2.3024, ||W|| = 2.1829\n",
            "Iteration 1240: Loss = 2.8691, ||Grad|| = 2.3001, ||W|| = 2.1806\n",
            "Iteration 1241: Loss = 2.8640, ||Grad|| = 2.2977, ||W|| = 2.1784\n",
            "Iteration 1242: Loss = 2.8589, ||Grad|| = 2.2953, ||W|| = 2.1762\n",
            "Iteration 1243: Loss = 2.8538, ||Grad|| = 2.2930, ||W|| = 2.1739\n",
            "Iteration 1244: Loss = 2.8487, ||Grad|| = 2.2906, ||W|| = 2.1717\n",
            "Iteration 1245: Loss = 2.8436, ||Grad|| = 2.2883, ||W|| = 2.1695\n",
            "Iteration 1246: Loss = 2.8385, ||Grad|| = 2.2859, ||W|| = 2.1673\n",
            "Iteration 1247: Loss = 2.8334, ||Grad|| = 2.2836, ||W|| = 2.1650\n",
            "Iteration 1248: Loss = 2.8284, ||Grad|| = 2.2812, ||W|| = 2.1628\n",
            "Iteration 1249: Loss = 2.8233, ||Grad|| = 2.2789, ||W|| = 2.1606\n",
            "Iteration 1250: Loss = 2.8183, ||Grad|| = 2.2766, ||W|| = 2.1584\n",
            "Iteration 1251: Loss = 2.8133, ||Grad|| = 2.2742, ||W|| = 2.1562\n",
            "Iteration 1252: Loss = 2.8083, ||Grad|| = 2.2719, ||W|| = 2.1540\n",
            "Iteration 1253: Loss = 2.8033, ||Grad|| = 2.2696, ||W|| = 2.1518\n",
            "Iteration 1254: Loss = 2.7983, ||Grad|| = 2.2672, ||W|| = 2.1496\n",
            "Iteration 1255: Loss = 2.7933, ||Grad|| = 2.2649, ||W|| = 2.1474\n",
            "Iteration 1256: Loss = 2.7883, ||Grad|| = 2.2626, ||W|| = 2.1452\n",
            "Iteration 1257: Loss = 2.7834, ||Grad|| = 2.2602, ||W|| = 2.1430\n",
            "Iteration 1258: Loss = 2.7784, ||Grad|| = 2.2579, ||W|| = 2.1408\n",
            "Iteration 1259: Loss = 2.7735, ||Grad|| = 2.2556, ||W|| = 2.1386\n",
            "Iteration 1260: Loss = 2.7685, ||Grad|| = 2.2533, ||W|| = 2.1364\n",
            "Iteration 1261: Loss = 2.7636, ||Grad|| = 2.2510, ||W|| = 2.1342\n",
            "Iteration 1262: Loss = 2.7587, ||Grad|| = 2.2487, ||W|| = 2.1321\n",
            "Iteration 1263: Loss = 2.7538, ||Grad|| = 2.2463, ||W|| = 2.1299\n",
            "Iteration 1264: Loss = 2.7489, ||Grad|| = 2.2440, ||W|| = 2.1277\n",
            "Iteration 1265: Loss = 2.7441, ||Grad|| = 2.2417, ||W|| = 2.1255\n",
            "Iteration 1266: Loss = 2.7392, ||Grad|| = 2.2394, ||W|| = 2.1233\n",
            "Iteration 1267: Loss = 2.7343, ||Grad|| = 2.2371, ||W|| = 2.1212\n",
            "Iteration 1268: Loss = 2.7295, ||Grad|| = 2.2348, ||W|| = 2.1190\n",
            "Iteration 1269: Loss = 2.7246, ||Grad|| = 2.2325, ||W|| = 2.1168\n",
            "Iteration 1270: Loss = 2.7198, ||Grad|| = 2.2302, ||W|| = 2.1147\n",
            "Iteration 1271: Loss = 2.7150, ||Grad|| = 2.2279, ||W|| = 2.1125\n",
            "Iteration 1272: Loss = 2.7102, ||Grad|| = 2.2257, ||W|| = 2.1104\n",
            "Iteration 1273: Loss = 2.7054, ||Grad|| = 2.2234, ||W|| = 2.1082\n",
            "Iteration 1274: Loss = 2.7006, ||Grad|| = 2.2211, ||W|| = 2.1060\n",
            "Iteration 1275: Loss = 2.6958, ||Grad|| = 2.2188, ||W|| = 2.1039\n",
            "Iteration 1276: Loss = 2.6911, ||Grad|| = 2.2165, ||W|| = 2.1017\n",
            "Iteration 1277: Loss = 2.6863, ||Grad|| = 2.2142, ||W|| = 2.0996\n",
            "Iteration 1278: Loss = 2.6816, ||Grad|| = 2.2120, ||W|| = 2.0975\n",
            "Iteration 1279: Loss = 2.6768, ||Grad|| = 2.2097, ||W|| = 2.0953\n",
            "Iteration 1280: Loss = 2.6721, ||Grad|| = 2.2074, ||W|| = 2.0932\n",
            "Iteration 1281: Loss = 2.6674, ||Grad|| = 2.2051, ||W|| = 2.0910\n",
            "Iteration 1282: Loss = 2.6627, ||Grad|| = 2.2029, ||W|| = 2.0889\n",
            "Iteration 1283: Loss = 2.6580, ||Grad|| = 2.2006, ||W|| = 2.0868\n",
            "Iteration 1284: Loss = 2.6533, ||Grad|| = 2.1984, ||W|| = 2.0846\n",
            "Iteration 1285: Loss = 2.6486, ||Grad|| = 2.1961, ||W|| = 2.0825\n",
            "Iteration 1286: Loss = 2.6440, ||Grad|| = 2.1938, ||W|| = 2.0804\n",
            "Iteration 1287: Loss = 2.6393, ||Grad|| = 2.1916, ||W|| = 2.0782\n",
            "Iteration 1288: Loss = 2.6347, ||Grad|| = 2.1893, ||W|| = 2.0761\n",
            "Iteration 1289: Loss = 2.6300, ||Grad|| = 2.1871, ||W|| = 2.0740\n",
            "Iteration 1290: Loss = 2.6254, ||Grad|| = 2.1848, ||W|| = 2.0719\n",
            "Iteration 1291: Loss = 2.6208, ||Grad|| = 2.1826, ||W|| = 2.0698\n",
            "Iteration 1292: Loss = 2.6162, ||Grad|| = 2.1803, ||W|| = 2.0677\n",
            "Iteration 1293: Loss = 2.6116, ||Grad|| = 2.1781, ||W|| = 2.0655\n",
            "Iteration 1294: Loss = 2.6070, ||Grad|| = 2.1758, ||W|| = 2.0634\n",
            "Iteration 1295: Loss = 2.6024, ||Grad|| = 2.1736, ||W|| = 2.0613\n",
            "Iteration 1296: Loss = 2.5978, ||Grad|| = 2.1714, ||W|| = 2.0592\n",
            "Iteration 1297: Loss = 2.5933, ||Grad|| = 2.1691, ||W|| = 2.0571\n",
            "Iteration 1298: Loss = 2.5887, ||Grad|| = 2.1669, ||W|| = 2.0550\n",
            "Iteration 1299: Loss = 2.5842, ||Grad|| = 2.1647, ||W|| = 2.0529\n",
            "Iteration 1300: Loss = 2.5797, ||Grad|| = 2.1624, ||W|| = 2.0508\n",
            "Iteration 1301: Loss = 2.5751, ||Grad|| = 2.1602, ||W|| = 2.0487\n",
            "Iteration 1302: Loss = 2.5706, ||Grad|| = 2.1580, ||W|| = 2.0466\n",
            "Iteration 1303: Loss = 2.5661, ||Grad|| = 2.1558, ||W|| = 2.0446\n",
            "Iteration 1304: Loss = 2.5616, ||Grad|| = 2.1536, ||W|| = 2.0425\n",
            "Iteration 1305: Loss = 2.5572, ||Grad|| = 2.1513, ||W|| = 2.0404\n",
            "Iteration 1306: Loss = 2.5527, ||Grad|| = 2.1491, ||W|| = 2.0383\n",
            "Iteration 1307: Loss = 2.5482, ||Grad|| = 2.1469, ||W|| = 2.0362\n",
            "Iteration 1308: Loss = 2.5438, ||Grad|| = 2.1447, ||W|| = 2.0342\n",
            "Iteration 1309: Loss = 2.5393, ||Grad|| = 2.1425, ||W|| = 2.0321\n",
            "Iteration 1310: Loss = 2.5349, ||Grad|| = 2.1403, ||W|| = 2.0300\n",
            "Iteration 1311: Loss = 2.5305, ||Grad|| = 2.1381, ||W|| = 2.0279\n",
            "Iteration 1312: Loss = 2.5260, ||Grad|| = 2.1359, ||W|| = 2.0259\n",
            "Iteration 1313: Loss = 2.5216, ||Grad|| = 2.1337, ||W|| = 2.0238\n",
            "Iteration 1314: Loss = 2.5172, ||Grad|| = 2.1315, ||W|| = 2.0217\n",
            "Iteration 1315: Loss = 2.5128, ||Grad|| = 2.1293, ||W|| = 2.0197\n",
            "Iteration 1316: Loss = 2.5085, ||Grad|| = 2.1271, ||W|| = 2.0176\n",
            "Iteration 1317: Loss = 2.5041, ||Grad|| = 2.1249, ||W|| = 2.0156\n",
            "Iteration 1318: Loss = 2.4997, ||Grad|| = 2.1227, ||W|| = 2.0135\n",
            "Iteration 1319: Loss = 2.4954, ||Grad|| = 2.1205, ||W|| = 2.0115\n",
            "Iteration 1320: Loss = 2.4910, ||Grad|| = 2.1184, ||W|| = 2.0094\n",
            "Iteration 1321: Loss = 2.4867, ||Grad|| = 2.1162, ||W|| = 2.0074\n",
            "Iteration 1322: Loss = 2.4824, ||Grad|| = 2.1140, ||W|| = 2.0053\n",
            "Iteration 1323: Loss = 2.4781, ||Grad|| = 2.1118, ||W|| = 2.0033\n",
            "Iteration 1324: Loss = 2.4738, ||Grad|| = 2.1096, ||W|| = 2.0012\n",
            "Iteration 1325: Loss = 2.4695, ||Grad|| = 2.1075, ||W|| = 1.9992\n",
            "Iteration 1326: Loss = 2.4652, ||Grad|| = 2.1053, ||W|| = 1.9972\n",
            "Iteration 1327: Loss = 2.4609, ||Grad|| = 2.1031, ||W|| = 1.9951\n",
            "Iteration 1328: Loss = 2.4566, ||Grad|| = 2.1010, ||W|| = 1.9931\n",
            "Iteration 1329: Loss = 2.4524, ||Grad|| = 2.0988, ||W|| = 1.9911\n",
            "Iteration 1330: Loss = 2.4481, ||Grad|| = 2.0966, ||W|| = 1.9890\n",
            "Iteration 1331: Loss = 2.4439, ||Grad|| = 2.0945, ||W|| = 1.9870\n",
            "Iteration 1332: Loss = 2.4396, ||Grad|| = 2.0923, ||W|| = 1.9850\n",
            "Iteration 1333: Loss = 2.4354, ||Grad|| = 2.0902, ||W|| = 1.9830\n",
            "Iteration 1334: Loss = 2.4312, ||Grad|| = 2.0880, ||W|| = 1.9809\n",
            "Iteration 1335: Loss = 2.4270, ||Grad|| = 2.0859, ||W|| = 1.9789\n",
            "Iteration 1336: Loss = 2.4228, ||Grad|| = 2.0837, ||W|| = 1.9769\n",
            "Iteration 1337: Loss = 2.4186, ||Grad|| = 2.0816, ||W|| = 1.9749\n",
            "Iteration 1338: Loss = 2.4144, ||Grad|| = 2.0794, ||W|| = 1.9729\n",
            "Iteration 1339: Loss = 2.4102, ||Grad|| = 2.0773, ||W|| = 1.9709\n",
            "Iteration 1340: Loss = 2.4061, ||Grad|| = 2.0751, ||W|| = 1.9689\n",
            "Iteration 1341: Loss = 2.4019, ||Grad|| = 2.0730, ||W|| = 1.9669\n",
            "Iteration 1342: Loss = 2.3978, ||Grad|| = 2.0709, ||W|| = 1.9649\n",
            "Iteration 1343: Loss = 2.3936, ||Grad|| = 2.0687, ||W|| = 1.9629\n",
            "Iteration 1344: Loss = 2.3895, ||Grad|| = 2.0666, ||W|| = 1.9609\n",
            "Iteration 1345: Loss = 2.3854, ||Grad|| = 2.0645, ||W|| = 1.9589\n",
            "Iteration 1346: Loss = 2.3813, ||Grad|| = 2.0623, ||W|| = 1.9569\n",
            "Iteration 1347: Loss = 2.3772, ||Grad|| = 2.0602, ||W|| = 1.9549\n",
            "Iteration 1348: Loss = 2.3731, ||Grad|| = 2.0581, ||W|| = 1.9529\n",
            "Iteration 1349: Loss = 2.3690, ||Grad|| = 2.0560, ||W|| = 1.9509\n",
            "Iteration 1350: Loss = 2.3649, ||Grad|| = 2.0538, ||W|| = 1.9489\n",
            "Iteration 1351: Loss = 2.3608, ||Grad|| = 2.0517, ||W|| = 1.9469\n",
            "Iteration 1352: Loss = 2.3568, ||Grad|| = 2.0496, ||W|| = 1.9450\n",
            "Iteration 1353: Loss = 2.3527, ||Grad|| = 2.0475, ||W|| = 1.9430\n",
            "Iteration 1354: Loss = 2.3487, ||Grad|| = 2.0454, ||W|| = 1.9410\n",
            "Iteration 1355: Loss = 2.3447, ||Grad|| = 2.0433, ||W|| = 1.9390\n",
            "Iteration 1356: Loss = 2.3406, ||Grad|| = 2.0412, ||W|| = 1.9371\n",
            "Iteration 1357: Loss = 2.3366, ||Grad|| = 2.0390, ||W|| = 1.9351\n",
            "Iteration 1358: Loss = 2.3326, ||Grad|| = 2.0369, ||W|| = 1.9331\n",
            "Iteration 1359: Loss = 2.3286, ||Grad|| = 2.0348, ||W|| = 1.9312\n",
            "Iteration 1360: Loss = 2.3246, ||Grad|| = 2.0327, ||W|| = 1.9292\n",
            "Iteration 1361: Loss = 2.3206, ||Grad|| = 2.0306, ||W|| = 1.9272\n",
            "Iteration 1362: Loss = 2.3167, ||Grad|| = 2.0286, ||W|| = 1.9253\n",
            "Iteration 1363: Loss = 2.3127, ||Grad|| = 2.0265, ||W|| = 1.9233\n",
            "Iteration 1364: Loss = 2.3087, ||Grad|| = 2.0244, ||W|| = 1.9214\n",
            "Iteration 1365: Loss = 2.3048, ||Grad|| = 2.0223, ||W|| = 1.9194\n",
            "Iteration 1366: Loss = 2.3009, ||Grad|| = 2.0202, ||W|| = 1.9175\n",
            "Iteration 1367: Loss = 2.2969, ||Grad|| = 2.0181, ||W|| = 1.9155\n",
            "Iteration 1368: Loss = 2.2930, ||Grad|| = 2.0160, ||W|| = 1.9136\n",
            "Iteration 1369: Loss = 2.2891, ||Grad|| = 2.0139, ||W|| = 1.9116\n",
            "Iteration 1370: Loss = 2.2852, ||Grad|| = 2.0119, ||W|| = 1.9097\n",
            "Iteration 1371: Loss = 2.2813, ||Grad|| = 2.0098, ||W|| = 1.9078\n",
            "Iteration 1372: Loss = 2.2774, ||Grad|| = 2.0077, ||W|| = 1.9058\n",
            "Iteration 1373: Loss = 2.2735, ||Grad|| = 2.0056, ||W|| = 1.9039\n",
            "Iteration 1374: Loss = 2.2696, ||Grad|| = 2.0036, ||W|| = 1.9020\n",
            "Iteration 1375: Loss = 2.2658, ||Grad|| = 2.0015, ||W|| = 1.9000\n",
            "Iteration 1376: Loss = 2.2619, ||Grad|| = 1.9994, ||W|| = 1.8981\n",
            "Iteration 1377: Loss = 2.2581, ||Grad|| = 1.9974, ||W|| = 1.8962\n",
            "Iteration 1378: Loss = 2.2542, ||Grad|| = 1.9953, ||W|| = 1.8942\n",
            "Iteration 1379: Loss = 2.2504, ||Grad|| = 1.9933, ||W|| = 1.8923\n",
            "Iteration 1380: Loss = 2.2466, ||Grad|| = 1.9912, ||W|| = 1.8904\n",
            "Iteration 1381: Loss = 2.2427, ||Grad|| = 1.9891, ||W|| = 1.8885\n",
            "Iteration 1382: Loss = 2.2389, ||Grad|| = 1.9871, ||W|| = 1.8866\n",
            "Iteration 1383: Loss = 2.2351, ||Grad|| = 1.9850, ||W|| = 1.8847\n",
            "Iteration 1384: Loss = 2.2313, ||Grad|| = 1.9830, ||W|| = 1.8827\n",
            "Iteration 1385: Loss = 2.2275, ||Grad|| = 1.9809, ||W|| = 1.8808\n",
            "Iteration 1386: Loss = 2.2238, ||Grad|| = 1.9789, ||W|| = 1.8789\n",
            "Iteration 1387: Loss = 2.2200, ||Grad|| = 1.9768, ||W|| = 1.8770\n",
            "Iteration 1388: Loss = 2.2162, ||Grad|| = 1.9748, ||W|| = 1.8751\n",
            "Iteration 1389: Loss = 2.2125, ||Grad|| = 1.9728, ||W|| = 1.8732\n",
            "Iteration 1390: Loss = 2.2087, ||Grad|| = 1.9707, ||W|| = 1.8713\n",
            "Iteration 1391: Loss = 2.2050, ||Grad|| = 1.9687, ||W|| = 1.8694\n",
            "Iteration 1392: Loss = 2.2013, ||Grad|| = 1.9667, ||W|| = 1.8675\n",
            "Iteration 1393: Loss = 2.1976, ||Grad|| = 1.9646, ||W|| = 1.8656\n",
            "Iteration 1394: Loss = 2.1938, ||Grad|| = 1.9626, ||W|| = 1.8637\n",
            "Iteration 1395: Loss = 2.1901, ||Grad|| = 1.9606, ||W|| = 1.8619\n",
            "Iteration 1396: Loss = 2.1864, ||Grad|| = 1.9585, ||W|| = 1.8600\n",
            "Iteration 1397: Loss = 2.1827, ||Grad|| = 1.9565, ||W|| = 1.8581\n",
            "Iteration 1398: Loss = 2.1791, ||Grad|| = 1.9545, ||W|| = 1.8562\n",
            "Iteration 1399: Loss = 2.1754, ||Grad|| = 1.9525, ||W|| = 1.8543\n",
            "Iteration 1400: Loss = 2.1717, ||Grad|| = 1.9505, ||W|| = 1.8524\n",
            "Iteration 1401: Loss = 2.1681, ||Grad|| = 1.9484, ||W|| = 1.8506\n",
            "Iteration 1402: Loss = 2.1644, ||Grad|| = 1.9464, ||W|| = 1.8487\n",
            "Iteration 1403: Loss = 2.1608, ||Grad|| = 1.9444, ||W|| = 1.8468\n",
            "Iteration 1404: Loss = 2.1571, ||Grad|| = 1.9424, ||W|| = 1.8449\n",
            "Iteration 1405: Loss = 2.1535, ||Grad|| = 1.9404, ||W|| = 1.8431\n",
            "Iteration 1406: Loss = 2.1499, ||Grad|| = 1.9384, ||W|| = 1.8412\n",
            "Iteration 1407: Loss = 2.1463, ||Grad|| = 1.9364, ||W|| = 1.8393\n",
            "Iteration 1408: Loss = 2.1427, ||Grad|| = 1.9344, ||W|| = 1.8375\n",
            "Iteration 1409: Loss = 2.1391, ||Grad|| = 1.9324, ||W|| = 1.8356\n",
            "Iteration 1410: Loss = 2.1355, ||Grad|| = 1.9304, ||W|| = 1.8338\n",
            "Iteration 1411: Loss = 2.1319, ||Grad|| = 1.9284, ||W|| = 1.8319\n",
            "Iteration 1412: Loss = 2.1283, ||Grad|| = 1.9264, ||W|| = 1.8301\n",
            "Iteration 1413: Loss = 2.1248, ||Grad|| = 1.9244, ||W|| = 1.8282\n",
            "Iteration 1414: Loss = 2.1212, ||Grad|| = 1.9224, ||W|| = 1.8264\n",
            "Iteration 1415: Loss = 2.1177, ||Grad|| = 1.9204, ||W|| = 1.8245\n",
            "Iteration 1416: Loss = 2.1141, ||Grad|| = 1.9184, ||W|| = 1.8227\n",
            "Iteration 1417: Loss = 2.1106, ||Grad|| = 1.9165, ||W|| = 1.8208\n",
            "Iteration 1418: Loss = 2.1070, ||Grad|| = 1.9145, ||W|| = 1.8190\n",
            "Iteration 1419: Loss = 2.1035, ||Grad|| = 1.9125, ||W|| = 1.8171\n",
            "Iteration 1420: Loss = 2.1000, ||Grad|| = 1.9105, ||W|| = 1.8153\n",
            "Iteration 1421: Loss = 2.0965, ||Grad|| = 1.9085, ||W|| = 1.8135\n",
            "Iteration 1422: Loss = 2.0930, ||Grad|| = 1.9066, ||W|| = 1.8116\n",
            "Iteration 1423: Loss = 2.0895, ||Grad|| = 1.9046, ||W|| = 1.8098\n",
            "Iteration 1424: Loss = 2.0860, ||Grad|| = 1.9026, ||W|| = 1.8080\n",
            "Iteration 1425: Loss = 2.0826, ||Grad|| = 1.9007, ||W|| = 1.8061\n",
            "Iteration 1426: Loss = 2.0791, ||Grad|| = 1.8987, ||W|| = 1.8043\n",
            "Iteration 1427: Loss = 2.0756, ||Grad|| = 1.8967, ||W|| = 1.8025\n",
            "Iteration 1428: Loss = 2.0722, ||Grad|| = 1.8948, ||W|| = 1.8007\n",
            "Iteration 1429: Loss = 2.0687, ||Grad|| = 1.8928, ||W|| = 1.7989\n",
            "Iteration 1430: Loss = 2.0653, ||Grad|| = 1.8909, ||W|| = 1.7970\n",
            "Iteration 1431: Loss = 2.0618, ||Grad|| = 1.8889, ||W|| = 1.7952\n",
            "Iteration 1432: Loss = 2.0584, ||Grad|| = 1.8869, ||W|| = 1.7934\n",
            "Iteration 1433: Loss = 2.0550, ||Grad|| = 1.8850, ||W|| = 1.7916\n",
            "Iteration 1434: Loss = 2.0516, ||Grad|| = 1.8830, ||W|| = 1.7898\n",
            "Iteration 1435: Loss = 2.0482, ||Grad|| = 1.8811, ||W|| = 1.7880\n",
            "Iteration 1436: Loss = 2.0448, ||Grad|| = 1.8791, ||W|| = 1.7862\n",
            "Iteration 1437: Loss = 2.0414, ||Grad|| = 1.8772, ||W|| = 1.7844\n",
            "Iteration 1438: Loss = 2.0380, ||Grad|| = 1.8753, ||W|| = 1.7826\n",
            "Iteration 1439: Loss = 2.0347, ||Grad|| = 1.8733, ||W|| = 1.7808\n",
            "Iteration 1440: Loss = 2.0313, ||Grad|| = 1.8714, ||W|| = 1.7790\n",
            "Iteration 1441: Loss = 2.0279, ||Grad|| = 1.8694, ||W|| = 1.7772\n",
            "Iteration 1442: Loss = 2.0246, ||Grad|| = 1.8675, ||W|| = 1.7754\n",
            "Iteration 1443: Loss = 2.0212, ||Grad|| = 1.8656, ||W|| = 1.7736\n",
            "Iteration 1444: Loss = 2.0179, ||Grad|| = 1.8636, ||W|| = 1.7718\n",
            "Iteration 1445: Loss = 2.0146, ||Grad|| = 1.8617, ||W|| = 1.7700\n",
            "Iteration 1446: Loss = 2.0112, ||Grad|| = 1.8598, ||W|| = 1.7682\n",
            "Iteration 1447: Loss = 2.0079, ||Grad|| = 1.8579, ||W|| = 1.7665\n",
            "Iteration 1448: Loss = 2.0046, ||Grad|| = 1.8559, ||W|| = 1.7647\n",
            "Iteration 1449: Loss = 2.0013, ||Grad|| = 1.8540, ||W|| = 1.7629\n",
            "Iteration 1450: Loss = 1.9980, ||Grad|| = 1.8521, ||W|| = 1.7611\n",
            "Iteration 1451: Loss = 1.9947, ||Grad|| = 1.8502, ||W|| = 1.7593\n",
            "Iteration 1452: Loss = 1.9914, ||Grad|| = 1.8483, ||W|| = 1.7576\n",
            "Iteration 1453: Loss = 1.9882, ||Grad|| = 1.8463, ||W|| = 1.7558\n",
            "Iteration 1454: Loss = 1.9849, ||Grad|| = 1.8444, ||W|| = 1.7540\n",
            "Iteration 1455: Loss = 1.9816, ||Grad|| = 1.8425, ||W|| = 1.7523\n",
            "Iteration 1456: Loss = 1.9784, ||Grad|| = 1.8406, ||W|| = 1.7505\n",
            "Iteration 1457: Loss = 1.9751, ||Grad|| = 1.8387, ||W|| = 1.7487\n",
            "Iteration 1458: Loss = 1.9719, ||Grad|| = 1.8368, ||W|| = 1.7470\n",
            "Iteration 1459: Loss = 1.9687, ||Grad|| = 1.8349, ||W|| = 1.7452\n",
            "Iteration 1460: Loss = 1.9654, ||Grad|| = 1.8330, ||W|| = 1.7434\n",
            "Iteration 1461: Loss = 1.9622, ||Grad|| = 1.8311, ||W|| = 1.7417\n",
            "Iteration 1462: Loss = 1.9590, ||Grad|| = 1.8292, ||W|| = 1.7399\n",
            "Iteration 1463: Loss = 1.9558, ||Grad|| = 1.8273, ||W|| = 1.7382\n",
            "Iteration 1464: Loss = 1.9526, ||Grad|| = 1.8254, ||W|| = 1.7364\n",
            "Iteration 1465: Loss = 1.9494, ||Grad|| = 1.8235, ||W|| = 1.7347\n",
            "Iteration 1466: Loss = 1.9462, ||Grad|| = 1.8216, ||W|| = 1.7329\n",
            "Iteration 1467: Loss = 1.9430, ||Grad|| = 1.8198, ||W|| = 1.7312\n",
            "Iteration 1468: Loss = 1.9399, ||Grad|| = 1.8179, ||W|| = 1.7295\n",
            "Iteration 1469: Loss = 1.9367, ||Grad|| = 1.8160, ||W|| = 1.7277\n",
            "Iteration 1470: Loss = 1.9335, ||Grad|| = 1.8141, ||W|| = 1.7260\n",
            "Iteration 1471: Loss = 1.9304, ||Grad|| = 1.8122, ||W|| = 1.7242\n",
            "Iteration 1472: Loss = 1.9272, ||Grad|| = 1.8103, ||W|| = 1.7225\n",
            "Iteration 1473: Loss = 1.9241, ||Grad|| = 1.8085, ||W|| = 1.7208\n",
            "Iteration 1474: Loss = 1.9210, ||Grad|| = 1.8066, ||W|| = 1.7190\n",
            "Iteration 1475: Loss = 1.9178, ||Grad|| = 1.8047, ||W|| = 1.7173\n",
            "Iteration 1476: Loss = 1.9147, ||Grad|| = 1.8029, ||W|| = 1.7156\n",
            "Iteration 1477: Loss = 1.9116, ||Grad|| = 1.8010, ||W|| = 1.7139\n",
            "Iteration 1478: Loss = 1.9085, ||Grad|| = 1.7991, ||W|| = 1.7121\n",
            "Iteration 1479: Loss = 1.9054, ||Grad|| = 1.7973, ||W|| = 1.7104\n",
            "Iteration 1480: Loss = 1.9023, ||Grad|| = 1.7954, ||W|| = 1.7087\n",
            "Iteration 1481: Loss = 1.8992, ||Grad|| = 1.7935, ||W|| = 1.7070\n",
            "Iteration 1482: Loss = 1.8962, ||Grad|| = 1.7917, ||W|| = 1.7053\n",
            "Iteration 1483: Loss = 1.8931, ||Grad|| = 1.7898, ||W|| = 1.7035\n",
            "Iteration 1484: Loss = 1.8900, ||Grad|| = 1.7880, ||W|| = 1.7018\n",
            "Iteration 1485: Loss = 1.8870, ||Grad|| = 1.7861, ||W|| = 1.7001\n",
            "Iteration 1486: Loss = 1.8839, ||Grad|| = 1.7843, ||W|| = 1.6984\n",
            "Iteration 1487: Loss = 1.8809, ||Grad|| = 1.7824, ||W|| = 1.6967\n",
            "Iteration 1488: Loss = 1.8778, ||Grad|| = 1.7806, ||W|| = 1.6950\n",
            "Iteration 1489: Loss = 1.8748, ||Grad|| = 1.7787, ||W|| = 1.6933\n",
            "Iteration 1490: Loss = 1.8718, ||Grad|| = 1.7769, ||W|| = 1.6916\n",
            "Iteration 1491: Loss = 1.8687, ||Grad|| = 1.7750, ||W|| = 1.6899\n",
            "Iteration 1492: Loss = 1.8657, ||Grad|| = 1.7732, ||W|| = 1.6882\n",
            "Iteration 1493: Loss = 1.8627, ||Grad|| = 1.7713, ||W|| = 1.6865\n",
            "Iteration 1494: Loss = 1.8597, ||Grad|| = 1.7695, ||W|| = 1.6848\n",
            "Iteration 1495: Loss = 1.8567, ||Grad|| = 1.7677, ||W|| = 1.6831\n",
            "Iteration 1496: Loss = 1.8537, ||Grad|| = 1.7658, ||W|| = 1.6814\n",
            "Iteration 1497: Loss = 1.8508, ||Grad|| = 1.7640, ||W|| = 1.6798\n",
            "Iteration 1498: Loss = 1.8478, ||Grad|| = 1.7622, ||W|| = 1.6781\n",
            "Iteration 1499: Loss = 1.8448, ||Grad|| = 1.7603, ||W|| = 1.6764\n",
            "Iteration 1500: Loss = 1.8418, ||Grad|| = 1.7585, ||W|| = 1.6747\n",
            "Iteration 1501: Loss = 1.8389, ||Grad|| = 1.7567, ||W|| = 1.6730\n",
            "Iteration 1502: Loss = 1.8359, ||Grad|| = 1.7549, ||W|| = 1.6714\n",
            "Iteration 1503: Loss = 1.8330, ||Grad|| = 1.7531, ||W|| = 1.6697\n",
            "Iteration 1504: Loss = 1.8301, ||Grad|| = 1.7512, ||W|| = 1.6680\n",
            "Iteration 1505: Loss = 1.8271, ||Grad|| = 1.7494, ||W|| = 1.6663\n",
            "Iteration 1506: Loss = 1.8242, ||Grad|| = 1.7476, ||W|| = 1.6647\n",
            "Iteration 1507: Loss = 1.8213, ||Grad|| = 1.7458, ||W|| = 1.6630\n",
            "Iteration 1508: Loss = 1.8184, ||Grad|| = 1.7440, ||W|| = 1.6613\n",
            "Iteration 1509: Loss = 1.8155, ||Grad|| = 1.7422, ||W|| = 1.6597\n",
            "Iteration 1510: Loss = 1.8126, ||Grad|| = 1.7404, ||W|| = 1.6580\n",
            "Iteration 1511: Loss = 1.8097, ||Grad|| = 1.7386, ||W|| = 1.6563\n",
            "Iteration 1512: Loss = 1.8068, ||Grad|| = 1.7368, ||W|| = 1.6547\n",
            "Iteration 1513: Loss = 1.8039, ||Grad|| = 1.7349, ||W|| = 1.6530\n",
            "Iteration 1514: Loss = 1.8010, ||Grad|| = 1.7331, ||W|| = 1.6514\n",
            "Iteration 1515: Loss = 1.7982, ||Grad|| = 1.7313, ||W|| = 1.6497\n",
            "Iteration 1516: Loss = 1.7953, ||Grad|| = 1.7296, ||W|| = 1.6481\n",
            "Iteration 1517: Loss = 1.7924, ||Grad|| = 1.7278, ||W|| = 1.6464\n",
            "Iteration 1518: Loss = 1.7896, ||Grad|| = 1.7260, ||W|| = 1.6448\n",
            "Iteration 1519: Loss = 1.7868, ||Grad|| = 1.7242, ||W|| = 1.6431\n",
            "Iteration 1520: Loss = 1.7839, ||Grad|| = 1.7224, ||W|| = 1.6415\n",
            "Iteration 1521: Loss = 1.7811, ||Grad|| = 1.7206, ||W|| = 1.6398\n",
            "Iteration 1522: Loss = 1.7783, ||Grad|| = 1.7188, ||W|| = 1.6382\n",
            "Iteration 1523: Loss = 1.7754, ||Grad|| = 1.7170, ||W|| = 1.6366\n",
            "Iteration 1524: Loss = 1.7726, ||Grad|| = 1.7152, ||W|| = 1.6349\n",
            "Iteration 1525: Loss = 1.7698, ||Grad|| = 1.7135, ||W|| = 1.6333\n",
            "Iteration 1526: Loss = 1.7670, ||Grad|| = 1.7117, ||W|| = 1.6316\n",
            "Iteration 1527: Loss = 1.7642, ||Grad|| = 1.7099, ||W|| = 1.6300\n",
            "Iteration 1528: Loss = 1.7614, ||Grad|| = 1.7081, ||W|| = 1.6284\n",
            "Iteration 1529: Loss = 1.7586, ||Grad|| = 1.7064, ||W|| = 1.6268\n",
            "Iteration 1530: Loss = 1.7559, ||Grad|| = 1.7046, ||W|| = 1.6251\n",
            "Iteration 1531: Loss = 1.7531, ||Grad|| = 1.7028, ||W|| = 1.6235\n",
            "Iteration 1532: Loss = 1.7503, ||Grad|| = 1.7010, ||W|| = 1.6219\n",
            "Iteration 1533: Loss = 1.7476, ||Grad|| = 1.6993, ||W|| = 1.6203\n",
            "Iteration 1534: Loss = 1.7448, ||Grad|| = 1.6975, ||W|| = 1.6186\n",
            "Iteration 1535: Loss = 1.7421, ||Grad|| = 1.6958, ||W|| = 1.6170\n",
            "Iteration 1536: Loss = 1.7393, ||Grad|| = 1.6940, ||W|| = 1.6154\n",
            "Iteration 1537: Loss = 1.7366, ||Grad|| = 1.6922, ||W|| = 1.6138\n",
            "Iteration 1538: Loss = 1.7339, ||Grad|| = 1.6905, ||W|| = 1.6122\n",
            "Iteration 1539: Loss = 1.7311, ||Grad|| = 1.6887, ||W|| = 1.6106\n",
            "Iteration 1540: Loss = 1.7284, ||Grad|| = 1.6870, ||W|| = 1.6090\n",
            "Iteration 1541: Loss = 1.7257, ||Grad|| = 1.6852, ||W|| = 1.6074\n",
            "Iteration 1542: Loss = 1.7230, ||Grad|| = 1.6835, ||W|| = 1.6058\n",
            "Iteration 1543: Loss = 1.7203, ||Grad|| = 1.6817, ||W|| = 1.6042\n",
            "Iteration 1544: Loss = 1.7176, ||Grad|| = 1.6800, ||W|| = 1.6026\n",
            "Iteration 1545: Loss = 1.7149, ||Grad|| = 1.6782, ||W|| = 1.6010\n",
            "Iteration 1546: Loss = 1.7122, ||Grad|| = 1.6765, ||W|| = 1.5994\n",
            "Iteration 1547: Loss = 1.7095, ||Grad|| = 1.6747, ||W|| = 1.5978\n",
            "Iteration 1548: Loss = 1.7069, ||Grad|| = 1.6730, ||W|| = 1.5962\n",
            "Iteration 1549: Loss = 1.7042, ||Grad|| = 1.6713, ||W|| = 1.5946\n",
            "Iteration 1550: Loss = 1.7015, ||Grad|| = 1.6695, ||W|| = 1.5930\n",
            "Iteration 1551: Loss = 1.6989, ||Grad|| = 1.6678, ||W|| = 1.5914\n",
            "Iteration 1552: Loss = 1.6962, ||Grad|| = 1.6661, ||W|| = 1.5898\n",
            "Iteration 1553: Loss = 1.6936, ||Grad|| = 1.6643, ||W|| = 1.5882\n",
            "Iteration 1554: Loss = 1.6910, ||Grad|| = 1.6626, ||W|| = 1.5867\n",
            "Iteration 1555: Loss = 1.6883, ||Grad|| = 1.6609, ||W|| = 1.5851\n",
            "Iteration 1556: Loss = 1.6857, ||Grad|| = 1.6591, ||W|| = 1.5835\n",
            "Iteration 1557: Loss = 1.6831, ||Grad|| = 1.6574, ||W|| = 1.5819\n",
            "Iteration 1558: Loss = 1.6805, ||Grad|| = 1.6557, ||W|| = 1.5803\n",
            "Iteration 1559: Loss = 1.6778, ||Grad|| = 1.6540, ||W|| = 1.5788\n",
            "Iteration 1560: Loss = 1.6752, ||Grad|| = 1.6523, ||W|| = 1.5772\n",
            "Iteration 1561: Loss = 1.6726, ||Grad|| = 1.6505, ||W|| = 1.5756\n",
            "Iteration 1562: Loss = 1.6700, ||Grad|| = 1.6488, ||W|| = 1.5741\n",
            "Iteration 1563: Loss = 1.6675, ||Grad|| = 1.6471, ||W|| = 1.5725\n",
            "Iteration 1564: Loss = 1.6649, ||Grad|| = 1.6454, ||W|| = 1.5709\n",
            "Iteration 1565: Loss = 1.6623, ||Grad|| = 1.6437, ||W|| = 1.5694\n",
            "Iteration 1566: Loss = 1.6597, ||Grad|| = 1.6420, ||W|| = 1.5678\n",
            "Iteration 1567: Loss = 1.6572, ||Grad|| = 1.6403, ||W|| = 1.5662\n",
            "Iteration 1568: Loss = 1.6546, ||Grad|| = 1.6386, ||W|| = 1.5647\n",
            "Iteration 1569: Loss = 1.6520, ||Grad|| = 1.6369, ||W|| = 1.5631\n",
            "Iteration 1570: Loss = 1.6495, ||Grad|| = 1.6352, ||W|| = 1.5616\n",
            "Iteration 1571: Loss = 1.6470, ||Grad|| = 1.6335, ||W|| = 1.5600\n",
            "Iteration 1572: Loss = 1.6444, ||Grad|| = 1.6318, ||W|| = 1.5585\n",
            "Iteration 1573: Loss = 1.6419, ||Grad|| = 1.6301, ||W|| = 1.5569\n",
            "Iteration 1574: Loss = 1.6394, ||Grad|| = 1.6284, ||W|| = 1.5554\n",
            "Iteration 1575: Loss = 1.6368, ||Grad|| = 1.6267, ||W|| = 1.5538\n",
            "Iteration 1576: Loss = 1.6343, ||Grad|| = 1.6250, ||W|| = 1.5523\n",
            "Iteration 1577: Loss = 1.6318, ||Grad|| = 1.6233, ||W|| = 1.5507\n",
            "Iteration 1578: Loss = 1.6293, ||Grad|| = 1.6216, ||W|| = 1.5492\n",
            "Iteration 1579: Loss = 1.6268, ||Grad|| = 1.6199, ||W|| = 1.5477\n",
            "Iteration 1580: Loss = 1.6243, ||Grad|| = 1.6182, ||W|| = 1.5461\n",
            "Iteration 1581: Loss = 1.6218, ||Grad|| = 1.6166, ||W|| = 1.5446\n",
            "Iteration 1582: Loss = 1.6193, ||Grad|| = 1.6149, ||W|| = 1.5431\n",
            "Iteration 1583: Loss = 1.6169, ||Grad|| = 1.6132, ||W|| = 1.5415\n",
            "Iteration 1584: Loss = 1.6144, ||Grad|| = 1.6115, ||W|| = 1.5400\n",
            "Iteration 1585: Loss = 1.6119, ||Grad|| = 1.6098, ||W|| = 1.5385\n",
            "Iteration 1586: Loss = 1.6094, ||Grad|| = 1.6082, ||W|| = 1.5369\n",
            "Iteration 1587: Loss = 1.6070, ||Grad|| = 1.6065, ||W|| = 1.5354\n",
            "Iteration 1588: Loss = 1.6045, ||Grad|| = 1.6048, ||W|| = 1.5339\n",
            "Iteration 1589: Loss = 1.6021, ||Grad|| = 1.6031, ||W|| = 1.5324\n",
            "Iteration 1590: Loss = 1.5996, ||Grad|| = 1.6015, ||W|| = 1.5309\n",
            "Iteration 1591: Loss = 1.5972, ||Grad|| = 1.5998, ||W|| = 1.5293\n",
            "Iteration 1592: Loss = 1.5948, ||Grad|| = 1.5982, ||W|| = 1.5278\n",
            "Iteration 1593: Loss = 1.5924, ||Grad|| = 1.5965, ||W|| = 1.5263\n",
            "Iteration 1594: Loss = 1.5899, ||Grad|| = 1.5948, ||W|| = 1.5248\n",
            "Iteration 1595: Loss = 1.5875, ||Grad|| = 1.5932, ||W|| = 1.5233\n",
            "Iteration 1596: Loss = 1.5851, ||Grad|| = 1.5915, ||W|| = 1.5218\n",
            "Iteration 1597: Loss = 1.5827, ||Grad|| = 1.5899, ||W|| = 1.5203\n",
            "Iteration 1598: Loss = 1.5803, ||Grad|| = 1.5882, ||W|| = 1.5188\n",
            "Iteration 1599: Loss = 1.5779, ||Grad|| = 1.5865, ||W|| = 1.5173\n",
            "Iteration 1600: Loss = 1.5755, ||Grad|| = 1.5849, ||W|| = 1.5158\n",
            "Iteration 1601: Loss = 1.5731, ||Grad|| = 1.5832, ||W|| = 1.5143\n",
            "Iteration 1602: Loss = 1.5708, ||Grad|| = 1.5816, ||W|| = 1.5128\n",
            "Iteration 1603: Loss = 1.5684, ||Grad|| = 1.5800, ||W|| = 1.5113\n",
            "Iteration 1604: Loss = 1.5660, ||Grad|| = 1.5783, ||W|| = 1.5098\n",
            "Iteration 1605: Loss = 1.5636, ||Grad|| = 1.5767, ||W|| = 1.5083\n",
            "Iteration 1606: Loss = 1.5613, ||Grad|| = 1.5750, ||W|| = 1.5068\n",
            "Iteration 1607: Loss = 1.5589, ||Grad|| = 1.5734, ||W|| = 1.5053\n",
            "Iteration 1608: Loss = 1.5566, ||Grad|| = 1.5717, ||W|| = 1.5038\n",
            "Iteration 1609: Loss = 1.5542, ||Grad|| = 1.5701, ||W|| = 1.5023\n",
            "Iteration 1610: Loss = 1.5519, ||Grad|| = 1.5685, ||W|| = 1.5008\n",
            "Iteration 1611: Loss = 1.5496, ||Grad|| = 1.5668, ||W|| = 1.4994\n",
            "Iteration 1612: Loss = 1.5472, ||Grad|| = 1.5652, ||W|| = 1.4979\n",
            "Iteration 1613: Loss = 1.5449, ||Grad|| = 1.5636, ||W|| = 1.4964\n",
            "Iteration 1614: Loss = 1.5426, ||Grad|| = 1.5620, ||W|| = 1.4949\n",
            "Iteration 1615: Loss = 1.5403, ||Grad|| = 1.5603, ||W|| = 1.4934\n",
            "Iteration 1616: Loss = 1.5380, ||Grad|| = 1.5587, ||W|| = 1.4920\n",
            "Iteration 1617: Loss = 1.5357, ||Grad|| = 1.5571, ||W|| = 1.4905\n",
            "Iteration 1618: Loss = 1.5334, ||Grad|| = 1.5555, ||W|| = 1.4890\n",
            "Iteration 1619: Loss = 1.5311, ||Grad|| = 1.5538, ||W|| = 1.4875\n",
            "Iteration 1620: Loss = 1.5288, ||Grad|| = 1.5522, ||W|| = 1.4861\n",
            "Iteration 1621: Loss = 1.5265, ||Grad|| = 1.5506, ||W|| = 1.4846\n",
            "Iteration 1622: Loss = 1.5242, ||Grad|| = 1.5490, ||W|| = 1.4831\n",
            "Iteration 1623: Loss = 1.5219, ||Grad|| = 1.5474, ||W|| = 1.4817\n",
            "Iteration 1624: Loss = 1.5197, ||Grad|| = 1.5458, ||W|| = 1.4802\n",
            "Iteration 1625: Loss = 1.5174, ||Grad|| = 1.5442, ||W|| = 1.4788\n",
            "Iteration 1626: Loss = 1.5152, ||Grad|| = 1.5426, ||W|| = 1.4773\n",
            "Iteration 1627: Loss = 1.5129, ||Grad|| = 1.5409, ||W|| = 1.4758\n",
            "Iteration 1628: Loss = 1.5107, ||Grad|| = 1.5393, ||W|| = 1.4744\n",
            "Iteration 1629: Loss = 1.5084, ||Grad|| = 1.5377, ||W|| = 1.4729\n",
            "Iteration 1630: Loss = 1.5062, ||Grad|| = 1.5361, ||W|| = 1.4715\n",
            "Iteration 1631: Loss = 1.5039, ||Grad|| = 1.5345, ||W|| = 1.4700\n",
            "Iteration 1632: Loss = 1.5017, ||Grad|| = 1.5329, ||W|| = 1.4686\n",
            "Iteration 1633: Loss = 1.4995, ||Grad|| = 1.5313, ||W|| = 1.4671\n",
            "Iteration 1634: Loss = 1.4973, ||Grad|| = 1.5298, ||W|| = 1.4657\n",
            "Iteration 1635: Loss = 1.4950, ||Grad|| = 1.5282, ||W|| = 1.4643\n",
            "Iteration 1636: Loss = 1.4928, ||Grad|| = 1.5266, ||W|| = 1.4628\n",
            "Iteration 1637: Loss = 1.4906, ||Grad|| = 1.5250, ||W|| = 1.4614\n",
            "Iteration 1638: Loss = 1.4884, ||Grad|| = 1.5234, ||W|| = 1.4599\n",
            "Iteration 1639: Loss = 1.4862, ||Grad|| = 1.5218, ||W|| = 1.4585\n",
            "Iteration 1640: Loss = 1.4840, ||Grad|| = 1.5202, ||W|| = 1.4571\n",
            "Iteration 1641: Loss = 1.4818, ||Grad|| = 1.5186, ||W|| = 1.4556\n",
            "Iteration 1642: Loss = 1.4797, ||Grad|| = 1.5170, ||W|| = 1.4542\n",
            "Iteration 1643: Loss = 1.4775, ||Grad|| = 1.5155, ||W|| = 1.4528\n",
            "Iteration 1644: Loss = 1.4753, ||Grad|| = 1.5139, ||W|| = 1.4513\n",
            "Iteration 1645: Loss = 1.4731, ||Grad|| = 1.5123, ||W|| = 1.4499\n",
            "Iteration 1646: Loss = 1.4710, ||Grad|| = 1.5107, ||W|| = 1.4485\n",
            "Iteration 1647: Loss = 1.4688, ||Grad|| = 1.5092, ||W|| = 1.4471\n",
            "Iteration 1648: Loss = 1.4667, ||Grad|| = 1.5076, ||W|| = 1.4456\n",
            "Iteration 1649: Loss = 1.4645, ||Grad|| = 1.5060, ||W|| = 1.4442\n",
            "Iteration 1650: Loss = 1.4624, ||Grad|| = 1.5045, ||W|| = 1.4428\n",
            "Iteration 1651: Loss = 1.4602, ||Grad|| = 1.5029, ||W|| = 1.4414\n",
            "Iteration 1652: Loss = 1.4581, ||Grad|| = 1.5013, ||W|| = 1.4400\n",
            "Iteration 1653: Loss = 1.4560, ||Grad|| = 1.4998, ||W|| = 1.4386\n",
            "Iteration 1654: Loss = 1.4538, ||Grad|| = 1.4982, ||W|| = 1.4371\n",
            "Iteration 1655: Loss = 1.4517, ||Grad|| = 1.4966, ||W|| = 1.4357\n",
            "Iteration 1656: Loss = 1.4496, ||Grad|| = 1.4951, ||W|| = 1.4343\n",
            "Iteration 1657: Loss = 1.4475, ||Grad|| = 1.4935, ||W|| = 1.4329\n",
            "Iteration 1658: Loss = 1.4454, ||Grad|| = 1.4920, ||W|| = 1.4315\n",
            "Iteration 1659: Loss = 1.4433, ||Grad|| = 1.4904, ||W|| = 1.4301\n",
            "Iteration 1660: Loss = 1.4412, ||Grad|| = 1.4888, ||W|| = 1.4287\n",
            "Iteration 1661: Loss = 1.4391, ||Grad|| = 1.4873, ||W|| = 1.4273\n",
            "Iteration 1662: Loss = 1.4370, ||Grad|| = 1.4857, ||W|| = 1.4259\n",
            "Iteration 1663: Loss = 1.4349, ||Grad|| = 1.4842, ||W|| = 1.4245\n",
            "Iteration 1664: Loss = 1.4328, ||Grad|| = 1.4827, ||W|| = 1.4231\n",
            "Iteration 1665: Loss = 1.4307, ||Grad|| = 1.4811, ||W|| = 1.4217\n",
            "Iteration 1666: Loss = 1.4287, ||Grad|| = 1.4796, ||W|| = 1.4203\n",
            "Iteration 1667: Loss = 1.4266, ||Grad|| = 1.4780, ||W|| = 1.4189\n",
            "Iteration 1668: Loss = 1.4245, ||Grad|| = 1.4765, ||W|| = 1.4175\n",
            "Iteration 1669: Loss = 1.4225, ||Grad|| = 1.4749, ||W|| = 1.4162\n",
            "Iteration 1670: Loss = 1.4204, ||Grad|| = 1.4734, ||W|| = 1.4148\n",
            "Iteration 1671: Loss = 1.4184, ||Grad|| = 1.4719, ||W|| = 1.4134\n",
            "Iteration 1672: Loss = 1.4163, ||Grad|| = 1.4703, ||W|| = 1.4120\n",
            "Iteration 1673: Loss = 1.4143, ||Grad|| = 1.4688, ||W|| = 1.4106\n",
            "Iteration 1674: Loss = 1.4122, ||Grad|| = 1.4673, ||W|| = 1.4092\n",
            "Iteration 1675: Loss = 1.4102, ||Grad|| = 1.4657, ||W|| = 1.4079\n",
            "Iteration 1676: Loss = 1.4082, ||Grad|| = 1.4642, ||W|| = 1.4065\n",
            "Iteration 1677: Loss = 1.4062, ||Grad|| = 1.4627, ||W|| = 1.4051\n",
            "Iteration 1678: Loss = 1.4041, ||Grad|| = 1.4612, ||W|| = 1.4037\n",
            "Iteration 1679: Loss = 1.4021, ||Grad|| = 1.4596, ||W|| = 1.4024\n",
            "Iteration 1680: Loss = 1.4001, ||Grad|| = 1.4581, ||W|| = 1.4010\n",
            "Iteration 1681: Loss = 1.3981, ||Grad|| = 1.4566, ||W|| = 1.3996\n",
            "Iteration 1682: Loss = 1.3961, ||Grad|| = 1.4551, ||W|| = 1.3983\n",
            "Iteration 1683: Loss = 1.3941, ||Grad|| = 1.4536, ||W|| = 1.3969\n",
            "Iteration 1684: Loss = 1.3921, ||Grad|| = 1.4520, ||W|| = 1.3955\n",
            "Iteration 1685: Loss = 1.3901, ||Grad|| = 1.4505, ||W|| = 1.3942\n",
            "Iteration 1686: Loss = 1.3881, ||Grad|| = 1.4490, ||W|| = 1.3928\n",
            "Iteration 1687: Loss = 1.3862, ||Grad|| = 1.4475, ||W|| = 1.3914\n",
            "Iteration 1688: Loss = 1.3842, ||Grad|| = 1.4460, ||W|| = 1.3901\n",
            "Iteration 1689: Loss = 1.3822, ||Grad|| = 1.4445, ||W|| = 1.3887\n",
            "Iteration 1690: Loss = 1.3803, ||Grad|| = 1.4430, ||W|| = 1.3874\n",
            "Iteration 1691: Loss = 1.3783, ||Grad|| = 1.4415, ||W|| = 1.3860\n",
            "Iteration 1692: Loss = 1.3763, ||Grad|| = 1.4400, ||W|| = 1.3847\n",
            "Iteration 1693: Loss = 1.3744, ||Grad|| = 1.4385, ||W|| = 1.3833\n",
            "Iteration 1694: Loss = 1.3724, ||Grad|| = 1.4370, ||W|| = 1.3820\n",
            "Iteration 1695: Loss = 1.3705, ||Grad|| = 1.4355, ||W|| = 1.3806\n",
            "Iteration 1696: Loss = 1.3685, ||Grad|| = 1.4340, ||W|| = 1.3793\n",
            "Iteration 1697: Loss = 1.3666, ||Grad|| = 1.4325, ||W|| = 1.3779\n",
            "Iteration 1698: Loss = 1.3647, ||Grad|| = 1.4310, ||W|| = 1.3766\n",
            "Iteration 1699: Loss = 1.3627, ||Grad|| = 1.4295, ||W|| = 1.3752\n",
            "Iteration 1700: Loss = 1.3608, ||Grad|| = 1.4280, ||W|| = 1.3739\n",
            "Iteration 1701: Loss = 1.3589, ||Grad|| = 1.4265, ||W|| = 1.3726\n",
            "Iteration 1702: Loss = 1.3570, ||Grad|| = 1.4250, ||W|| = 1.3712\n",
            "Iteration 1703: Loss = 1.3551, ||Grad|| = 1.4235, ||W|| = 1.3699\n",
            "Iteration 1704: Loss = 1.3532, ||Grad|| = 1.4221, ||W|| = 1.3686\n",
            "Iteration 1705: Loss = 1.3513, ||Grad|| = 1.4206, ||W|| = 1.3672\n",
            "Iteration 1706: Loss = 1.3494, ||Grad|| = 1.4191, ||W|| = 1.3659\n",
            "Iteration 1707: Loss = 1.3475, ||Grad|| = 1.4176, ||W|| = 1.3646\n",
            "Iteration 1708: Loss = 1.3456, ||Grad|| = 1.4161, ||W|| = 1.3633\n",
            "Iteration 1709: Loss = 1.3437, ||Grad|| = 1.4147, ||W|| = 1.3619\n",
            "Iteration 1710: Loss = 1.3418, ||Grad|| = 1.4132, ||W|| = 1.3606\n",
            "Iteration 1711: Loss = 1.3399, ||Grad|| = 1.4117, ||W|| = 1.3593\n",
            "Iteration 1712: Loss = 1.3380, ||Grad|| = 1.4102, ||W|| = 1.3580\n",
            "Iteration 1713: Loss = 1.3362, ||Grad|| = 1.4088, ||W|| = 1.3566\n",
            "Iteration 1714: Loss = 1.3343, ||Grad|| = 1.4073, ||W|| = 1.3553\n",
            "Iteration 1715: Loss = 1.3324, ||Grad|| = 1.4058, ||W|| = 1.3540\n",
            "Iteration 1716: Loss = 1.3306, ||Grad|| = 1.4044, ||W|| = 1.3527\n",
            "Iteration 1717: Loss = 1.3287, ||Grad|| = 1.4029, ||W|| = 1.3514\n",
            "Iteration 1718: Loss = 1.3269, ||Grad|| = 1.4014, ||W|| = 1.3501\n",
            "Iteration 1719: Loss = 1.3250, ||Grad|| = 1.4000, ||W|| = 1.3488\n",
            "Iteration 1720: Loss = 1.3232, ||Grad|| = 1.3985, ||W|| = 1.3475\n",
            "Iteration 1721: Loss = 1.3213, ||Grad|| = 1.3970, ||W|| = 1.3461\n",
            "Iteration 1722: Loss = 1.3195, ||Grad|| = 1.3956, ||W|| = 1.3448\n",
            "Iteration 1723: Loss = 1.3177, ||Grad|| = 1.3941, ||W|| = 1.3435\n",
            "Iteration 1724: Loss = 1.3158, ||Grad|| = 1.3927, ||W|| = 1.3422\n",
            "Iteration 1725: Loss = 1.3140, ||Grad|| = 1.3912, ||W|| = 1.3409\n",
            "Iteration 1726: Loss = 1.3122, ||Grad|| = 1.3898, ||W|| = 1.3396\n",
            "Iteration 1727: Loss = 1.3104, ||Grad|| = 1.3883, ||W|| = 1.3383\n",
            "Iteration 1728: Loss = 1.3086, ||Grad|| = 1.3869, ||W|| = 1.3370\n",
            "Iteration 1729: Loss = 1.3068, ||Grad|| = 1.3854, ||W|| = 1.3357\n",
            "Iteration 1730: Loss = 1.3050, ||Grad|| = 1.3840, ||W|| = 1.3345\n",
            "Iteration 1731: Loss = 1.3032, ||Grad|| = 1.3825, ||W|| = 1.3332\n",
            "Iteration 1732: Loss = 1.3014, ||Grad|| = 1.3811, ||W|| = 1.3319\n",
            "Iteration 1733: Loss = 1.2996, ||Grad|| = 1.3796, ||W|| = 1.3306\n",
            "Iteration 1734: Loss = 1.2978, ||Grad|| = 1.3782, ||W|| = 1.3293\n",
            "Iteration 1735: Loss = 1.2960, ||Grad|| = 1.3768, ||W|| = 1.3280\n",
            "Iteration 1736: Loss = 1.2942, ||Grad|| = 1.3753, ||W|| = 1.3267\n",
            "Iteration 1737: Loss = 1.2924, ||Grad|| = 1.3739, ||W|| = 1.3254\n",
            "Iteration 1738: Loss = 1.2907, ||Grad|| = 1.3725, ||W|| = 1.3242\n",
            "Iteration 1739: Loss = 1.2889, ||Grad|| = 1.3710, ||W|| = 1.3229\n",
            "Iteration 1740: Loss = 1.2871, ||Grad|| = 1.3696, ||W|| = 1.3216\n",
            "Iteration 1741: Loss = 1.2854, ||Grad|| = 1.3682, ||W|| = 1.3203\n",
            "Iteration 1742: Loss = 1.2836, ||Grad|| = 1.3667, ||W|| = 1.3191\n",
            "Iteration 1743: Loss = 1.2819, ||Grad|| = 1.3653, ||W|| = 1.3178\n",
            "Iteration 1744: Loss = 1.2801, ||Grad|| = 1.3639, ||W|| = 1.3165\n",
            "Iteration 1745: Loss = 1.2784, ||Grad|| = 1.3625, ||W|| = 1.3152\n",
            "Iteration 1746: Loss = 1.2766, ||Grad|| = 1.3610, ||W|| = 1.3140\n",
            "Iteration 1747: Loss = 1.2749, ||Grad|| = 1.3596, ||W|| = 1.3127\n",
            "Iteration 1748: Loss = 1.2732, ||Grad|| = 1.3582, ||W|| = 1.3114\n",
            "Iteration 1749: Loss = 1.2714, ||Grad|| = 1.3568, ||W|| = 1.3102\n",
            "Iteration 1750: Loss = 1.2697, ||Grad|| = 1.3554, ||W|| = 1.3089\n",
            "Iteration 1751: Loss = 1.2680, ||Grad|| = 1.3540, ||W|| = 1.3076\n",
            "Iteration 1752: Loss = 1.2663, ||Grad|| = 1.3525, ||W|| = 1.3064\n",
            "Iteration 1753: Loss = 1.2645, ||Grad|| = 1.3511, ||W|| = 1.3051\n",
            "Iteration 1754: Loss = 1.2628, ||Grad|| = 1.3497, ||W|| = 1.3039\n",
            "Iteration 1755: Loss = 1.2611, ||Grad|| = 1.3483, ||W|| = 1.3026\n",
            "Iteration 1756: Loss = 1.2594, ||Grad|| = 1.3469, ||W|| = 1.3014\n",
            "Iteration 1757: Loss = 1.2577, ||Grad|| = 1.3455, ||W|| = 1.3001\n",
            "Iteration 1758: Loss = 1.2560, ||Grad|| = 1.3441, ||W|| = 1.2989\n",
            "Iteration 1759: Loss = 1.2543, ||Grad|| = 1.3427, ||W|| = 1.2976\n",
            "Iteration 1760: Loss = 1.2526, ||Grad|| = 1.3413, ||W|| = 1.2964\n",
            "Iteration 1761: Loss = 1.2509, ||Grad|| = 1.3399, ||W|| = 1.2951\n",
            "Iteration 1762: Loss = 1.2493, ||Grad|| = 1.3385, ||W|| = 1.2939\n",
            "Iteration 1763: Loss = 1.2476, ||Grad|| = 1.3371, ||W|| = 1.2926\n",
            "Iteration 1764: Loss = 1.2459, ||Grad|| = 1.3357, ||W|| = 1.2914\n",
            "Iteration 1765: Loss = 1.2442, ||Grad|| = 1.3343, ||W|| = 1.2901\n",
            "Iteration 1766: Loss = 1.2426, ||Grad|| = 1.3329, ||W|| = 1.2889\n",
            "Iteration 1767: Loss = 1.2409, ||Grad|| = 1.3315, ||W|| = 1.2877\n",
            "Iteration 1768: Loss = 1.2392, ||Grad|| = 1.3301, ||W|| = 1.2864\n",
            "Iteration 1769: Loss = 1.2376, ||Grad|| = 1.3287, ||W|| = 1.2852\n",
            "Iteration 1770: Loss = 1.2359, ||Grad|| = 1.3273, ||W|| = 1.2839\n",
            "Iteration 1771: Loss = 1.2343, ||Grad|| = 1.3260, ||W|| = 1.2827\n",
            "Iteration 1772: Loss = 1.2326, ||Grad|| = 1.3246, ||W|| = 1.2815\n",
            "Iteration 1773: Loss = 1.2310, ||Grad|| = 1.3232, ||W|| = 1.2803\n",
            "Iteration 1774: Loss = 1.2294, ||Grad|| = 1.3218, ||W|| = 1.2790\n",
            "Iteration 1775: Loss = 1.2277, ||Grad|| = 1.3204, ||W|| = 1.2778\n",
            "Iteration 1776: Loss = 1.2261, ||Grad|| = 1.3191, ||W|| = 1.2766\n",
            "Iteration 1777: Loss = 1.2245, ||Grad|| = 1.3177, ||W|| = 1.2754\n",
            "Iteration 1778: Loss = 1.2228, ||Grad|| = 1.3163, ||W|| = 1.2741\n",
            "Iteration 1779: Loss = 1.2212, ||Grad|| = 1.3149, ||W|| = 1.2729\n",
            "Iteration 1780: Loss = 1.2196, ||Grad|| = 1.3136, ||W|| = 1.2717\n",
            "Iteration 1781: Loss = 1.2180, ||Grad|| = 1.3122, ||W|| = 1.2705\n",
            "Iteration 1782: Loss = 1.2164, ||Grad|| = 1.3108, ||W|| = 1.2693\n",
            "Iteration 1783: Loss = 1.2148, ||Grad|| = 1.3094, ||W|| = 1.2680\n",
            "Iteration 1784: Loss = 1.2132, ||Grad|| = 1.3081, ||W|| = 1.2668\n",
            "Iteration 1785: Loss = 1.2116, ||Grad|| = 1.3067, ||W|| = 1.2656\n",
            "Iteration 1786: Loss = 1.2100, ||Grad|| = 1.3053, ||W|| = 1.2644\n",
            "Iteration 1787: Loss = 1.2084, ||Grad|| = 1.3040, ||W|| = 1.2632\n",
            "Iteration 1788: Loss = 1.2068, ||Grad|| = 1.3026, ||W|| = 1.2620\n",
            "Iteration 1789: Loss = 1.2052, ||Grad|| = 1.3013, ||W|| = 1.2608\n",
            "Iteration 1790: Loss = 1.2036, ||Grad|| = 1.2999, ||W|| = 1.2596\n",
            "Iteration 1791: Loss = 1.2020, ||Grad|| = 1.2985, ||W|| = 1.2584\n",
            "Iteration 1792: Loss = 1.2005, ||Grad|| = 1.2972, ||W|| = 1.2572\n",
            "Iteration 1793: Loss = 1.1989, ||Grad|| = 1.2958, ||W|| = 1.2560\n",
            "Iteration 1794: Loss = 1.1973, ||Grad|| = 1.2945, ||W|| = 1.2548\n",
            "Iteration 1795: Loss = 1.1958, ||Grad|| = 1.2931, ||W|| = 1.2536\n",
            "Iteration 1796: Loss = 1.1942, ||Grad|| = 1.2918, ||W|| = 1.2524\n",
            "Iteration 1797: Loss = 1.1926, ||Grad|| = 1.2904, ||W|| = 1.2512\n",
            "Iteration 1798: Loss = 1.1911, ||Grad|| = 1.2891, ||W|| = 1.2500\n",
            "Iteration 1799: Loss = 1.1895, ||Grad|| = 1.2877, ||W|| = 1.2488\n",
            "Iteration 1800: Loss = 1.1880, ||Grad|| = 1.2864, ||W|| = 1.2476\n",
            "Iteration 1801: Loss = 1.1864, ||Grad|| = 1.2850, ||W|| = 1.2464\n",
            "Iteration 1802: Loss = 1.1849, ||Grad|| = 1.2837, ||W|| = 1.2452\n",
            "Iteration 1803: Loss = 1.1833, ||Grad|| = 1.2824, ||W|| = 1.2440\n",
            "Iteration 1804: Loss = 1.1818, ||Grad|| = 1.2810, ||W|| = 1.2429\n",
            "Iteration 1805: Loss = 1.1803, ||Grad|| = 1.2797, ||W|| = 1.2417\n",
            "Iteration 1806: Loss = 1.1788, ||Grad|| = 1.2783, ||W|| = 1.2405\n",
            "Iteration 1807: Loss = 1.1772, ||Grad|| = 1.2770, ||W|| = 1.2393\n",
            "Iteration 1808: Loss = 1.1757, ||Grad|| = 1.2757, ||W|| = 1.2381\n",
            "Iteration 1809: Loss = 1.1742, ||Grad|| = 1.2743, ||W|| = 1.2369\n",
            "Iteration 1810: Loss = 1.1727, ||Grad|| = 1.2730, ||W|| = 1.2358\n",
            "Iteration 1811: Loss = 1.1712, ||Grad|| = 1.2717, ||W|| = 1.2346\n",
            "Iteration 1812: Loss = 1.1697, ||Grad|| = 1.2704, ||W|| = 1.2334\n",
            "Iteration 1813: Loss = 1.1681, ||Grad|| = 1.2690, ||W|| = 1.2322\n",
            "Iteration 1814: Loss = 1.1666, ||Grad|| = 1.2677, ||W|| = 1.2311\n",
            "Iteration 1815: Loss = 1.1651, ||Grad|| = 1.2664, ||W|| = 1.2299\n",
            "Iteration 1816: Loss = 1.1637, ||Grad|| = 1.2651, ||W|| = 1.2287\n",
            "Iteration 1817: Loss = 1.1622, ||Grad|| = 1.2637, ||W|| = 1.2276\n",
            "Iteration 1818: Loss = 1.1607, ||Grad|| = 1.2624, ||W|| = 1.2264\n",
            "Iteration 1819: Loss = 1.1592, ||Grad|| = 1.2611, ||W|| = 1.2252\n",
            "Iteration 1820: Loss = 1.1577, ||Grad|| = 1.2598, ||W|| = 1.2241\n",
            "Iteration 1821: Loss = 1.1562, ||Grad|| = 1.2585, ||W|| = 1.2229\n",
            "Iteration 1822: Loss = 1.1547, ||Grad|| = 1.2571, ||W|| = 1.2218\n",
            "Iteration 1823: Loss = 1.1533, ||Grad|| = 1.2558, ||W|| = 1.2206\n",
            "Iteration 1824: Loss = 1.1518, ||Grad|| = 1.2545, ||W|| = 1.2194\n",
            "Iteration 1825: Loss = 1.1503, ||Grad|| = 1.2532, ||W|| = 1.2183\n",
            "Iteration 1826: Loss = 1.1489, ||Grad|| = 1.2519, ||W|| = 1.2171\n",
            "Iteration 1827: Loss = 1.1474, ||Grad|| = 1.2506, ||W|| = 1.2160\n",
            "Iteration 1828: Loss = 1.1460, ||Grad|| = 1.2493, ||W|| = 1.2148\n",
            "Iteration 1829: Loss = 1.1445, ||Grad|| = 1.2480, ||W|| = 1.2137\n",
            "Iteration 1830: Loss = 1.1431, ||Grad|| = 1.2467, ||W|| = 1.2125\n",
            "Iteration 1831: Loss = 1.1416, ||Grad|| = 1.2454, ||W|| = 1.2114\n",
            "Iteration 1832: Loss = 1.1402, ||Grad|| = 1.2441, ||W|| = 1.2102\n",
            "Iteration 1833: Loss = 1.1387, ||Grad|| = 1.2428, ||W|| = 1.2091\n",
            "Iteration 1834: Loss = 1.1373, ||Grad|| = 1.2415, ||W|| = 1.2079\n",
            "Iteration 1835: Loss = 1.1358, ||Grad|| = 1.2402, ||W|| = 1.2068\n",
            "Iteration 1836: Loss = 1.1344, ||Grad|| = 1.2389, ||W|| = 1.2057\n",
            "Iteration 1837: Loss = 1.1330, ||Grad|| = 1.2376, ||W|| = 1.2045\n",
            "Iteration 1838: Loss = 1.1316, ||Grad|| = 1.2363, ||W|| = 1.2034\n",
            "Iteration 1839: Loss = 1.1301, ||Grad|| = 1.2350, ||W|| = 1.2022\n",
            "Iteration 1840: Loss = 1.1287, ||Grad|| = 1.2337, ||W|| = 1.2011\n",
            "Iteration 1841: Loss = 1.1273, ||Grad|| = 1.2324, ||W|| = 1.2000\n",
            "Iteration 1842: Loss = 1.1259, ||Grad|| = 1.2311, ||W|| = 1.1988\n",
            "Iteration 1843: Loss = 1.1245, ||Grad|| = 1.2299, ||W|| = 1.1977\n",
            "Iteration 1844: Loss = 1.1231, ||Grad|| = 1.2286, ||W|| = 1.1966\n",
            "Iteration 1845: Loss = 1.1217, ||Grad|| = 1.2273, ||W|| = 1.1955\n",
            "Iteration 1846: Loss = 1.1203, ||Grad|| = 1.2260, ||W|| = 1.1943\n",
            "Iteration 1847: Loss = 1.1189, ||Grad|| = 1.2247, ||W|| = 1.1932\n",
            "Iteration 1848: Loss = 1.1175, ||Grad|| = 1.2234, ||W|| = 1.1921\n",
            "Iteration 1849: Loss = 1.1161, ||Grad|| = 1.2222, ||W|| = 1.1909\n",
            "Iteration 1850: Loss = 1.1147, ||Grad|| = 1.2209, ||W|| = 1.1898\n",
            "Iteration 1851: Loss = 1.1133, ||Grad|| = 1.2196, ||W|| = 1.1887\n",
            "Iteration 1852: Loss = 1.1119, ||Grad|| = 1.2183, ||W|| = 1.1876\n",
            "Iteration 1853: Loss = 1.1106, ||Grad|| = 1.2171, ||W|| = 1.1865\n",
            "Iteration 1854: Loss = 1.1092, ||Grad|| = 1.2158, ||W|| = 1.1854\n",
            "Iteration 1855: Loss = 1.1078, ||Grad|| = 1.2145, ||W|| = 1.1842\n",
            "Iteration 1856: Loss = 1.1064, ||Grad|| = 1.2133, ||W|| = 1.1831\n",
            "Iteration 1857: Loss = 1.1051, ||Grad|| = 1.2120, ||W|| = 1.1820\n",
            "Iteration 1858: Loss = 1.1037, ||Grad|| = 1.2107, ||W|| = 1.1809\n",
            "Iteration 1859: Loss = 1.1023, ||Grad|| = 1.2095, ||W|| = 1.1798\n",
            "Iteration 1860: Loss = 1.1010, ||Grad|| = 1.2082, ||W|| = 1.1787\n",
            "Iteration 1861: Loss = 1.0996, ||Grad|| = 1.2069, ||W|| = 1.1776\n",
            "Iteration 1862: Loss = 1.0983, ||Grad|| = 1.2057, ||W|| = 1.1765\n",
            "Iteration 1863: Loss = 1.0969, ||Grad|| = 1.2044, ||W|| = 1.1754\n",
            "Iteration 1864: Loss = 1.0956, ||Grad|| = 1.2031, ||W|| = 1.1743\n",
            "Iteration 1865: Loss = 1.0942, ||Grad|| = 1.2019, ||W|| = 1.1732\n",
            "Iteration 1866: Loss = 1.0929, ||Grad|| = 1.2006, ||W|| = 1.1721\n",
            "Iteration 1867: Loss = 1.0916, ||Grad|| = 1.1994, ||W|| = 1.1710\n",
            "Iteration 1868: Loss = 1.0902, ||Grad|| = 1.1981, ||W|| = 1.1699\n",
            "Iteration 1869: Loss = 1.0889, ||Grad|| = 1.1969, ||W|| = 1.1688\n",
            "Iteration 1870: Loss = 1.0876, ||Grad|| = 1.1956, ||W|| = 1.1677\n",
            "Iteration 1871: Loss = 1.0862, ||Grad|| = 1.1944, ||W|| = 1.1666\n",
            "Iteration 1872: Loss = 1.0849, ||Grad|| = 1.1931, ||W|| = 1.1655\n",
            "Iteration 1873: Loss = 1.0836, ||Grad|| = 1.1919, ||W|| = 1.1644\n",
            "Iteration 1874: Loss = 1.0823, ||Grad|| = 1.1906, ||W|| = 1.1633\n",
            "Iteration 1875: Loss = 1.0810, ||Grad|| = 1.1894, ||W|| = 1.1622\n",
            "Iteration 1876: Loss = 1.0796, ||Grad|| = 1.1881, ||W|| = 1.1611\n",
            "Iteration 1877: Loss = 1.0783, ||Grad|| = 1.1869, ||W|| = 1.1600\n",
            "Iteration 1878: Loss = 1.0770, ||Grad|| = 1.1857, ||W|| = 1.1590\n",
            "Iteration 1879: Loss = 1.0757, ||Grad|| = 1.1844, ||W|| = 1.1579\n",
            "Iteration 1880: Loss = 1.0744, ||Grad|| = 1.1832, ||W|| = 1.1568\n",
            "Iteration 1881: Loss = 1.0731, ||Grad|| = 1.1820, ||W|| = 1.1557\n",
            "Iteration 1882: Loss = 1.0718, ||Grad|| = 1.1807, ||W|| = 1.1546\n",
            "Iteration 1883: Loss = 1.0705, ||Grad|| = 1.1795, ||W|| = 1.1536\n",
            "Iteration 1884: Loss = 1.0693, ||Grad|| = 1.1783, ||W|| = 1.1525\n",
            "Iteration 1885: Loss = 1.0680, ||Grad|| = 1.1770, ||W|| = 1.1514\n",
            "Iteration 1886: Loss = 1.0667, ||Grad|| = 1.1758, ||W|| = 1.1503\n",
            "Iteration 1887: Loss = 1.0654, ||Grad|| = 1.1746, ||W|| = 1.1493\n",
            "Iteration 1888: Loss = 1.0641, ||Grad|| = 1.1733, ||W|| = 1.1482\n",
            "Iteration 1889: Loss = 1.0629, ||Grad|| = 1.1721, ||W|| = 1.1471\n",
            "Iteration 1890: Loss = 1.0616, ||Grad|| = 1.1709, ||W|| = 1.1460\n",
            "Iteration 1891: Loss = 1.0603, ||Grad|| = 1.1697, ||W|| = 1.1450\n",
            "Iteration 1892: Loss = 1.0590, ||Grad|| = 1.1684, ||W|| = 1.1439\n",
            "Iteration 1893: Loss = 1.0578, ||Grad|| = 1.1672, ||W|| = 1.1428\n",
            "Iteration 1894: Loss = 1.0565, ||Grad|| = 1.1660, ||W|| = 1.1418\n",
            "Iteration 1895: Loss = 1.0553, ||Grad|| = 1.1648, ||W|| = 1.1407\n",
            "Iteration 1896: Loss = 1.0540, ||Grad|| = 1.1636, ||W|| = 1.1397\n",
            "Iteration 1897: Loss = 1.0528, ||Grad|| = 1.1623, ||W|| = 1.1386\n",
            "Iteration 1898: Loss = 1.0515, ||Grad|| = 1.1611, ||W|| = 1.1375\n",
            "Iteration 1899: Loss = 1.0503, ||Grad|| = 1.1599, ||W|| = 1.1365\n",
            "Iteration 1900: Loss = 1.0490, ||Grad|| = 1.1587, ||W|| = 1.1354\n",
            "Iteration 1901: Loss = 1.0478, ||Grad|| = 1.1575, ||W|| = 1.1344\n",
            "Iteration 1902: Loss = 1.0465, ||Grad|| = 1.1563, ||W|| = 1.1333\n",
            "Iteration 1903: Loss = 1.0453, ||Grad|| = 1.1551, ||W|| = 1.1323\n",
            "Iteration 1904: Loss = 1.0441, ||Grad|| = 1.1539, ||W|| = 1.1312\n",
            "Iteration 1905: Loss = 1.0428, ||Grad|| = 1.1527, ||W|| = 1.1302\n",
            "Iteration 1906: Loss = 1.0416, ||Grad|| = 1.1515, ||W|| = 1.1291\n",
            "Iteration 1907: Loss = 1.0404, ||Grad|| = 1.1503, ||W|| = 1.1281\n",
            "Iteration 1908: Loss = 1.0392, ||Grad|| = 1.1491, ||W|| = 1.1270\n",
            "Iteration 1909: Loss = 1.0379, ||Grad|| = 1.1479, ||W|| = 1.1260\n",
            "Iteration 1910: Loss = 1.0367, ||Grad|| = 1.1467, ||W|| = 1.1249\n",
            "Iteration 1911: Loss = 1.0355, ||Grad|| = 1.1455, ||W|| = 1.1239\n",
            "Iteration 1912: Loss = 1.0343, ||Grad|| = 1.1443, ||W|| = 1.1228\n",
            "Iteration 1913: Loss = 1.0331, ||Grad|| = 1.1431, ||W|| = 1.1218\n",
            "Iteration 1914: Loss = 1.0319, ||Grad|| = 1.1419, ||W|| = 1.1208\n",
            "Iteration 1915: Loss = 1.0307, ||Grad|| = 1.1407, ||W|| = 1.1197\n",
            "Iteration 1916: Loss = 1.0295, ||Grad|| = 1.1395, ||W|| = 1.1187\n",
            "Iteration 1917: Loss = 1.0283, ||Grad|| = 1.1383, ||W|| = 1.1177\n",
            "Iteration 1918: Loss = 1.0271, ||Grad|| = 1.1371, ||W|| = 1.1166\n",
            "Iteration 1919: Loss = 1.0259, ||Grad|| = 1.1359, ||W|| = 1.1156\n",
            "Iteration 1920: Loss = 1.0247, ||Grad|| = 1.1347, ||W|| = 1.1146\n",
            "Iteration 1921: Loss = 1.0235, ||Grad|| = 1.1335, ||W|| = 1.1135\n",
            "Iteration 1922: Loss = 1.0223, ||Grad|| = 1.1324, ||W|| = 1.1125\n",
            "Iteration 1923: Loss = 1.0211, ||Grad|| = 1.1312, ||W|| = 1.1115\n",
            "Iteration 1924: Loss = 1.0199, ||Grad|| = 1.1300, ||W|| = 1.1105\n",
            "Iteration 1925: Loss = 1.0188, ||Grad|| = 1.1288, ||W|| = 1.1094\n",
            "Iteration 1926: Loss = 1.0176, ||Grad|| = 1.1276, ||W|| = 1.1084\n",
            "Iteration 1927: Loss = 1.0164, ||Grad|| = 1.1265, ||W|| = 1.1074\n",
            "Iteration 1928: Loss = 1.0153, ||Grad|| = 1.1253, ||W|| = 1.1064\n",
            "Iteration 1929: Loss = 1.0141, ||Grad|| = 1.1241, ||W|| = 1.1053\n",
            "Iteration 1930: Loss = 1.0129, ||Grad|| = 1.1229, ||W|| = 1.1043\n",
            "Iteration 1931: Loss = 1.0118, ||Grad|| = 1.1218, ||W|| = 1.1033\n",
            "Iteration 1932: Loss = 1.0106, ||Grad|| = 1.1206, ||W|| = 1.1023\n",
            "Iteration 1933: Loss = 1.0094, ||Grad|| = 1.1194, ||W|| = 1.1013\n",
            "Iteration 1934: Loss = 1.0083, ||Grad|| = 1.1182, ||W|| = 1.1003\n",
            "Iteration 1935: Loss = 1.0071, ||Grad|| = 1.1171, ||W|| = 1.0993\n",
            "Iteration 1936: Loss = 1.0060, ||Grad|| = 1.1159, ||W|| = 1.0982\n",
            "Iteration 1937: Loss = 1.0048, ||Grad|| = 1.1147, ||W|| = 1.0972\n",
            "Iteration 1938: Loss = 1.0037, ||Grad|| = 1.1136, ||W|| = 1.0962\n",
            "Iteration 1939: Loss = 1.0025, ||Grad|| = 1.1124, ||W|| = 1.0952\n",
            "Iteration 1940: Loss = 1.0014, ||Grad|| = 1.1113, ||W|| = 1.0942\n",
            "Iteration 1941: Loss = 1.0003, ||Grad|| = 1.1101, ||W|| = 1.0932\n",
            "Iteration 1942: Loss = 0.9991, ||Grad|| = 1.1089, ||W|| = 1.0922\n",
            "Iteration 1943: Loss = 0.9980, ||Grad|| = 1.1078, ||W|| = 1.0912\n",
            "Iteration 1944: Loss = 0.9969, ||Grad|| = 1.1066, ||W|| = 1.0902\n",
            "Iteration 1945: Loss = 0.9957, ||Grad|| = 1.1055, ||W|| = 1.0892\n",
            "Iteration 1946: Loss = 0.9946, ||Grad|| = 1.1043, ||W|| = 1.0882\n",
            "Iteration 1947: Loss = 0.9935, ||Grad|| = 1.1032, ||W|| = 1.0872\n",
            "Iteration 1948: Loss = 0.9924, ||Grad|| = 1.1020, ||W|| = 1.0862\n",
            "Iteration 1949: Loss = 0.9913, ||Grad|| = 1.1008, ||W|| = 1.0852\n",
            "Iteration 1950: Loss = 0.9901, ||Grad|| = 1.0997, ||W|| = 1.0842\n",
            "Iteration 1951: Loss = 0.9890, ||Grad|| = 1.0985, ||W|| = 1.0832\n",
            "Iteration 1952: Loss = 0.9879, ||Grad|| = 1.0974, ||W|| = 1.0822\n",
            "Iteration 1953: Loss = 0.9868, ||Grad|| = 1.0963, ||W|| = 1.0813\n",
            "Iteration 1954: Loss = 0.9857, ||Grad|| = 1.0951, ||W|| = 1.0803\n",
            "Iteration 1955: Loss = 0.9846, ||Grad|| = 1.0940, ||W|| = 1.0793\n",
            "Iteration 1956: Loss = 0.9835, ||Grad|| = 1.0928, ||W|| = 1.0783\n",
            "Iteration 1957: Loss = 0.9824, ||Grad|| = 1.0917, ||W|| = 1.0773\n",
            "Iteration 1958: Loss = 0.9813, ||Grad|| = 1.0905, ||W|| = 1.0763\n",
            "Iteration 1959: Loss = 0.9802, ||Grad|| = 1.0894, ||W|| = 1.0753\n",
            "Iteration 1960: Loss = 0.9791, ||Grad|| = 1.0883, ||W|| = 1.0744\n",
            "Iteration 1961: Loss = 0.9780, ||Grad|| = 1.0871, ||W|| = 1.0734\n",
            "Iteration 1962: Loss = 0.9769, ||Grad|| = 1.0860, ||W|| = 1.0724\n",
            "Iteration 1963: Loss = 0.9759, ||Grad|| = 1.0849, ||W|| = 1.0714\n",
            "Iteration 1964: Loss = 0.9748, ||Grad|| = 1.0837, ||W|| = 1.0704\n",
            "Iteration 1965: Loss = 0.9737, ||Grad|| = 1.0826, ||W|| = 1.0695\n",
            "Iteration 1966: Loss = 0.9726, ||Grad|| = 1.0815, ||W|| = 1.0685\n",
            "Iteration 1967: Loss = 0.9716, ||Grad|| = 1.0803, ||W|| = 1.0675\n",
            "Iteration 1968: Loss = 0.9705, ||Grad|| = 1.0792, ||W|| = 1.0666\n",
            "Iteration 1969: Loss = 0.9694, ||Grad|| = 1.0781, ||W|| = 1.0656\n",
            "Iteration 1970: Loss = 0.9683, ||Grad|| = 1.0769, ||W|| = 1.0646\n",
            "Iteration 1971: Loss = 0.9673, ||Grad|| = 1.0758, ||W|| = 1.0636\n",
            "Iteration 1972: Loss = 0.9662, ||Grad|| = 1.0747, ||W|| = 1.0627\n",
            "Iteration 1973: Loss = 0.9652, ||Grad|| = 1.0736, ||W|| = 1.0617\n",
            "Iteration 1974: Loss = 0.9641, ||Grad|| = 1.0725, ||W|| = 1.0607\n",
            "Iteration 1975: Loss = 0.9630, ||Grad|| = 1.0713, ||W|| = 1.0598\n",
            "Iteration 1976: Loss = 0.9620, ||Grad|| = 1.0702, ||W|| = 1.0588\n",
            "Iteration 1977: Loss = 0.9609, ||Grad|| = 1.0691, ||W|| = 1.0579\n",
            "Iteration 1978: Loss = 0.9599, ||Grad|| = 1.0680, ||W|| = 1.0569\n",
            "Iteration 1979: Loss = 0.9588, ||Grad|| = 1.0669, ||W|| = 1.0559\n",
            "Iteration 1980: Loss = 0.9578, ||Grad|| = 1.0658, ||W|| = 1.0550\n",
            "Iteration 1981: Loss = 0.9568, ||Grad|| = 1.0646, ||W|| = 1.0540\n",
            "Iteration 1982: Loss = 0.9557, ||Grad|| = 1.0635, ||W|| = 1.0531\n",
            "Iteration 1983: Loss = 0.9547, ||Grad|| = 1.0624, ||W|| = 1.0521\n",
            "Iteration 1984: Loss = 0.9536, ||Grad|| = 1.0613, ||W|| = 1.0512\n",
            "Iteration 1985: Loss = 0.9526, ||Grad|| = 1.0602, ||W|| = 1.0502\n",
            "Iteration 1986: Loss = 0.9516, ||Grad|| = 1.0591, ||W|| = 1.0493\n",
            "Iteration 1987: Loss = 0.9506, ||Grad|| = 1.0580, ||W|| = 1.0483\n",
            "Iteration 1988: Loss = 0.9495, ||Grad|| = 1.0569, ||W|| = 1.0474\n",
            "Iteration 1989: Loss = 0.9485, ||Grad|| = 1.0558, ||W|| = 1.0464\n",
            "Iteration 1990: Loss = 0.9475, ||Grad|| = 1.0547, ||W|| = 1.0455\n",
            "Iteration 1991: Loss = 0.9465, ||Grad|| = 1.0536, ||W|| = 1.0445\n",
            "Iteration 1992: Loss = 0.9455, ||Grad|| = 1.0525, ||W|| = 1.0436\n",
            "Iteration 1993: Loss = 0.9444, ||Grad|| = 1.0514, ||W|| = 1.0427\n",
            "Iteration 1994: Loss = 0.9434, ||Grad|| = 1.0503, ||W|| = 1.0417\n",
            "Iteration 1995: Loss = 0.9424, ||Grad|| = 1.0492, ||W|| = 1.0408\n",
            "Iteration 1996: Loss = 0.9414, ||Grad|| = 1.0481, ||W|| = 1.0398\n",
            "Iteration 1997: Loss = 0.9404, ||Grad|| = 1.0470, ||W|| = 1.0389\n",
            "Iteration 1998: Loss = 0.9394, ||Grad|| = 1.0459, ||W|| = 1.0380\n",
            "Iteration 1999: Loss = 0.9384, ||Grad|| = 1.0448, ||W|| = 1.0370\n",
            "Iteration 2000: Loss = 0.9374, ||Grad|| = 1.0437, ||W|| = 1.0361\n",
            "Iteration 2001: Loss = 0.9364, ||Grad|| = 1.0426, ||W|| = 1.0352\n",
            "Iteration 2002: Loss = 0.9354, ||Grad|| = 1.0415, ||W|| = 1.0342\n",
            "Iteration 2003: Loss = 0.9344, ||Grad|| = 1.0404, ||W|| = 1.0333\n",
            "Iteration 2004: Loss = 0.9334, ||Grad|| = 1.0394, ||W|| = 1.0324\n",
            "Iteration 2005: Loss = 0.9324, ||Grad|| = 1.0383, ||W|| = 1.0314\n",
            "Iteration 2006: Loss = 0.9314, ||Grad|| = 1.0372, ||W|| = 1.0305\n",
            "Iteration 2007: Loss = 0.9305, ||Grad|| = 1.0361, ||W|| = 1.0296\n",
            "Iteration 2008: Loss = 0.9295, ||Grad|| = 1.0350, ||W|| = 1.0287\n",
            "Iteration 2009: Loss = 0.9285, ||Grad|| = 1.0339, ||W|| = 1.0277\n",
            "Iteration 2010: Loss = 0.9275, ||Grad|| = 1.0329, ||W|| = 1.0268\n",
            "Iteration 2011: Loss = 0.9266, ||Grad|| = 1.0318, ||W|| = 1.0259\n",
            "Iteration 2012: Loss = 0.9256, ||Grad|| = 1.0307, ||W|| = 1.0250\n",
            "Iteration 2013: Loss = 0.9246, ||Grad|| = 1.0296, ||W|| = 1.0241\n",
            "Iteration 2014: Loss = 0.9236, ||Grad|| = 1.0286, ||W|| = 1.0231\n",
            "Iteration 2015: Loss = 0.9227, ||Grad|| = 1.0275, ||W|| = 1.0222\n",
            "Iteration 2016: Loss = 0.9217, ||Grad|| = 1.0264, ||W|| = 1.0213\n",
            "Iteration 2017: Loss = 0.9207, ||Grad|| = 1.0253, ||W|| = 1.0204\n",
            "Iteration 2018: Loss = 0.9198, ||Grad|| = 1.0243, ||W|| = 1.0195\n",
            "Iteration 2019: Loss = 0.9188, ||Grad|| = 1.0232, ||W|| = 1.0186\n",
            "Iteration 2020: Loss = 0.9179, ||Grad|| = 1.0221, ||W|| = 1.0177\n",
            "Iteration 2021: Loss = 0.9169, ||Grad|| = 1.0211, ||W|| = 1.0167\n",
            "Iteration 2022: Loss = 0.9160, ||Grad|| = 1.0200, ||W|| = 1.0158\n",
            "Iteration 2023: Loss = 0.9150, ||Grad|| = 1.0189, ||W|| = 1.0149\n",
            "Iteration 2024: Loss = 0.9141, ||Grad|| = 1.0179, ||W|| = 1.0140\n",
            "Iteration 2025: Loss = 0.9131, ||Grad|| = 1.0168, ||W|| = 1.0131\n",
            "Iteration 2026: Loss = 0.9122, ||Grad|| = 1.0157, ||W|| = 1.0122\n",
            "Iteration 2027: Loss = 0.9112, ||Grad|| = 1.0147, ||W|| = 1.0113\n",
            "Iteration 2028: Loss = 0.9103, ||Grad|| = 1.0136, ||W|| = 1.0104\n",
            "Iteration 2029: Loss = 0.9094, ||Grad|| = 1.0126, ||W|| = 1.0095\n",
            "Iteration 2030: Loss = 0.9084, ||Grad|| = 1.0115, ||W|| = 1.0086\n",
            "Iteration 2031: Loss = 0.9075, ||Grad|| = 1.0105, ||W|| = 1.0077\n",
            "Iteration 2032: Loss = 0.9066, ||Grad|| = 1.0094, ||W|| = 1.0068\n",
            "Iteration 2033: Loss = 0.9056, ||Grad|| = 1.0084, ||W|| = 1.0059\n",
            "Iteration 2034: Loss = 0.9047, ||Grad|| = 1.0073, ||W|| = 1.0050\n",
            "Iteration 2035: Loss = 0.9038, ||Grad|| = 1.0062, ||W|| = 1.0041\n",
            "Iteration 2036: Loss = 0.9029, ||Grad|| = 1.0052, ||W|| = 1.0032\n",
            "Iteration 2037: Loss = 0.9019, ||Grad|| = 1.0041, ||W|| = 1.0024\n",
            "Iteration 2038: Loss = 0.9010, ||Grad|| = 1.0031, ||W|| = 1.0015\n",
            "Iteration 2039: Loss = 0.9001, ||Grad|| = 1.0021, ||W|| = 1.0006\n",
            "Iteration 2040: Loss = 0.8992, ||Grad|| = 1.0010, ||W|| = 0.9997\n",
            "Iteration 2041: Loss = 0.8983, ||Grad|| = 1.0000, ||W|| = 0.9988\n",
            "Iteration 2042: Loss = 0.8974, ||Grad|| = 0.9989, ||W|| = 0.9979\n",
            "Iteration 2043: Loss = 0.8965, ||Grad|| = 0.9979, ||W|| = 0.9970\n",
            "Iteration 2044: Loss = 0.8955, ||Grad|| = 0.9968, ||W|| = 0.9961\n",
            "Iteration 2045: Loss = 0.8946, ||Grad|| = 0.9958, ||W|| = 0.9953\n",
            "Iteration 2046: Loss = 0.8937, ||Grad|| = 0.9948, ||W|| = 0.9944\n",
            "Iteration 2047: Loss = 0.8928, ||Grad|| = 0.9937, ||W|| = 0.9935\n",
            "Iteration 2048: Loss = 0.8919, ||Grad|| = 0.9927, ||W|| = 0.9926\n",
            "Iteration 2049: Loss = 0.8910, ||Grad|| = 0.9916, ||W|| = 0.9917\n",
            "Iteration 2050: Loss = 0.8901, ||Grad|| = 0.9906, ||W|| = 0.9909\n",
            "Iteration 2051: Loss = 0.8893, ||Grad|| = 0.9896, ||W|| = 0.9900\n",
            "Iteration 2052: Loss = 0.8884, ||Grad|| = 0.9885, ||W|| = 0.9891\n",
            "Iteration 2053: Loss = 0.8875, ||Grad|| = 0.9875, ||W|| = 0.9882\n",
            "Iteration 2054: Loss = 0.8866, ||Grad|| = 0.9865, ||W|| = 0.9874\n",
            "Iteration 2055: Loss = 0.8857, ||Grad|| = 0.9855, ||W|| = 0.9865\n",
            "Iteration 2056: Loss = 0.8848, ||Grad|| = 0.9844, ||W|| = 0.9856\n",
            "Iteration 2057: Loss = 0.8839, ||Grad|| = 0.9834, ||W|| = 0.9848\n",
            "Iteration 2058: Loss = 0.8831, ||Grad|| = 0.9824, ||W|| = 0.9839\n",
            "Iteration 2059: Loss = 0.8822, ||Grad|| = 0.9813, ||W|| = 0.9830\n",
            "Iteration 2060: Loss = 0.8813, ||Grad|| = 0.9803, ||W|| = 0.9822\n",
            "Iteration 2061: Loss = 0.8804, ||Grad|| = 0.9793, ||W|| = 0.9813\n",
            "Iteration 2062: Loss = 0.8796, ||Grad|| = 0.9783, ||W|| = 0.9804\n",
            "Iteration 2063: Loss = 0.8787, ||Grad|| = 0.9773, ||W|| = 0.9796\n",
            "Iteration 2064: Loss = 0.8778, ||Grad|| = 0.9762, ||W|| = 0.9787\n",
            "Iteration 2065: Loss = 0.8770, ||Grad|| = 0.9752, ||W|| = 0.9778\n",
            "Iteration 2066: Loss = 0.8761, ||Grad|| = 0.9742, ||W|| = 0.9770\n",
            "Iteration 2067: Loss = 0.8752, ||Grad|| = 0.9732, ||W|| = 0.9761\n",
            "Iteration 2068: Loss = 0.8744, ||Grad|| = 0.9722, ||W|| = 0.9753\n",
            "Iteration 2069: Loss = 0.8735, ||Grad|| = 0.9712, ||W|| = 0.9744\n",
            "Iteration 2070: Loss = 0.8727, ||Grad|| = 0.9701, ||W|| = 0.9736\n",
            "Iteration 2071: Loss = 0.8718, ||Grad|| = 0.9691, ||W|| = 0.9727\n",
            "Iteration 2072: Loss = 0.8710, ||Grad|| = 0.9681, ||W|| = 0.9719\n",
            "Iteration 2073: Loss = 0.8701, ||Grad|| = 0.9671, ||W|| = 0.9710\n",
            "Iteration 2074: Loss = 0.8693, ||Grad|| = 0.9661, ||W|| = 0.9702\n",
            "Iteration 2075: Loss = 0.8684, ||Grad|| = 0.9651, ||W|| = 0.9693\n",
            "Iteration 2076: Loss = 0.8676, ||Grad|| = 0.9641, ||W|| = 0.9685\n",
            "Iteration 2077: Loss = 0.8667, ||Grad|| = 0.9631, ||W|| = 0.9676\n",
            "Iteration 2078: Loss = 0.8659, ||Grad|| = 0.9621, ||W|| = 0.9668\n",
            "Iteration 2079: Loss = 0.8650, ||Grad|| = 0.9611, ||W|| = 0.9659\n",
            "Iteration 2080: Loss = 0.8642, ||Grad|| = 0.9601, ||W|| = 0.9651\n",
            "Iteration 2081: Loss = 0.8634, ||Grad|| = 0.9591, ||W|| = 0.9642\n",
            "Iteration 2082: Loss = 0.8625, ||Grad|| = 0.9581, ||W|| = 0.9634\n",
            "Iteration 2083: Loss = 0.8617, ||Grad|| = 0.9571, ||W|| = 0.9625\n",
            "Iteration 2084: Loss = 0.8609, ||Grad|| = 0.9561, ||W|| = 0.9617\n",
            "Iteration 2085: Loss = 0.8600, ||Grad|| = 0.9551, ||W|| = 0.9609\n",
            "Iteration 2086: Loss = 0.8592, ||Grad|| = 0.9541, ||W|| = 0.9600\n",
            "Iteration 2087: Loss = 0.8584, ||Grad|| = 0.9531, ||W|| = 0.9592\n",
            "Iteration 2088: Loss = 0.8576, ||Grad|| = 0.9521, ||W|| = 0.9584\n",
            "Iteration 2089: Loss = 0.8567, ||Grad|| = 0.9511, ||W|| = 0.9575\n",
            "Iteration 2090: Loss = 0.8559, ||Grad|| = 0.9501, ||W|| = 0.9567\n",
            "Iteration 2091: Loss = 0.8551, ||Grad|| = 0.9491, ||W|| = 0.9559\n",
            "Iteration 2092: Loss = 0.8543, ||Grad|| = 0.9481, ||W|| = 0.9550\n",
            "Iteration 2093: Loss = 0.8535, ||Grad|| = 0.9471, ||W|| = 0.9542\n",
            "Iteration 2094: Loss = 0.8527, ||Grad|| = 0.9462, ||W|| = 0.9534\n",
            "Iteration 2095: Loss = 0.8519, ||Grad|| = 0.9452, ||W|| = 0.9525\n",
            "Iteration 2096: Loss = 0.8510, ||Grad|| = 0.9442, ||W|| = 0.9517\n",
            "Iteration 2097: Loss = 0.8502, ||Grad|| = 0.9432, ||W|| = 0.9509\n",
            "Iteration 2098: Loss = 0.8494, ||Grad|| = 0.9422, ||W|| = 0.9501\n",
            "Iteration 2099: Loss = 0.8486, ||Grad|| = 0.9412, ||W|| = 0.9492\n",
            "Iteration 2100: Loss = 0.8478, ||Grad|| = 0.9403, ||W|| = 0.9484\n",
            "Iteration 2101: Loss = 0.8470, ||Grad|| = 0.9393, ||W|| = 0.9476\n",
            "Iteration 2102: Loss = 0.8462, ||Grad|| = 0.9383, ||W|| = 0.9468\n",
            "Iteration 2103: Loss = 0.8454, ||Grad|| = 0.9373, ||W|| = 0.9460\n",
            "Iteration 2104: Loss = 0.8446, ||Grad|| = 0.9363, ||W|| = 0.9451\n",
            "Iteration 2105: Loss = 0.8438, ||Grad|| = 0.9354, ||W|| = 0.9443\n",
            "Iteration 2106: Loss = 0.8431, ||Grad|| = 0.9344, ||W|| = 0.9435\n",
            "Iteration 2107: Loss = 0.8423, ||Grad|| = 0.9334, ||W|| = 0.9427\n",
            "Iteration 2108: Loss = 0.8415, ||Grad|| = 0.9324, ||W|| = 0.9419\n",
            "Iteration 2109: Loss = 0.8407, ||Grad|| = 0.9315, ||W|| = 0.9411\n",
            "Iteration 2110: Loss = 0.8399, ||Grad|| = 0.9305, ||W|| = 0.9403\n",
            "Iteration 2111: Loss = 0.8391, ||Grad|| = 0.9295, ||W|| = 0.9394\n",
            "Iteration 2112: Loss = 0.8383, ||Grad|| = 0.9286, ||W|| = 0.9386\n",
            "Iteration 2113: Loss = 0.8376, ||Grad|| = 0.9276, ||W|| = 0.9378\n",
            "Iteration 2114: Loss = 0.8368, ||Grad|| = 0.9266, ||W|| = 0.9370\n",
            "Iteration 2115: Loss = 0.8360, ||Grad|| = 0.9257, ||W|| = 0.9362\n",
            "Iteration 2116: Loss = 0.8352, ||Grad|| = 0.9247, ||W|| = 0.9354\n",
            "Iteration 2117: Loss = 0.8345, ||Grad|| = 0.9237, ||W|| = 0.9346\n",
            "Iteration 2118: Loss = 0.8337, ||Grad|| = 0.9228, ||W|| = 0.9338\n",
            "Iteration 2119: Loss = 0.8329, ||Grad|| = 0.9218, ||W|| = 0.9330\n",
            "Iteration 2120: Loss = 0.8322, ||Grad|| = 0.9209, ||W|| = 0.9322\n",
            "Iteration 2121: Loss = 0.8314, ||Grad|| = 0.9199, ||W|| = 0.9314\n",
            "Iteration 2122: Loss = 0.8306, ||Grad|| = 0.9189, ||W|| = 0.9306\n",
            "Iteration 2123: Loss = 0.8299, ||Grad|| = 0.9180, ||W|| = 0.9298\n",
            "Iteration 2124: Loss = 0.8291, ||Grad|| = 0.9170, ||W|| = 0.9290\n",
            "Iteration 2125: Loss = 0.8284, ||Grad|| = 0.9161, ||W|| = 0.9282\n",
            "Iteration 2126: Loss = 0.8276, ||Grad|| = 0.9151, ||W|| = 0.9274\n",
            "Iteration 2127: Loss = 0.8268, ||Grad|| = 0.9142, ||W|| = 0.9266\n",
            "Iteration 2128: Loss = 0.8261, ||Grad|| = 0.9132, ||W|| = 0.9258\n",
            "Iteration 2129: Loss = 0.8253, ||Grad|| = 0.9123, ||W|| = 0.9250\n",
            "Iteration 2130: Loss = 0.8246, ||Grad|| = 0.9113, ||W|| = 0.9242\n",
            "Iteration 2131: Loss = 0.8238, ||Grad|| = 0.9104, ||W|| = 0.9234\n",
            "Iteration 2132: Loss = 0.8231, ||Grad|| = 0.9094, ||W|| = 0.9227\n",
            "Iteration 2133: Loss = 0.8224, ||Grad|| = 0.9085, ||W|| = 0.9219\n",
            "Iteration 2134: Loss = 0.8216, ||Grad|| = 0.9075, ||W|| = 0.9211\n",
            "Iteration 2135: Loss = 0.8209, ||Grad|| = 0.9066, ||W|| = 0.9203\n",
            "Iteration 2136: Loss = 0.8201, ||Grad|| = 0.9056, ||W|| = 0.9195\n",
            "Iteration 2137: Loss = 0.8194, ||Grad|| = 0.9047, ||W|| = 0.9187\n",
            "Iteration 2138: Loss = 0.8187, ||Grad|| = 0.9037, ||W|| = 0.9179\n",
            "Iteration 2139: Loss = 0.8179, ||Grad|| = 0.9028, ||W|| = 0.9172\n",
            "Iteration 2140: Loss = 0.8172, ||Grad|| = 0.9019, ||W|| = 0.9164\n",
            "Iteration 2141: Loss = 0.8164, ||Grad|| = 0.9009, ||W|| = 0.9156\n",
            "Iteration 2142: Loss = 0.8157, ||Grad|| = 0.9000, ||W|| = 0.9148\n",
            "Iteration 2143: Loss = 0.8150, ||Grad|| = 0.8990, ||W|| = 0.9140\n",
            "Iteration 2144: Loss = 0.8143, ||Grad|| = 0.8981, ||W|| = 0.9133\n",
            "Iteration 2145: Loss = 0.8135, ||Grad|| = 0.8972, ||W|| = 0.9125\n",
            "Iteration 2146: Loss = 0.8128, ||Grad|| = 0.8962, ||W|| = 0.9117\n",
            "Iteration 2147: Loss = 0.8121, ||Grad|| = 0.8953, ||W|| = 0.9109\n",
            "Iteration 2148: Loss = 0.8114, ||Grad|| = 0.8944, ||W|| = 0.9102\n",
            "Iteration 2149: Loss = 0.8107, ||Grad|| = 0.8934, ||W|| = 0.9094\n",
            "Iteration 2150: Loss = 0.8099, ||Grad|| = 0.8925, ||W|| = 0.9086\n",
            "Iteration 2151: Loss = 0.8092, ||Grad|| = 0.8916, ||W|| = 0.9078\n",
            "Iteration 2152: Loss = 0.8085, ||Grad|| = 0.8907, ||W|| = 0.9071\n",
            "Iteration 2153: Loss = 0.8078, ||Grad|| = 0.8897, ||W|| = 0.9063\n",
            "Iteration 2154: Loss = 0.8071, ||Grad|| = 0.8888, ||W|| = 0.9055\n",
            "Iteration 2155: Loss = 0.8064, ||Grad|| = 0.8879, ||W|| = 0.9048\n",
            "Iteration 2156: Loss = 0.8057, ||Grad|| = 0.8870, ||W|| = 0.9040\n",
            "Iteration 2157: Loss = 0.8050, ||Grad|| = 0.8860, ||W|| = 0.9032\n",
            "Iteration 2158: Loss = 0.8042, ||Grad|| = 0.8851, ||W|| = 0.9025\n",
            "Iteration 2159: Loss = 0.8035, ||Grad|| = 0.8842, ||W|| = 0.9017\n",
            "Iteration 2160: Loss = 0.8028, ||Grad|| = 0.8833, ||W|| = 0.9010\n",
            "Iteration 2161: Loss = 0.8021, ||Grad|| = 0.8823, ||W|| = 0.9002\n",
            "Iteration 2162: Loss = 0.8014, ||Grad|| = 0.8814, ||W|| = 0.8994\n",
            "Iteration 2163: Loss = 0.8007, ||Grad|| = 0.8805, ||W|| = 0.8987\n",
            "Iteration 2164: Loss = 0.8001, ||Grad|| = 0.8796, ||W|| = 0.8979\n",
            "Iteration 2165: Loss = 0.7994, ||Grad|| = 0.8787, ||W|| = 0.8972\n",
            "Iteration 2166: Loss = 0.7987, ||Grad|| = 0.8778, ||W|| = 0.8964\n",
            "Iteration 2167: Loss = 0.7980, ||Grad|| = 0.8769, ||W|| = 0.8957\n",
            "Iteration 2168: Loss = 0.7973, ||Grad|| = 0.8759, ||W|| = 0.8949\n",
            "Iteration 2169: Loss = 0.7966, ||Grad|| = 0.8750, ||W|| = 0.8942\n",
            "Iteration 2170: Loss = 0.7959, ||Grad|| = 0.8741, ||W|| = 0.8934\n",
            "Iteration 2171: Loss = 0.7952, ||Grad|| = 0.8732, ||W|| = 0.8927\n",
            "Iteration 2172: Loss = 0.7945, ||Grad|| = 0.8723, ||W|| = 0.8919\n",
            "Iteration 2173: Loss = 0.7939, ||Grad|| = 0.8714, ||W|| = 0.8912\n",
            "Iteration 2174: Loss = 0.7932, ||Grad|| = 0.8705, ||W|| = 0.8904\n",
            "Iteration 2175: Loss = 0.7925, ||Grad|| = 0.8696, ||W|| = 0.8897\n",
            "Iteration 2176: Loss = 0.7918, ||Grad|| = 0.8687, ||W|| = 0.8889\n",
            "Iteration 2177: Loss = 0.7911, ||Grad|| = 0.8678, ||W|| = 0.8882\n",
            "Iteration 2178: Loss = 0.7905, ||Grad|| = 0.8669, ||W|| = 0.8874\n",
            "Iteration 2179: Loss = 0.7898, ||Grad|| = 0.8660, ||W|| = 0.8867\n",
            "Iteration 2180: Loss = 0.7891, ||Grad|| = 0.8651, ||W|| = 0.8860\n",
            "Iteration 2181: Loss = 0.7885, ||Grad|| = 0.8642, ||W|| = 0.8852\n",
            "Iteration 2182: Loss = 0.7878, ||Grad|| = 0.8633, ||W|| = 0.8845\n",
            "Iteration 2183: Loss = 0.7871, ||Grad|| = 0.8624, ||W|| = 0.8837\n",
            "Iteration 2184: Loss = 0.7865, ||Grad|| = 0.8615, ||W|| = 0.8830\n",
            "Iteration 2185: Loss = 0.7858, ||Grad|| = 0.8606, ||W|| = 0.8823\n",
            "Iteration 2186: Loss = 0.7851, ||Grad|| = 0.8597, ||W|| = 0.8815\n",
            "Iteration 2187: Loss = 0.7845, ||Grad|| = 0.8588, ||W|| = 0.8808\n",
            "Iteration 2188: Loss = 0.7838, ||Grad|| = 0.8579, ||W|| = 0.8801\n",
            "Iteration 2189: Loss = 0.7831, ||Grad|| = 0.8570, ||W|| = 0.8793\n",
            "Iteration 2190: Loss = 0.7825, ||Grad|| = 0.8561, ||W|| = 0.8786\n",
            "Iteration 2191: Loss = 0.7818, ||Grad|| = 0.8552, ||W|| = 0.8779\n",
            "Iteration 2192: Loss = 0.7812, ||Grad|| = 0.8543, ||W|| = 0.8771\n",
            "Iteration 2193: Loss = 0.7805, ||Grad|| = 0.8534, ||W|| = 0.8764\n",
            "Iteration 2194: Loss = 0.7799, ||Grad|| = 0.8526, ||W|| = 0.8757\n",
            "Iteration 2195: Loss = 0.7792, ||Grad|| = 0.8517, ||W|| = 0.8749\n",
            "Iteration 2196: Loss = 0.7786, ||Grad|| = 0.8508, ||W|| = 0.8742\n",
            "Iteration 2197: Loss = 0.7779, ||Grad|| = 0.8499, ||W|| = 0.8735\n",
            "Iteration 2198: Loss = 0.7773, ||Grad|| = 0.8490, ||W|| = 0.8728\n",
            "Iteration 2199: Loss = 0.7766, ||Grad|| = 0.8481, ||W|| = 0.8721\n",
            "Iteration 2200: Loss = 0.7760, ||Grad|| = 0.8473, ||W|| = 0.8713\n",
            "Iteration 2201: Loss = 0.7754, ||Grad|| = 0.8464, ||W|| = 0.8706\n",
            "Iteration 2202: Loss = 0.7747, ||Grad|| = 0.8455, ||W|| = 0.8699\n",
            "Iteration 2203: Loss = 0.7741, ||Grad|| = 0.8446, ||W|| = 0.8692\n",
            "Iteration 2204: Loss = 0.7734, ||Grad|| = 0.8437, ||W|| = 0.8685\n",
            "Iteration 2205: Loss = 0.7728, ||Grad|| = 0.8429, ||W|| = 0.8677\n",
            "Iteration 2206: Loss = 0.7722, ||Grad|| = 0.8420, ||W|| = 0.8670\n",
            "Iteration 2207: Loss = 0.7715, ||Grad|| = 0.8411, ||W|| = 0.8663\n",
            "Iteration 2208: Loss = 0.7709, ||Grad|| = 0.8402, ||W|| = 0.8656\n",
            "Iteration 2209: Loss = 0.7703, ||Grad|| = 0.8394, ||W|| = 0.8649\n",
            "Iteration 2210: Loss = 0.7697, ||Grad|| = 0.8385, ||W|| = 0.8642\n",
            "Iteration 2211: Loss = 0.7690, ||Grad|| = 0.8376, ||W|| = 0.8635\n",
            "Iteration 2212: Loss = 0.7684, ||Grad|| = 0.8368, ||W|| = 0.8627\n",
            "Iteration 2213: Loss = 0.7678, ||Grad|| = 0.8359, ||W|| = 0.8620\n",
            "Iteration 2214: Loss = 0.7672, ||Grad|| = 0.8350, ||W|| = 0.8613\n",
            "Iteration 2215: Loss = 0.7665, ||Grad|| = 0.8341, ||W|| = 0.8606\n",
            "Iteration 2216: Loss = 0.7659, ||Grad|| = 0.8333, ||W|| = 0.8599\n",
            "Iteration 2217: Loss = 0.7653, ||Grad|| = 0.8324, ||W|| = 0.8592\n",
            "Iteration 2218: Loss = 0.7647, ||Grad|| = 0.8316, ||W|| = 0.8585\n",
            "Iteration 2219: Loss = 0.7641, ||Grad|| = 0.8307, ||W|| = 0.8578\n",
            "Iteration 2220: Loss = 0.7634, ||Grad|| = 0.8298, ||W|| = 0.8571\n",
            "Iteration 2221: Loss = 0.7628, ||Grad|| = 0.8290, ||W|| = 0.8564\n",
            "Iteration 2222: Loss = 0.7622, ||Grad|| = 0.8281, ||W|| = 0.8557\n",
            "Iteration 2223: Loss = 0.7616, ||Grad|| = 0.8272, ||W|| = 0.8550\n",
            "Iteration 2224: Loss = 0.7610, ||Grad|| = 0.8264, ||W|| = 0.8543\n",
            "Iteration 2225: Loss = 0.7604, ||Grad|| = 0.8255, ||W|| = 0.8536\n",
            "Iteration 2226: Loss = 0.7598, ||Grad|| = 0.8247, ||W|| = 0.8529\n",
            "Iteration 2227: Loss = 0.7592, ||Grad|| = 0.8238, ||W|| = 0.8522\n",
            "Iteration 2228: Loss = 0.7586, ||Grad|| = 0.8230, ||W|| = 0.8515\n",
            "Iteration 2229: Loss = 0.7580, ||Grad|| = 0.8221, ||W|| = 0.8508\n",
            "Iteration 2230: Loss = 0.7574, ||Grad|| = 0.8212, ||W|| = 0.8501\n",
            "Iteration 2231: Loss = 0.7568, ||Grad|| = 0.8204, ||W|| = 0.8494\n",
            "Iteration 2232: Loss = 0.7562, ||Grad|| = 0.8195, ||W|| = 0.8487\n",
            "Iteration 2233: Loss = 0.7556, ||Grad|| = 0.8187, ||W|| = 0.8480\n",
            "Iteration 2234: Loss = 0.7550, ||Grad|| = 0.8178, ||W|| = 0.8473\n",
            "Iteration 2235: Loss = 0.7544, ||Grad|| = 0.8170, ||W|| = 0.8467\n",
            "Iteration 2236: Loss = 0.7538, ||Grad|| = 0.8161, ||W|| = 0.8460\n",
            "Iteration 2237: Loss = 0.7532, ||Grad|| = 0.8153, ||W|| = 0.8453\n",
            "Iteration 2238: Loss = 0.7526, ||Grad|| = 0.8145, ||W|| = 0.8446\n",
            "Iteration 2239: Loss = 0.7520, ||Grad|| = 0.8136, ||W|| = 0.8439\n",
            "Iteration 2240: Loss = 0.7514, ||Grad|| = 0.8128, ||W|| = 0.8432\n",
            "Iteration 2241: Loss = 0.7508, ||Grad|| = 0.8119, ||W|| = 0.8425\n",
            "Iteration 2242: Loss = 0.7503, ||Grad|| = 0.8111, ||W|| = 0.8419\n",
            "Iteration 2243: Loss = 0.7497, ||Grad|| = 0.8102, ||W|| = 0.8412\n",
            "Iteration 2244: Loss = 0.7491, ||Grad|| = 0.8094, ||W|| = 0.8405\n",
            "Iteration 2245: Loss = 0.7485, ||Grad|| = 0.8086, ||W|| = 0.8398\n",
            "Iteration 2246: Loss = 0.7479, ||Grad|| = 0.8077, ||W|| = 0.8391\n",
            "Iteration 2247: Loss = 0.7473, ||Grad|| = 0.8069, ||W|| = 0.8385\n",
            "Iteration 2248: Loss = 0.7468, ||Grad|| = 0.8060, ||W|| = 0.8378\n",
            "Iteration 2249: Loss = 0.7462, ||Grad|| = 0.8052, ||W|| = 0.8371\n",
            "Iteration 2250: Loss = 0.7456, ||Grad|| = 0.8044, ||W|| = 0.8364\n",
            "Iteration 2251: Loss = 0.7450, ||Grad|| = 0.8035, ||W|| = 0.8358\n",
            "Iteration 2252: Loss = 0.7445, ||Grad|| = 0.8027, ||W|| = 0.8351\n",
            "Iteration 2253: Loss = 0.7439, ||Grad|| = 0.8019, ||W|| = 0.8344\n",
            "Iteration 2254: Loss = 0.7433, ||Grad|| = 0.8010, ||W|| = 0.8337\n",
            "Iteration 2255: Loss = 0.7428, ||Grad|| = 0.8002, ||W|| = 0.8331\n",
            "Iteration 2256: Loss = 0.7422, ||Grad|| = 0.7994, ||W|| = 0.8324\n",
            "Iteration 2257: Loss = 0.7416, ||Grad|| = 0.7985, ||W|| = 0.8317\n",
            "Iteration 2258: Loss = 0.7411, ||Grad|| = 0.7977, ||W|| = 0.8311\n",
            "Iteration 2259: Loss = 0.7405, ||Grad|| = 0.7969, ||W|| = 0.8304\n",
            "Iteration 2260: Loss = 0.7399, ||Grad|| = 0.7961, ||W|| = 0.8297\n",
            "Iteration 2261: Loss = 0.7394, ||Grad|| = 0.7952, ||W|| = 0.8291\n",
            "Iteration 2262: Loss = 0.7388, ||Grad|| = 0.7944, ||W|| = 0.8284\n",
            "Iteration 2263: Loss = 0.7383, ||Grad|| = 0.7936, ||W|| = 0.8277\n",
            "Iteration 2264: Loss = 0.7377, ||Grad|| = 0.7928, ||W|| = 0.8271\n",
            "Iteration 2265: Loss = 0.7371, ||Grad|| = 0.7919, ||W|| = 0.8264\n",
            "Iteration 2266: Loss = 0.7366, ||Grad|| = 0.7911, ||W|| = 0.8258\n",
            "Iteration 2267: Loss = 0.7360, ||Grad|| = 0.7903, ||W|| = 0.8251\n",
            "Iteration 2268: Loss = 0.7355, ||Grad|| = 0.7895, ||W|| = 0.8244\n",
            "Iteration 2269: Loss = 0.7349, ||Grad|| = 0.7887, ||W|| = 0.8238\n",
            "Iteration 2270: Loss = 0.7344, ||Grad|| = 0.7879, ||W|| = 0.8231\n",
            "Iteration 2271: Loss = 0.7338, ||Grad|| = 0.7870, ||W|| = 0.8225\n",
            "Iteration 2272: Loss = 0.7333, ||Grad|| = 0.7862, ||W|| = 0.8218\n",
            "Iteration 2273: Loss = 0.7327, ||Grad|| = 0.7854, ||W|| = 0.8212\n",
            "Iteration 2274: Loss = 0.7322, ||Grad|| = 0.7846, ||W|| = 0.8205\n",
            "Iteration 2275: Loss = 0.7316, ||Grad|| = 0.7838, ||W|| = 0.8198\n",
            "Iteration 2276: Loss = 0.7311, ||Grad|| = 0.7830, ||W|| = 0.8192\n",
            "Iteration 2277: Loss = 0.7306, ||Grad|| = 0.7822, ||W|| = 0.8185\n",
            "Iteration 2278: Loss = 0.7300, ||Grad|| = 0.7813, ||W|| = 0.8179\n",
            "Iteration 2279: Loss = 0.7295, ||Grad|| = 0.7805, ||W|| = 0.8172\n",
            "Iteration 2280: Loss = 0.7289, ||Grad|| = 0.7797, ||W|| = 0.8166\n",
            "Iteration 2281: Loss = 0.7284, ||Grad|| = 0.7789, ||W|| = 0.8159\n",
            "Iteration 2282: Loss = 0.7279, ||Grad|| = 0.7781, ||W|| = 0.8153\n",
            "Iteration 2283: Loss = 0.7273, ||Grad|| = 0.7773, ||W|| = 0.8147\n",
            "Iteration 2284: Loss = 0.7268, ||Grad|| = 0.7765, ||W|| = 0.8140\n",
            "Iteration 2285: Loss = 0.7263, ||Grad|| = 0.7757, ||W|| = 0.8134\n",
            "Iteration 2286: Loss = 0.7257, ||Grad|| = 0.7749, ||W|| = 0.8127\n",
            "Iteration 2287: Loss = 0.7252, ||Grad|| = 0.7741, ||W|| = 0.8121\n",
            "Iteration 2288: Loss = 0.7247, ||Grad|| = 0.7733, ||W|| = 0.8114\n",
            "Iteration 2289: Loss = 0.7241, ||Grad|| = 0.7725, ||W|| = 0.8108\n",
            "Iteration 2290: Loss = 0.7236, ||Grad|| = 0.7717, ||W|| = 0.8102\n",
            "Iteration 2291: Loss = 0.7231, ||Grad|| = 0.7709, ||W|| = 0.8095\n",
            "Iteration 2292: Loss = 0.7226, ||Grad|| = 0.7701, ||W|| = 0.8089\n",
            "Iteration 2293: Loss = 0.7220, ||Grad|| = 0.7693, ||W|| = 0.8082\n",
            "Iteration 2294: Loss = 0.7215, ||Grad|| = 0.7685, ||W|| = 0.8076\n",
            "Iteration 2295: Loss = 0.7210, ||Grad|| = 0.7677, ||W|| = 0.8070\n",
            "Iteration 2296: Loss = 0.7205, ||Grad|| = 0.7669, ||W|| = 0.8063\n",
            "Iteration 2297: Loss = 0.7200, ||Grad|| = 0.7661, ||W|| = 0.8057\n",
            "Iteration 2298: Loss = 0.7194, ||Grad|| = 0.7653, ||W|| = 0.8051\n",
            "Iteration 2299: Loss = 0.7189, ||Grad|| = 0.7645, ||W|| = 0.8044\n",
            "Iteration 2300: Loss = 0.7184, ||Grad|| = 0.7637, ||W|| = 0.8038\n",
            "Iteration 2301: Loss = 0.7179, ||Grad|| = 0.7629, ||W|| = 0.8032\n",
            "Iteration 2302: Loss = 0.7174, ||Grad|| = 0.7621, ||W|| = 0.8026\n",
            "Iteration 2303: Loss = 0.7169, ||Grad|| = 0.7614, ||W|| = 0.8019\n",
            "Iteration 2304: Loss = 0.7164, ||Grad|| = 0.7606, ||W|| = 0.8013\n",
            "Iteration 2305: Loss = 0.7159, ||Grad|| = 0.7598, ||W|| = 0.8007\n",
            "Iteration 2306: Loss = 0.7154, ||Grad|| = 0.7590, ||W|| = 0.8000\n",
            "Iteration 2307: Loss = 0.7148, ||Grad|| = 0.7582, ||W|| = 0.7994\n",
            "Iteration 2308: Loss = 0.7143, ||Grad|| = 0.7574, ||W|| = 0.7988\n",
            "Iteration 2309: Loss = 0.7138, ||Grad|| = 0.7566, ||W|| = 0.7982\n",
            "Iteration 2310: Loss = 0.7133, ||Grad|| = 0.7559, ||W|| = 0.7976\n",
            "Iteration 2311: Loss = 0.7128, ||Grad|| = 0.7551, ||W|| = 0.7969\n",
            "Iteration 2312: Loss = 0.7123, ||Grad|| = 0.7543, ||W|| = 0.7963\n",
            "Iteration 2313: Loss = 0.7118, ||Grad|| = 0.7535, ||W|| = 0.7957\n",
            "Iteration 2314: Loss = 0.7113, ||Grad|| = 0.7527, ||W|| = 0.7951\n",
            "Iteration 2315: Loss = 0.7108, ||Grad|| = 0.7520, ||W|| = 0.7945\n",
            "Iteration 2316: Loss = 0.7103, ||Grad|| = 0.7512, ||W|| = 0.7938\n",
            "Iteration 2317: Loss = 0.7098, ||Grad|| = 0.7504, ||W|| = 0.7932\n",
            "Iteration 2318: Loss = 0.7093, ||Grad|| = 0.7496, ||W|| = 0.7926\n",
            "Iteration 2319: Loss = 0.7088, ||Grad|| = 0.7489, ||W|| = 0.7920\n",
            "Iteration 2320: Loss = 0.7084, ||Grad|| = 0.7481, ||W|| = 0.7914\n",
            "Iteration 2321: Loss = 0.7079, ||Grad|| = 0.7473, ||W|| = 0.7908\n",
            "Iteration 2322: Loss = 0.7074, ||Grad|| = 0.7465, ||W|| = 0.7902\n",
            "Iteration 2323: Loss = 0.7069, ||Grad|| = 0.7458, ||W|| = 0.7895\n",
            "Iteration 2324: Loss = 0.7064, ||Grad|| = 0.7450, ||W|| = 0.7889\n",
            "Iteration 2325: Loss = 0.7059, ||Grad|| = 0.7442, ||W|| = 0.7883\n",
            "Iteration 2326: Loss = 0.7054, ||Grad|| = 0.7434, ||W|| = 0.7877\n",
            "Iteration 2327: Loss = 0.7049, ||Grad|| = 0.7427, ||W|| = 0.7871\n",
            "Iteration 2328: Loss = 0.7044, ||Grad|| = 0.7419, ||W|| = 0.7865\n",
            "Iteration 2329: Loss = 0.7040, ||Grad|| = 0.7411, ||W|| = 0.7859\n",
            "Iteration 2330: Loss = 0.7035, ||Grad|| = 0.7404, ||W|| = 0.7853\n",
            "Iteration 2331: Loss = 0.7030, ||Grad|| = 0.7396, ||W|| = 0.7847\n",
            "Iteration 2332: Loss = 0.7025, ||Grad|| = 0.7388, ||W|| = 0.7841\n",
            "Iteration 2333: Loss = 0.7020, ||Grad|| = 0.7381, ||W|| = 0.7835\n",
            "Iteration 2334: Loss = 0.7016, ||Grad|| = 0.7373, ||W|| = 0.7829\n",
            "Iteration 2335: Loss = 0.7011, ||Grad|| = 0.7366, ||W|| = 0.7823\n",
            "Iteration 2336: Loss = 0.7006, ||Grad|| = 0.7358, ||W|| = 0.7817\n",
            "Iteration 2337: Loss = 0.7001, ||Grad|| = 0.7350, ||W|| = 0.7811\n",
            "Iteration 2338: Loss = 0.6997, ||Grad|| = 0.7343, ||W|| = 0.7805\n",
            "Iteration 2339: Loss = 0.6992, ||Grad|| = 0.7335, ||W|| = 0.7799\n",
            "Iteration 2340: Loss = 0.6987, ||Grad|| = 0.7328, ||W|| = 0.7793\n",
            "Iteration 2341: Loss = 0.6983, ||Grad|| = 0.7320, ||W|| = 0.7787\n",
            "Iteration 2342: Loss = 0.6978, ||Grad|| = 0.7312, ||W|| = 0.7781\n",
            "Iteration 2343: Loss = 0.6973, ||Grad|| = 0.7305, ||W|| = 0.7775\n",
            "Iteration 2344: Loss = 0.6968, ||Grad|| = 0.7297, ||W|| = 0.7769\n",
            "Iteration 2345: Loss = 0.6964, ||Grad|| = 0.7290, ||W|| = 0.7763\n",
            "Iteration 2346: Loss = 0.6959, ||Grad|| = 0.7282, ||W|| = 0.7757\n",
            "Iteration 2347: Loss = 0.6955, ||Grad|| = 0.7275, ||W|| = 0.7751\n",
            "Iteration 2348: Loss = 0.6950, ||Grad|| = 0.7267, ||W|| = 0.7745\n",
            "Iteration 2349: Loss = 0.6945, ||Grad|| = 0.7260, ||W|| = 0.7739\n",
            "Iteration 2350: Loss = 0.6941, ||Grad|| = 0.7252, ||W|| = 0.7734\n",
            "Iteration 2351: Loss = 0.6936, ||Grad|| = 0.7245, ||W|| = 0.7728\n",
            "Iteration 2352: Loss = 0.6931, ||Grad|| = 0.7237, ||W|| = 0.7722\n",
            "Iteration 2353: Loss = 0.6927, ||Grad|| = 0.7230, ||W|| = 0.7716\n",
            "Iteration 2354: Loss = 0.6922, ||Grad|| = 0.7222, ||W|| = 0.7710\n",
            "Iteration 2355: Loss = 0.6918, ||Grad|| = 0.7215, ||W|| = 0.7704\n",
            "Iteration 2356: Loss = 0.6913, ||Grad|| = 0.7207, ||W|| = 0.7698\n",
            "Iteration 2357: Loss = 0.6909, ||Grad|| = 0.7200, ||W|| = 0.7693\n",
            "Iteration 2358: Loss = 0.6904, ||Grad|| = 0.7193, ||W|| = 0.7687\n",
            "Iteration 2359: Loss = 0.6900, ||Grad|| = 0.7185, ||W|| = 0.7681\n",
            "Iteration 2360: Loss = 0.6895, ||Grad|| = 0.7178, ||W|| = 0.7675\n",
            "Iteration 2361: Loss = 0.6891, ||Grad|| = 0.7170, ||W|| = 0.7669\n",
            "Iteration 2362: Loss = 0.6886, ||Grad|| = 0.7163, ||W|| = 0.7664\n",
            "Iteration 2363: Loss = 0.6882, ||Grad|| = 0.7155, ||W|| = 0.7658\n",
            "Iteration 2364: Loss = 0.6877, ||Grad|| = 0.7148, ||W|| = 0.7652\n",
            "Iteration 2365: Loss = 0.6873, ||Grad|| = 0.7141, ||W|| = 0.7646\n",
            "Iteration 2366: Loss = 0.6868, ||Grad|| = 0.7133, ||W|| = 0.7640\n",
            "Iteration 2367: Loss = 0.6864, ||Grad|| = 0.7126, ||W|| = 0.7635\n",
            "Iteration 2368: Loss = 0.6859, ||Grad|| = 0.7119, ||W|| = 0.7629\n",
            "Iteration 2369: Loss = 0.6855, ||Grad|| = 0.7111, ||W|| = 0.7623\n",
            "Iteration 2370: Loss = 0.6851, ||Grad|| = 0.7104, ||W|| = 0.7618\n",
            "Iteration 2371: Loss = 0.6846, ||Grad|| = 0.7097, ||W|| = 0.7612\n",
            "Iteration 2372: Loss = 0.6842, ||Grad|| = 0.7089, ||W|| = 0.7606\n",
            "Iteration 2373: Loss = 0.6837, ||Grad|| = 0.7082, ||W|| = 0.7600\n",
            "Iteration 2374: Loss = 0.6833, ||Grad|| = 0.7075, ||W|| = 0.7595\n",
            "Iteration 2375: Loss = 0.6829, ||Grad|| = 0.7067, ||W|| = 0.7589\n",
            "Iteration 2376: Loss = 0.6824, ||Grad|| = 0.7060, ||W|| = 0.7583\n",
            "Iteration 2377: Loss = 0.6820, ||Grad|| = 0.7053, ||W|| = 0.7578\n",
            "Iteration 2378: Loss = 0.6816, ||Grad|| = 0.7046, ||W|| = 0.7572\n",
            "Iteration 2379: Loss = 0.6811, ||Grad|| = 0.7038, ||W|| = 0.7566\n",
            "Iteration 2380: Loss = 0.6807, ||Grad|| = 0.7031, ||W|| = 0.7561\n",
            "Iteration 2381: Loss = 0.6803, ||Grad|| = 0.7024, ||W|| = 0.7555\n",
            "Iteration 2382: Loss = 0.6798, ||Grad|| = 0.7017, ||W|| = 0.7549\n",
            "Iteration 2383: Loss = 0.6794, ||Grad|| = 0.7009, ||W|| = 0.7544\n",
            "Iteration 2384: Loss = 0.6790, ||Grad|| = 0.7002, ||W|| = 0.7538\n",
            "Iteration 2385: Loss = 0.6786, ||Grad|| = 0.6995, ||W|| = 0.7533\n",
            "Iteration 2386: Loss = 0.6781, ||Grad|| = 0.6988, ||W|| = 0.7527\n",
            "Iteration 2387: Loss = 0.6777, ||Grad|| = 0.6980, ||W|| = 0.7521\n",
            "Iteration 2388: Loss = 0.6773, ||Grad|| = 0.6973, ||W|| = 0.7516\n",
            "Iteration 2389: Loss = 0.6769, ||Grad|| = 0.6966, ||W|| = 0.7510\n",
            "Iteration 2390: Loss = 0.6764, ||Grad|| = 0.6959, ||W|| = 0.7505\n",
            "Iteration 2391: Loss = 0.6760, ||Grad|| = 0.6952, ||W|| = 0.7499\n",
            "Iteration 2392: Loss = 0.6756, ||Grad|| = 0.6944, ||W|| = 0.7494\n",
            "Iteration 2393: Loss = 0.6752, ||Grad|| = 0.6937, ||W|| = 0.7488\n",
            "Iteration 2394: Loss = 0.6748, ||Grad|| = 0.6930, ||W|| = 0.7483\n",
            "Iteration 2395: Loss = 0.6743, ||Grad|| = 0.6923, ||W|| = 0.7477\n",
            "Iteration 2396: Loss = 0.6739, ||Grad|| = 0.6916, ||W|| = 0.7471\n",
            "Iteration 2397: Loss = 0.6735, ||Grad|| = 0.6909, ||W|| = 0.7466\n",
            "Iteration 2398: Loss = 0.6731, ||Grad|| = 0.6902, ||W|| = 0.7460\n",
            "Iteration 2399: Loss = 0.6727, ||Grad|| = 0.6895, ||W|| = 0.7455\n",
            "Iteration 2400: Loss = 0.6723, ||Grad|| = 0.6887, ||W|| = 0.7449\n",
            "Iteration 2401: Loss = 0.6719, ||Grad|| = 0.6880, ||W|| = 0.7444\n",
            "Iteration 2402: Loss = 0.6714, ||Grad|| = 0.6873, ||W|| = 0.7439\n",
            "Iteration 2403: Loss = 0.6710, ||Grad|| = 0.6866, ||W|| = 0.7433\n",
            "Iteration 2404: Loss = 0.6706, ||Grad|| = 0.6859, ||W|| = 0.7428\n",
            "Iteration 2405: Loss = 0.6702, ||Grad|| = 0.6852, ||W|| = 0.7422\n",
            "Iteration 2406: Loss = 0.6698, ||Grad|| = 0.6845, ||W|| = 0.7417\n",
            "Iteration 2407: Loss = 0.6694, ||Grad|| = 0.6838, ||W|| = 0.7411\n",
            "Iteration 2408: Loss = 0.6690, ||Grad|| = 0.6831, ||W|| = 0.7406\n",
            "Iteration 2409: Loss = 0.6686, ||Grad|| = 0.6824, ||W|| = 0.7400\n",
            "Iteration 2410: Loss = 0.6682, ||Grad|| = 0.6817, ||W|| = 0.7395\n",
            "Iteration 2411: Loss = 0.6678, ||Grad|| = 0.6810, ||W|| = 0.7390\n",
            "Iteration 2412: Loss = 0.6674, ||Grad|| = 0.6803, ||W|| = 0.7384\n",
            "Iteration 2413: Loss = 0.6670, ||Grad|| = 0.6796, ||W|| = 0.7379\n",
            "Iteration 2414: Loss = 0.6666, ||Grad|| = 0.6789, ||W|| = 0.7373\n",
            "Iteration 2415: Loss = 0.6662, ||Grad|| = 0.6782, ||W|| = 0.7368\n",
            "Iteration 2416: Loss = 0.6658, ||Grad|| = 0.6775, ||W|| = 0.7363\n",
            "Iteration 2417: Loss = 0.6654, ||Grad|| = 0.6768, ||W|| = 0.7357\n",
            "Iteration 2418: Loss = 0.6650, ||Grad|| = 0.6761, ||W|| = 0.7352\n",
            "Iteration 2419: Loss = 0.6646, ||Grad|| = 0.6754, ||W|| = 0.7347\n",
            "Iteration 2420: Loss = 0.6642, ||Grad|| = 0.6747, ||W|| = 0.7341\n",
            "Iteration 2421: Loss = 0.6638, ||Grad|| = 0.6740, ||W|| = 0.7336\n",
            "Iteration 2422: Loss = 0.6634, ||Grad|| = 0.6733, ||W|| = 0.7331\n",
            "Iteration 2423: Loss = 0.6630, ||Grad|| = 0.6726, ||W|| = 0.7325\n",
            "Iteration 2424: Loss = 0.6626, ||Grad|| = 0.6719, ||W|| = 0.7320\n",
            "Iteration 2425: Loss = 0.6622, ||Grad|| = 0.6712, ||W|| = 0.7315\n",
            "Iteration 2426: Loss = 0.6618, ||Grad|| = 0.6705, ||W|| = 0.7309\n",
            "Iteration 2427: Loss = 0.6615, ||Grad|| = 0.6699, ||W|| = 0.7304\n",
            "Iteration 2428: Loss = 0.6611, ||Grad|| = 0.6692, ||W|| = 0.7299\n",
            "Iteration 2429: Loss = 0.6607, ||Grad|| = 0.6685, ||W|| = 0.7294\n",
            "Iteration 2430: Loss = 0.6603, ||Grad|| = 0.6678, ||W|| = 0.7288\n",
            "Iteration 2431: Loss = 0.6599, ||Grad|| = 0.6671, ||W|| = 0.7283\n",
            "Iteration 2432: Loss = 0.6595, ||Grad|| = 0.6664, ||W|| = 0.7278\n",
            "Iteration 2433: Loss = 0.6591, ||Grad|| = 0.6657, ||W|| = 0.7273\n",
            "Iteration 2434: Loss = 0.6588, ||Grad|| = 0.6650, ||W|| = 0.7267\n",
            "Iteration 2435: Loss = 0.6584, ||Grad|| = 0.6644, ||W|| = 0.7262\n",
            "Iteration 2436: Loss = 0.6580, ||Grad|| = 0.6637, ||W|| = 0.7257\n",
            "Iteration 2437: Loss = 0.6576, ||Grad|| = 0.6630, ||W|| = 0.7252\n",
            "Iteration 2438: Loss = 0.6572, ||Grad|| = 0.6623, ||W|| = 0.7247\n",
            "Iteration 2439: Loss = 0.6569, ||Grad|| = 0.6616, ||W|| = 0.7241\n",
            "Iteration 2440: Loss = 0.6565, ||Grad|| = 0.6610, ||W|| = 0.7236\n",
            "Iteration 2441: Loss = 0.6561, ||Grad|| = 0.6603, ||W|| = 0.7231\n",
            "Iteration 2442: Loss = 0.6557, ||Grad|| = 0.6596, ||W|| = 0.7226\n",
            "Iteration 2443: Loss = 0.6554, ||Grad|| = 0.6589, ||W|| = 0.7221\n",
            "Iteration 2444: Loss = 0.6550, ||Grad|| = 0.6582, ||W|| = 0.7216\n",
            "Iteration 2445: Loss = 0.6546, ||Grad|| = 0.6576, ||W|| = 0.7210\n",
            "Iteration 2446: Loss = 0.6542, ||Grad|| = 0.6569, ||W|| = 0.7205\n",
            "Iteration 2447: Loss = 0.6539, ||Grad|| = 0.6562, ||W|| = 0.7200\n",
            "Iteration 2448: Loss = 0.6535, ||Grad|| = 0.6555, ||W|| = 0.7195\n",
            "Iteration 2449: Loss = 0.6531, ||Grad|| = 0.6549, ||W|| = 0.7190\n",
            "Iteration 2450: Loss = 0.6527, ||Grad|| = 0.6542, ||W|| = 0.7185\n",
            "Iteration 2451: Loss = 0.6524, ||Grad|| = 0.6535, ||W|| = 0.7180\n",
            "Iteration 2452: Loss = 0.6520, ||Grad|| = 0.6528, ||W|| = 0.7175\n",
            "Iteration 2453: Loss = 0.6516, ||Grad|| = 0.6522, ||W|| = 0.7170\n",
            "Iteration 2454: Loss = 0.6513, ||Grad|| = 0.6515, ||W|| = 0.7164\n",
            "Iteration 2455: Loss = 0.6509, ||Grad|| = 0.6508, ||W|| = 0.7159\n",
            "Iteration 2456: Loss = 0.6505, ||Grad|| = 0.6502, ||W|| = 0.7154\n",
            "Iteration 2457: Loss = 0.6502, ||Grad|| = 0.6495, ||W|| = 0.7149\n",
            "Iteration 2458: Loss = 0.6498, ||Grad|| = 0.6488, ||W|| = 0.7144\n",
            "Iteration 2459: Loss = 0.6495, ||Grad|| = 0.6482, ||W|| = 0.7139\n",
            "Iteration 2460: Loss = 0.6491, ||Grad|| = 0.6475, ||W|| = 0.7134\n",
            "Iteration 2461: Loss = 0.6487, ||Grad|| = 0.6468, ||W|| = 0.7129\n",
            "Iteration 2462: Loss = 0.6484, ||Grad|| = 0.6462, ||W|| = 0.7124\n",
            "Iteration 2463: Loss = 0.6480, ||Grad|| = 0.6455, ||W|| = 0.7119\n",
            "Iteration 2464: Loss = 0.6477, ||Grad|| = 0.6448, ||W|| = 0.7114\n",
            "Iteration 2465: Loss = 0.6473, ||Grad|| = 0.6442, ||W|| = 0.7109\n",
            "Iteration 2466: Loss = 0.6469, ||Grad|| = 0.6435, ||W|| = 0.7104\n",
            "Iteration 2467: Loss = 0.6466, ||Grad|| = 0.6429, ||W|| = 0.7099\n",
            "Iteration 2468: Loss = 0.6462, ||Grad|| = 0.6422, ||W|| = 0.7094\n",
            "Iteration 2469: Loss = 0.6459, ||Grad|| = 0.6415, ||W|| = 0.7089\n",
            "Iteration 2470: Loss = 0.6455, ||Grad|| = 0.6409, ||W|| = 0.7084\n",
            "Iteration 2471: Loss = 0.6452, ||Grad|| = 0.6402, ||W|| = 0.7079\n",
            "Iteration 2472: Loss = 0.6448, ||Grad|| = 0.6396, ||W|| = 0.7074\n",
            "Iteration 2473: Loss = 0.6445, ||Grad|| = 0.6389, ||W|| = 0.7069\n",
            "Iteration 2474: Loss = 0.6441, ||Grad|| = 0.6383, ||W|| = 0.7064\n",
            "Iteration 2475: Loss = 0.6438, ||Grad|| = 0.6376, ||W|| = 0.7059\n",
            "Iteration 2476: Loss = 0.6434, ||Grad|| = 0.6369, ||W|| = 0.7055\n",
            "Iteration 2477: Loss = 0.6431, ||Grad|| = 0.6363, ||W|| = 0.7050\n",
            "Iteration 2478: Loss = 0.6427, ||Grad|| = 0.6356, ||W|| = 0.7045\n",
            "Iteration 2479: Loss = 0.6424, ||Grad|| = 0.6350, ||W|| = 0.7040\n",
            "Iteration 2480: Loss = 0.6420, ||Grad|| = 0.6343, ||W|| = 0.7035\n",
            "Iteration 2481: Loss = 0.6417, ||Grad|| = 0.6337, ||W|| = 0.7030\n",
            "Iteration 2482: Loss = 0.6413, ||Grad|| = 0.6330, ||W|| = 0.7025\n",
            "Iteration 2483: Loss = 0.6410, ||Grad|| = 0.6324, ||W|| = 0.7020\n",
            "Iteration 2484: Loss = 0.6407, ||Grad|| = 0.6317, ||W|| = 0.7015\n",
            "Iteration 2485: Loss = 0.6403, ||Grad|| = 0.6311, ||W|| = 0.7011\n",
            "Iteration 2486: Loss = 0.6400, ||Grad|| = 0.6304, ||W|| = 0.7006\n",
            "Iteration 2487: Loss = 0.6396, ||Grad|| = 0.6298, ||W|| = 0.7001\n",
            "Iteration 2488: Loss = 0.6393, ||Grad|| = 0.6292, ||W|| = 0.6996\n",
            "Iteration 2489: Loss = 0.6390, ||Grad|| = 0.6285, ||W|| = 0.6991\n",
            "Iteration 2490: Loss = 0.6386, ||Grad|| = 0.6279, ||W|| = 0.6986\n",
            "Iteration 2491: Loss = 0.6383, ||Grad|| = 0.6272, ||W|| = 0.6982\n",
            "Iteration 2492: Loss = 0.6379, ||Grad|| = 0.6266, ||W|| = 0.6977\n",
            "Iteration 2493: Loss = 0.6376, ||Grad|| = 0.6259, ||W|| = 0.6972\n",
            "Iteration 2494: Loss = 0.6373, ||Grad|| = 0.6253, ||W|| = 0.6967\n",
            "Iteration 2495: Loss = 0.6369, ||Grad|| = 0.6247, ||W|| = 0.6962\n",
            "Iteration 2496: Loss = 0.6366, ||Grad|| = 0.6240, ||W|| = 0.6958\n",
            "Iteration 2497: Loss = 0.6363, ||Grad|| = 0.6234, ||W|| = 0.6953\n",
            "Iteration 2498: Loss = 0.6359, ||Grad|| = 0.6227, ||W|| = 0.6948\n",
            "Iteration 2499: Loss = 0.6356, ||Grad|| = 0.6221, ||W|| = 0.6943\n",
            "Iteration 2500: Loss = 0.6353, ||Grad|| = 0.6215, ||W|| = 0.6939\n",
            "Iteration 2501: Loss = 0.6349, ||Grad|| = 0.6208, ||W|| = 0.6934\n",
            "Iteration 2502: Loss = 0.6346, ||Grad|| = 0.6202, ||W|| = 0.6929\n",
            "Iteration 2503: Loss = 0.6343, ||Grad|| = 0.6195, ||W|| = 0.6924\n",
            "Iteration 2504: Loss = 0.6340, ||Grad|| = 0.6189, ||W|| = 0.6920\n",
            "Iteration 2505: Loss = 0.6336, ||Grad|| = 0.6183, ||W|| = 0.6915\n",
            "Iteration 2506: Loss = 0.6333, ||Grad|| = 0.6176, ||W|| = 0.6910\n",
            "Iteration 2507: Loss = 0.6330, ||Grad|| = 0.6170, ||W|| = 0.6906\n",
            "Iteration 2508: Loss = 0.6327, ||Grad|| = 0.6164, ||W|| = 0.6901\n",
            "Iteration 2509: Loss = 0.6323, ||Grad|| = 0.6158, ||W|| = 0.6896\n",
            "Iteration 2510: Loss = 0.6320, ||Grad|| = 0.6151, ||W|| = 0.6891\n",
            "Iteration 2511: Loss = 0.6317, ||Grad|| = 0.6145, ||W|| = 0.6887\n",
            "Iteration 2512: Loss = 0.6314, ||Grad|| = 0.6139, ||W|| = 0.6882\n",
            "Iteration 2513: Loss = 0.6310, ||Grad|| = 0.6132, ||W|| = 0.6877\n",
            "Iteration 2514: Loss = 0.6307, ||Grad|| = 0.6126, ||W|| = 0.6873\n",
            "Iteration 2515: Loss = 0.6304, ||Grad|| = 0.6120, ||W|| = 0.6868\n",
            "Iteration 2516: Loss = 0.6301, ||Grad|| = 0.6114, ||W|| = 0.6864\n",
            "Iteration 2517: Loss = 0.6298, ||Grad|| = 0.6107, ||W|| = 0.6859\n",
            "Iteration 2518: Loss = 0.6294, ||Grad|| = 0.6101, ||W|| = 0.6854\n",
            "Iteration 2519: Loss = 0.6291, ||Grad|| = 0.6095, ||W|| = 0.6850\n",
            "Iteration 2520: Loss = 0.6288, ||Grad|| = 0.6089, ||W|| = 0.6845\n",
            "Iteration 2521: Loss = 0.6285, ||Grad|| = 0.6082, ||W|| = 0.6840\n",
            "Iteration 2522: Loss = 0.6282, ||Grad|| = 0.6076, ||W|| = 0.6836\n",
            "Iteration 2523: Loss = 0.6279, ||Grad|| = 0.6070, ||W|| = 0.6831\n",
            "Iteration 2524: Loss = 0.6276, ||Grad|| = 0.6064, ||W|| = 0.6827\n",
            "Iteration 2525: Loss = 0.6272, ||Grad|| = 0.6057, ||W|| = 0.6822\n",
            "Iteration 2526: Loss = 0.6269, ||Grad|| = 0.6051, ||W|| = 0.6818\n",
            "Iteration 2527: Loss = 0.6266, ||Grad|| = 0.6045, ||W|| = 0.6813\n",
            "Iteration 2528: Loss = 0.6263, ||Grad|| = 0.6039, ||W|| = 0.6808\n",
            "Iteration 2529: Loss = 0.6260, ||Grad|| = 0.6033, ||W|| = 0.6804\n",
            "Iteration 2530: Loss = 0.6257, ||Grad|| = 0.6027, ||W|| = 0.6799\n",
            "Iteration 2531: Loss = 0.6254, ||Grad|| = 0.6020, ||W|| = 0.6795\n",
            "Iteration 2532: Loss = 0.6251, ||Grad|| = 0.6014, ||W|| = 0.6790\n",
            "Iteration 2533: Loss = 0.6248, ||Grad|| = 0.6008, ||W|| = 0.6786\n",
            "Iteration 2534: Loss = 0.6245, ||Grad|| = 0.6002, ||W|| = 0.6781\n",
            "Iteration 2535: Loss = 0.6241, ||Grad|| = 0.5996, ||W|| = 0.6777\n",
            "Iteration 2536: Loss = 0.6238, ||Grad|| = 0.5990, ||W|| = 0.6772\n",
            "Iteration 2537: Loss = 0.6235, ||Grad|| = 0.5984, ||W|| = 0.6768\n",
            "Iteration 2538: Loss = 0.6232, ||Grad|| = 0.5977, ||W|| = 0.6763\n",
            "Iteration 2539: Loss = 0.6229, ||Grad|| = 0.5971, ||W|| = 0.6759\n",
            "Iteration 2540: Loss = 0.6226, ||Grad|| = 0.5965, ||W|| = 0.6754\n",
            "Iteration 2541: Loss = 0.6223, ||Grad|| = 0.5959, ||W|| = 0.6750\n",
            "Iteration 2542: Loss = 0.6220, ||Grad|| = 0.5953, ||W|| = 0.6745\n",
            "Iteration 2543: Loss = 0.6217, ||Grad|| = 0.5947, ||W|| = 0.6741\n",
            "Iteration 2544: Loss = 0.6214, ||Grad|| = 0.5941, ||W|| = 0.6736\n",
            "Iteration 2545: Loss = 0.6211, ||Grad|| = 0.5935, ||W|| = 0.6732\n",
            "Iteration 2546: Loss = 0.6208, ||Grad|| = 0.5929, ||W|| = 0.6727\n",
            "Iteration 2547: Loss = 0.6205, ||Grad|| = 0.5923, ||W|| = 0.6723\n",
            "Iteration 2548: Loss = 0.6202, ||Grad|| = 0.5917, ||W|| = 0.6719\n",
            "Iteration 2549: Loss = 0.6199, ||Grad|| = 0.5911, ||W|| = 0.6714\n",
            "Iteration 2550: Loss = 0.6196, ||Grad|| = 0.5905, ||W|| = 0.6710\n",
            "Iteration 2551: Loss = 0.6193, ||Grad|| = 0.5899, ||W|| = 0.6705\n",
            "Iteration 2552: Loss = 0.6190, ||Grad|| = 0.5893, ||W|| = 0.6701\n",
            "Iteration 2553: Loss = 0.6188, ||Grad|| = 0.5886, ||W|| = 0.6697\n",
            "Iteration 2554: Loss = 0.6185, ||Grad|| = 0.5880, ||W|| = 0.6692\n",
            "Iteration 2555: Loss = 0.6182, ||Grad|| = 0.5874, ||W|| = 0.6688\n",
            "Iteration 2556: Loss = 0.6179, ||Grad|| = 0.5868, ||W|| = 0.6683\n",
            "Iteration 2557: Loss = 0.6176, ||Grad|| = 0.5862, ||W|| = 0.6679\n",
            "Iteration 2558: Loss = 0.6173, ||Grad|| = 0.5856, ||W|| = 0.6675\n",
            "Iteration 2559: Loss = 0.6170, ||Grad|| = 0.5851, ||W|| = 0.6670\n",
            "Iteration 2560: Loss = 0.6167, ||Grad|| = 0.5845, ||W|| = 0.6666\n",
            "Iteration 2561: Loss = 0.6164, ||Grad|| = 0.5839, ||W|| = 0.6662\n",
            "Iteration 2562: Loss = 0.6161, ||Grad|| = 0.5833, ||W|| = 0.6657\n",
            "Iteration 2563: Loss = 0.6158, ||Grad|| = 0.5827, ||W|| = 0.6653\n",
            "Iteration 2564: Loss = 0.6156, ||Grad|| = 0.5821, ||W|| = 0.6649\n",
            "Iteration 2565: Loss = 0.6153, ||Grad|| = 0.5815, ||W|| = 0.6644\n",
            "Iteration 2566: Loss = 0.6150, ||Grad|| = 0.5809, ||W|| = 0.6640\n",
            "Iteration 2567: Loss = 0.6147, ||Grad|| = 0.5803, ||W|| = 0.6636\n",
            "Iteration 2568: Loss = 0.6144, ||Grad|| = 0.5797, ||W|| = 0.6632\n",
            "Iteration 2569: Loss = 0.6141, ||Grad|| = 0.5791, ||W|| = 0.6627\n",
            "Iteration 2570: Loss = 0.6138, ||Grad|| = 0.5785, ||W|| = 0.6623\n",
            "Iteration 2571: Loss = 0.6136, ||Grad|| = 0.5779, ||W|| = 0.6619\n",
            "Iteration 2572: Loss = 0.6133, ||Grad|| = 0.5773, ||W|| = 0.6614\n",
            "Iteration 2573: Loss = 0.6130, ||Grad|| = 0.5768, ||W|| = 0.6610\n",
            "Iteration 2574: Loss = 0.6127, ||Grad|| = 0.5762, ||W|| = 0.6606\n",
            "Iteration 2575: Loss = 0.6124, ||Grad|| = 0.5756, ||W|| = 0.6602\n",
            "Iteration 2576: Loss = 0.6122, ||Grad|| = 0.5750, ||W|| = 0.6597\n",
            "Iteration 2577: Loss = 0.6119, ||Grad|| = 0.5744, ||W|| = 0.6593\n",
            "Iteration 2578: Loss = 0.6116, ||Grad|| = 0.5738, ||W|| = 0.6589\n",
            "Iteration 2579: Loss = 0.6113, ||Grad|| = 0.5732, ||W|| = 0.6585\n",
            "Iteration 2580: Loss = 0.6110, ||Grad|| = 0.5726, ||W|| = 0.6581\n",
            "Iteration 2581: Loss = 0.6108, ||Grad|| = 0.5721, ||W|| = 0.6576\n",
            "Iteration 2582: Loss = 0.6105, ||Grad|| = 0.5715, ||W|| = 0.6572\n",
            "Iteration 2583: Loss = 0.6102, ||Grad|| = 0.5709, ||W|| = 0.6568\n",
            "Iteration 2584: Loss = 0.6099, ||Grad|| = 0.5703, ||W|| = 0.6564\n",
            "Iteration 2585: Loss = 0.6097, ||Grad|| = 0.5697, ||W|| = 0.6560\n",
            "Iteration 2586: Loss = 0.6094, ||Grad|| = 0.5692, ||W|| = 0.6555\n",
            "Iteration 2587: Loss = 0.6091, ||Grad|| = 0.5686, ||W|| = 0.6551\n",
            "Iteration 2588: Loss = 0.6089, ||Grad|| = 0.5680, ||W|| = 0.6547\n",
            "Iteration 2589: Loss = 0.6086, ||Grad|| = 0.5674, ||W|| = 0.6543\n",
            "Iteration 2590: Loss = 0.6083, ||Grad|| = 0.5668, ||W|| = 0.6539\n",
            "Iteration 2591: Loss = 0.6080, ||Grad|| = 0.5663, ||W|| = 0.6535\n",
            "Iteration 2592: Loss = 0.6078, ||Grad|| = 0.5657, ||W|| = 0.6530\n",
            "Iteration 2593: Loss = 0.6075, ||Grad|| = 0.5651, ||W|| = 0.6526\n",
            "Iteration 2594: Loss = 0.6072, ||Grad|| = 0.5645, ||W|| = 0.6522\n",
            "Iteration 2595: Loss = 0.6070, ||Grad|| = 0.5640, ||W|| = 0.6518\n",
            "Iteration 2596: Loss = 0.6067, ||Grad|| = 0.5634, ||W|| = 0.6514\n",
            "Iteration 2597: Loss = 0.6064, ||Grad|| = 0.5628, ||W|| = 0.6510\n",
            "Iteration 2598: Loss = 0.6062, ||Grad|| = 0.5622, ||W|| = 0.6506\n",
            "Iteration 2599: Loss = 0.6059, ||Grad|| = 0.5617, ||W|| = 0.6502\n",
            "Iteration 2600: Loss = 0.6056, ||Grad|| = 0.5611, ||W|| = 0.6497\n",
            "Iteration 2601: Loss = 0.6054, ||Grad|| = 0.5605, ||W|| = 0.6493\n",
            "Iteration 2602: Loss = 0.6051, ||Grad|| = 0.5600, ||W|| = 0.6489\n",
            "Iteration 2603: Loss = 0.6048, ||Grad|| = 0.5594, ||W|| = 0.6485\n",
            "Iteration 2604: Loss = 0.6046, ||Grad|| = 0.5588, ||W|| = 0.6481\n",
            "Iteration 2605: Loss = 0.6043, ||Grad|| = 0.5582, ||W|| = 0.6477\n",
            "Iteration 2606: Loss = 0.6041, ||Grad|| = 0.5577, ||W|| = 0.6473\n",
            "Iteration 2607: Loss = 0.6038, ||Grad|| = 0.5571, ||W|| = 0.6469\n",
            "Iteration 2608: Loss = 0.6035, ||Grad|| = 0.5565, ||W|| = 0.6465\n",
            "Iteration 2609: Loss = 0.6033, ||Grad|| = 0.5560, ||W|| = 0.6461\n",
            "Iteration 2610: Loss = 0.6030, ||Grad|| = 0.5554, ||W|| = 0.6457\n",
            "Iteration 2611: Loss = 0.6028, ||Grad|| = 0.5548, ||W|| = 0.6453\n",
            "Iteration 2612: Loss = 0.6025, ||Grad|| = 0.5543, ||W|| = 0.6449\n",
            "Iteration 2613: Loss = 0.6022, ||Grad|| = 0.5537, ||W|| = 0.6445\n",
            "Iteration 2614: Loss = 0.6020, ||Grad|| = 0.5532, ||W|| = 0.6441\n",
            "Iteration 2615: Loss = 0.6017, ||Grad|| = 0.5526, ||W|| = 0.6437\n",
            "Iteration 2616: Loss = 0.6015, ||Grad|| = 0.5520, ||W|| = 0.6433\n",
            "Iteration 2617: Loss = 0.6012, ||Grad|| = 0.5515, ||W|| = 0.6429\n",
            "Iteration 2618: Loss = 0.6010, ||Grad|| = 0.5509, ||W|| = 0.6425\n",
            "Iteration 2619: Loss = 0.6007, ||Grad|| = 0.5503, ||W|| = 0.6421\n",
            "Iteration 2620: Loss = 0.6004, ||Grad|| = 0.5498, ||W|| = 0.6417\n",
            "Iteration 2621: Loss = 0.6002, ||Grad|| = 0.5492, ||W|| = 0.6413\n",
            "Iteration 2622: Loss = 0.5999, ||Grad|| = 0.5487, ||W|| = 0.6409\n",
            "Iteration 2623: Loss = 0.5997, ||Grad|| = 0.5481, ||W|| = 0.6405\n",
            "Iteration 2624: Loss = 0.5994, ||Grad|| = 0.5476, ||W|| = 0.6401\n",
            "Iteration 2625: Loss = 0.5992, ||Grad|| = 0.5470, ||W|| = 0.6397\n",
            "Iteration 2626: Loss = 0.5989, ||Grad|| = 0.5464, ||W|| = 0.6393\n",
            "Iteration 2627: Loss = 0.5987, ||Grad|| = 0.5459, ||W|| = 0.6389\n",
            "Iteration 2628: Loss = 0.5984, ||Grad|| = 0.5453, ||W|| = 0.6385\n",
            "Iteration 2629: Loss = 0.5982, ||Grad|| = 0.5448, ||W|| = 0.6382\n",
            "Iteration 2630: Loss = 0.5979, ||Grad|| = 0.5442, ||W|| = 0.6378\n",
            "Iteration 2631: Loss = 0.5977, ||Grad|| = 0.5437, ||W|| = 0.6374\n",
            "Iteration 2632: Loss = 0.5974, ||Grad|| = 0.5431, ||W|| = 0.6370\n",
            "Iteration 2633: Loss = 0.5972, ||Grad|| = 0.5426, ||W|| = 0.6366\n",
            "Iteration 2634: Loss = 0.5970, ||Grad|| = 0.5420, ||W|| = 0.6362\n",
            "Iteration 2635: Loss = 0.5967, ||Grad|| = 0.5415, ||W|| = 0.6358\n",
            "Iteration 2636: Loss = 0.5965, ||Grad|| = 0.5409, ||W|| = 0.6354\n",
            "Iteration 2637: Loss = 0.5962, ||Grad|| = 0.5404, ||W|| = 0.6350\n",
            "Iteration 2638: Loss = 0.5960, ||Grad|| = 0.5398, ||W|| = 0.6347\n",
            "Iteration 2639: Loss = 0.5957, ||Grad|| = 0.5393, ||W|| = 0.6343\n",
            "Iteration 2640: Loss = 0.5955, ||Grad|| = 0.5387, ||W|| = 0.6339\n",
            "Iteration 2641: Loss = 0.5952, ||Grad|| = 0.5382, ||W|| = 0.6335\n",
            "Iteration 2642: Loss = 0.5950, ||Grad|| = 0.5376, ||W|| = 0.6331\n",
            "Iteration 2643: Loss = 0.5948, ||Grad|| = 0.5371, ||W|| = 0.6327\n",
            "Iteration 2644: Loss = 0.5945, ||Grad|| = 0.5365, ||W|| = 0.6324\n",
            "Iteration 2645: Loss = 0.5943, ||Grad|| = 0.5360, ||W|| = 0.6320\n",
            "Iteration 2646: Loss = 0.5940, ||Grad|| = 0.5355, ||W|| = 0.6316\n",
            "Iteration 2647: Loss = 0.5938, ||Grad|| = 0.5349, ||W|| = 0.6312\n",
            "Iteration 2648: Loss = 0.5936, ||Grad|| = 0.5344, ||W|| = 0.6308\n",
            "Iteration 2649: Loss = 0.5933, ||Grad|| = 0.5338, ||W|| = 0.6305\n",
            "Iteration 2650: Loss = 0.5931, ||Grad|| = 0.5333, ||W|| = 0.6301\n",
            "Iteration 2651: Loss = 0.5929, ||Grad|| = 0.5327, ||W|| = 0.6297\n",
            "Iteration 2652: Loss = 0.5926, ||Grad|| = 0.5322, ||W|| = 0.6293\n",
            "Iteration 2653: Loss = 0.5924, ||Grad|| = 0.5317, ||W|| = 0.6289\n",
            "Iteration 2654: Loss = 0.5921, ||Grad|| = 0.5311, ||W|| = 0.6286\n",
            "Iteration 2655: Loss = 0.5919, ||Grad|| = 0.5306, ||W|| = 0.6282\n",
            "Iteration 2656: Loss = 0.5917, ||Grad|| = 0.5300, ||W|| = 0.6278\n",
            "Iteration 2657: Loss = 0.5914, ||Grad|| = 0.5295, ||W|| = 0.6274\n",
            "Iteration 2658: Loss = 0.5912, ||Grad|| = 0.5290, ||W|| = 0.6271\n",
            "Iteration 2659: Loss = 0.5910, ||Grad|| = 0.5284, ||W|| = 0.6267\n",
            "Iteration 2660: Loss = 0.5907, ||Grad|| = 0.5279, ||W|| = 0.6263\n",
            "Iteration 2661: Loss = 0.5905, ||Grad|| = 0.5274, ||W|| = 0.6259\n",
            "Iteration 2662: Loss = 0.5903, ||Grad|| = 0.5268, ||W|| = 0.6256\n",
            "Iteration 2663: Loss = 0.5901, ||Grad|| = 0.5263, ||W|| = 0.6252\n",
            "Iteration 2664: Loss = 0.5898, ||Grad|| = 0.5258, ||W|| = 0.6248\n",
            "Iteration 2665: Loss = 0.5896, ||Grad|| = 0.5252, ||W|| = 0.6245\n",
            "Iteration 2666: Loss = 0.5894, ||Grad|| = 0.5247, ||W|| = 0.6241\n",
            "Iteration 2667: Loss = 0.5891, ||Grad|| = 0.5242, ||W|| = 0.6237\n",
            "Iteration 2668: Loss = 0.5889, ||Grad|| = 0.5236, ||W|| = 0.6234\n",
            "Iteration 2669: Loss = 0.5887, ||Grad|| = 0.5231, ||W|| = 0.6230\n",
            "Iteration 2670: Loss = 0.5885, ||Grad|| = 0.5226, ||W|| = 0.6226\n",
            "Iteration 2671: Loss = 0.5882, ||Grad|| = 0.5220, ||W|| = 0.6223\n",
            "Iteration 2672: Loss = 0.5880, ||Grad|| = 0.5215, ||W|| = 0.6219\n",
            "Iteration 2673: Loss = 0.5878, ||Grad|| = 0.5210, ||W|| = 0.6215\n",
            "Iteration 2674: Loss = 0.5875, ||Grad|| = 0.5205, ||W|| = 0.6212\n",
            "Iteration 2675: Loss = 0.5873, ||Grad|| = 0.5199, ||W|| = 0.6208\n",
            "Iteration 2676: Loss = 0.5871, ||Grad|| = 0.5194, ||W|| = 0.6204\n",
            "Iteration 2677: Loss = 0.5869, ||Grad|| = 0.5189, ||W|| = 0.6201\n",
            "Iteration 2678: Loss = 0.5867, ||Grad|| = 0.5184, ||W|| = 0.6197\n",
            "Iteration 2679: Loss = 0.5864, ||Grad|| = 0.5178, ||W|| = 0.6193\n",
            "Iteration 2680: Loss = 0.5862, ||Grad|| = 0.5173, ||W|| = 0.6190\n",
            "Iteration 2681: Loss = 0.5860, ||Grad|| = 0.5168, ||W|| = 0.6186\n",
            "Iteration 2682: Loss = 0.5858, ||Grad|| = 0.5163, ||W|| = 0.6183\n",
            "Iteration 2683: Loss = 0.5855, ||Grad|| = 0.5157, ||W|| = 0.6179\n",
            "Iteration 2684: Loss = 0.5853, ||Grad|| = 0.5152, ||W|| = 0.6175\n",
            "Iteration 2685: Loss = 0.5851, ||Grad|| = 0.5147, ||W|| = 0.6172\n",
            "Iteration 2686: Loss = 0.5849, ||Grad|| = 0.5142, ||W|| = 0.6168\n",
            "Iteration 2687: Loss = 0.5847, ||Grad|| = 0.5137, ||W|| = 0.6165\n",
            "Iteration 2688: Loss = 0.5844, ||Grad|| = 0.5131, ||W|| = 0.6161\n",
            "Iteration 2689: Loss = 0.5842, ||Grad|| = 0.5126, ||W|| = 0.6157\n",
            "Iteration 2690: Loss = 0.5840, ||Grad|| = 0.5121, ||W|| = 0.6154\n",
            "Iteration 2691: Loss = 0.5838, ||Grad|| = 0.5116, ||W|| = 0.6150\n",
            "Iteration 2692: Loss = 0.5836, ||Grad|| = 0.5111, ||W|| = 0.6147\n",
            "Iteration 2693: Loss = 0.5834, ||Grad|| = 0.5105, ||W|| = 0.6143\n",
            "Iteration 2694: Loss = 0.5831, ||Grad|| = 0.5100, ||W|| = 0.6140\n",
            "Iteration 2695: Loss = 0.5829, ||Grad|| = 0.5095, ||W|| = 0.6136\n",
            "Iteration 2696: Loss = 0.5827, ||Grad|| = 0.5090, ||W|| = 0.6133\n",
            "Iteration 2697: Loss = 0.5825, ||Grad|| = 0.5085, ||W|| = 0.6129\n",
            "Iteration 2698: Loss = 0.5823, ||Grad|| = 0.5080, ||W|| = 0.6126\n",
            "Iteration 2699: Loss = 0.5821, ||Grad|| = 0.5075, ||W|| = 0.6122\n",
            "Iteration 2700: Loss = 0.5819, ||Grad|| = 0.5069, ||W|| = 0.6119\n",
            "Iteration 2701: Loss = 0.5817, ||Grad|| = 0.5064, ||W|| = 0.6115\n",
            "Iteration 2702: Loss = 0.5814, ||Grad|| = 0.5059, ||W|| = 0.6112\n",
            "Iteration 2703: Loss = 0.5812, ||Grad|| = 0.5054, ||W|| = 0.6108\n",
            "Iteration 2704: Loss = 0.5810, ||Grad|| = 0.5049, ||W|| = 0.6105\n",
            "Iteration 2705: Loss = 0.5808, ||Grad|| = 0.5044, ||W|| = 0.6101\n",
            "Iteration 2706: Loss = 0.5806, ||Grad|| = 0.5039, ||W|| = 0.6098\n",
            "Iteration 2707: Loss = 0.5804, ||Grad|| = 0.5034, ||W|| = 0.6094\n",
            "Iteration 2708: Loss = 0.5802, ||Grad|| = 0.5029, ||W|| = 0.6091\n",
            "Iteration 2709: Loss = 0.5800, ||Grad|| = 0.5024, ||W|| = 0.6087\n",
            "Iteration 2710: Loss = 0.5798, ||Grad|| = 0.5018, ||W|| = 0.6084\n",
            "Iteration 2711: Loss = 0.5796, ||Grad|| = 0.5013, ||W|| = 0.6080\n",
            "Iteration 2712: Loss = 0.5793, ||Grad|| = 0.5008, ||W|| = 0.6077\n",
            "Iteration 2713: Loss = 0.5791, ||Grad|| = 0.5003, ||W|| = 0.6074\n",
            "Iteration 2714: Loss = 0.5789, ||Grad|| = 0.4998, ||W|| = 0.6070\n",
            "Iteration 2715: Loss = 0.5787, ||Grad|| = 0.4993, ||W|| = 0.6067\n",
            "Iteration 2716: Loss = 0.5785, ||Grad|| = 0.4988, ||W|| = 0.6063\n",
            "Iteration 2717: Loss = 0.5783, ||Grad|| = 0.4983, ||W|| = 0.6060\n",
            "Iteration 2718: Loss = 0.5781, ||Grad|| = 0.4978, ||W|| = 0.6056\n",
            "Iteration 2719: Loss = 0.5779, ||Grad|| = 0.4973, ||W|| = 0.6053\n",
            "Iteration 2720: Loss = 0.5777, ||Grad|| = 0.4968, ||W|| = 0.6050\n",
            "Iteration 2721: Loss = 0.5775, ||Grad|| = 0.4963, ||W|| = 0.6046\n",
            "Iteration 2722: Loss = 0.5773, ||Grad|| = 0.4958, ||W|| = 0.6043\n",
            "Iteration 2723: Loss = 0.5771, ||Grad|| = 0.4953, ||W|| = 0.6040\n",
            "Iteration 2724: Loss = 0.5769, ||Grad|| = 0.4948, ||W|| = 0.6036\n",
            "Iteration 2725: Loss = 0.5767, ||Grad|| = 0.4943, ||W|| = 0.6033\n",
            "Iteration 2726: Loss = 0.5765, ||Grad|| = 0.4938, ||W|| = 0.6029\n",
            "Iteration 2727: Loss = 0.5763, ||Grad|| = 0.4933, ||W|| = 0.6026\n",
            "Iteration 2728: Loss = 0.5761, ||Grad|| = 0.4928, ||W|| = 0.6023\n",
            "Iteration 2729: Loss = 0.5759, ||Grad|| = 0.4923, ||W|| = 0.6019\n",
            "Iteration 2730: Loss = 0.5757, ||Grad|| = 0.4918, ||W|| = 0.6016\n",
            "Iteration 2731: Loss = 0.5755, ||Grad|| = 0.4913, ||W|| = 0.6013\n",
            "Iteration 2732: Loss = 0.5753, ||Grad|| = 0.4908, ||W|| = 0.6009\n",
            "Iteration 2733: Loss = 0.5751, ||Grad|| = 0.4903, ||W|| = 0.6006\n",
            "Iteration 2734: Loss = 0.5749, ||Grad|| = 0.4898, ||W|| = 0.6003\n",
            "Iteration 2735: Loss = 0.5747, ||Grad|| = 0.4893, ||W|| = 0.5999\n",
            "Iteration 2736: Loss = 0.5745, ||Grad|| = 0.4888, ||W|| = 0.5996\n",
            "Iteration 2737: Loss = 0.5743, ||Grad|| = 0.4884, ||W|| = 0.5993\n",
            "Iteration 2738: Loss = 0.5741, ||Grad|| = 0.4879, ||W|| = 0.5989\n",
            "Iteration 2739: Loss = 0.5739, ||Grad|| = 0.4874, ||W|| = 0.5986\n",
            "Iteration 2740: Loss = 0.5737, ||Grad|| = 0.4869, ||W|| = 0.5983\n",
            "Iteration 2741: Loss = 0.5735, ||Grad|| = 0.4864, ||W|| = 0.5980\n",
            "Iteration 2742: Loss = 0.5733, ||Grad|| = 0.4859, ||W|| = 0.5976\n",
            "Iteration 2743: Loss = 0.5731, ||Grad|| = 0.4854, ||W|| = 0.5973\n",
            "Iteration 2744: Loss = 0.5730, ||Grad|| = 0.4849, ||W|| = 0.5970\n",
            "Iteration 2745: Loss = 0.5728, ||Grad|| = 0.4844, ||W|| = 0.5967\n",
            "Iteration 2746: Loss = 0.5726, ||Grad|| = 0.4839, ||W|| = 0.5963\n",
            "Iteration 2747: Loss = 0.5724, ||Grad|| = 0.4835, ||W|| = 0.5960\n",
            "Iteration 2748: Loss = 0.5722, ||Grad|| = 0.4830, ||W|| = 0.5957\n",
            "Iteration 2749: Loss = 0.5720, ||Grad|| = 0.4825, ||W|| = 0.5954\n",
            "Iteration 2750: Loss = 0.5718, ||Grad|| = 0.4820, ||W|| = 0.5950\n",
            "Iteration 2751: Loss = 0.5716, ||Grad|| = 0.4815, ||W|| = 0.5947\n",
            "Iteration 2752: Loss = 0.5714, ||Grad|| = 0.4810, ||W|| = 0.5944\n",
            "Iteration 2753: Loss = 0.5712, ||Grad|| = 0.4805, ||W|| = 0.5941\n",
            "Iteration 2754: Loss = 0.5710, ||Grad|| = 0.4801, ||W|| = 0.5937\n",
            "Iteration 2755: Loss = 0.5709, ||Grad|| = 0.4796, ||W|| = 0.5934\n",
            "Iteration 2756: Loss = 0.5707, ||Grad|| = 0.4791, ||W|| = 0.5931\n",
            "Iteration 2757: Loss = 0.5705, ||Grad|| = 0.4786, ||W|| = 0.5928\n",
            "Iteration 2758: Loss = 0.5703, ||Grad|| = 0.4781, ||W|| = 0.5925\n",
            "Iteration 2759: Loss = 0.5701, ||Grad|| = 0.4776, ||W|| = 0.5921\n",
            "Iteration 2760: Loss = 0.5699, ||Grad|| = 0.4772, ||W|| = 0.5918\n",
            "Iteration 2761: Loss = 0.5697, ||Grad|| = 0.4767, ||W|| = 0.5915\n",
            "Iteration 2762: Loss = 0.5696, ||Grad|| = 0.4762, ||W|| = 0.5912\n",
            "Iteration 2763: Loss = 0.5694, ||Grad|| = 0.4757, ||W|| = 0.5909\n",
            "Iteration 2764: Loss = 0.5692, ||Grad|| = 0.4753, ||W|| = 0.5905\n",
            "Iteration 2765: Loss = 0.5690, ||Grad|| = 0.4748, ||W|| = 0.5902\n",
            "Iteration 2766: Loss = 0.5688, ||Grad|| = 0.4743, ||W|| = 0.5899\n",
            "Iteration 2767: Loss = 0.5686, ||Grad|| = 0.4738, ||W|| = 0.5896\n",
            "Iteration 2768: Loss = 0.5684, ||Grad|| = 0.4733, ||W|| = 0.5893\n",
            "Iteration 2769: Loss = 0.5683, ||Grad|| = 0.4729, ||W|| = 0.5890\n",
            "Iteration 2770: Loss = 0.5681, ||Grad|| = 0.4724, ||W|| = 0.5887\n",
            "Iteration 2771: Loss = 0.5679, ||Grad|| = 0.4719, ||W|| = 0.5883\n",
            "Iteration 2772: Loss = 0.5677, ||Grad|| = 0.4714, ||W|| = 0.5880\n",
            "Iteration 2773: Loss = 0.5675, ||Grad|| = 0.4710, ||W|| = 0.5877\n",
            "Iteration 2774: Loss = 0.5674, ||Grad|| = 0.4705, ||W|| = 0.5874\n",
            "Iteration 2775: Loss = 0.5672, ||Grad|| = 0.4700, ||W|| = 0.5871\n",
            "Iteration 2776: Loss = 0.5670, ||Grad|| = 0.4696, ||W|| = 0.5868\n",
            "Iteration 2777: Loss = 0.5668, ||Grad|| = 0.4691, ||W|| = 0.5865\n",
            "Iteration 2778: Loss = 0.5666, ||Grad|| = 0.4686, ||W|| = 0.5862\n",
            "Iteration 2779: Loss = 0.5665, ||Grad|| = 0.4681, ||W|| = 0.5859\n",
            "Iteration 2780: Loss = 0.5663, ||Grad|| = 0.4677, ||W|| = 0.5856\n",
            "Iteration 2781: Loss = 0.5661, ||Grad|| = 0.4672, ||W|| = 0.5852\n",
            "Iteration 2782: Loss = 0.5659, ||Grad|| = 0.4667, ||W|| = 0.5849\n",
            "Iteration 2783: Loss = 0.5658, ||Grad|| = 0.4663, ||W|| = 0.5846\n",
            "Iteration 2784: Loss = 0.5656, ||Grad|| = 0.4658, ||W|| = 0.5843\n",
            "Iteration 2785: Loss = 0.5654, ||Grad|| = 0.4653, ||W|| = 0.5840\n",
            "Iteration 2786: Loss = 0.5652, ||Grad|| = 0.4649, ||W|| = 0.5837\n",
            "Iteration 2787: Loss = 0.5650, ||Grad|| = 0.4644, ||W|| = 0.5834\n",
            "Iteration 2788: Loss = 0.5649, ||Grad|| = 0.4639, ||W|| = 0.5831\n",
            "Iteration 2789: Loss = 0.5647, ||Grad|| = 0.4635, ||W|| = 0.5828\n",
            "Iteration 2790: Loss = 0.5645, ||Grad|| = 0.4630, ||W|| = 0.5825\n",
            "Iteration 2791: Loss = 0.5643, ||Grad|| = 0.4625, ||W|| = 0.5822\n",
            "Iteration 2792: Loss = 0.5642, ||Grad|| = 0.4621, ||W|| = 0.5819\n",
            "Iteration 2793: Loss = 0.5640, ||Grad|| = 0.4616, ||W|| = 0.5816\n",
            "Iteration 2794: Loss = 0.5638, ||Grad|| = 0.4611, ||W|| = 0.5813\n",
            "Iteration 2795: Loss = 0.5637, ||Grad|| = 0.4607, ||W|| = 0.5810\n",
            "Iteration 2796: Loss = 0.5635, ||Grad|| = 0.4602, ||W|| = 0.5807\n",
            "Iteration 2797: Loss = 0.5633, ||Grad|| = 0.4598, ||W|| = 0.5804\n",
            "Iteration 2798: Loss = 0.5631, ||Grad|| = 0.4593, ||W|| = 0.5801\n",
            "Iteration 2799: Loss = 0.5630, ||Grad|| = 0.4588, ||W|| = 0.5798\n",
            "Iteration 2800: Loss = 0.5628, ||Grad|| = 0.4584, ||W|| = 0.5795\n",
            "Iteration 2801: Loss = 0.5626, ||Grad|| = 0.4579, ||W|| = 0.5792\n",
            "Iteration 2802: Loss = 0.5625, ||Grad|| = 0.4575, ||W|| = 0.5789\n",
            "Iteration 2803: Loss = 0.5623, ||Grad|| = 0.4570, ||W|| = 0.5786\n",
            "Iteration 2804: Loss = 0.5621, ||Grad|| = 0.4565, ||W|| = 0.5783\n",
            "Iteration 2805: Loss = 0.5620, ||Grad|| = 0.4561, ||W|| = 0.5780\n",
            "Iteration 2806: Loss = 0.5618, ||Grad|| = 0.4556, ||W|| = 0.5777\n",
            "Iteration 2807: Loss = 0.5616, ||Grad|| = 0.4552, ||W|| = 0.5774\n",
            "Iteration 2808: Loss = 0.5614, ||Grad|| = 0.4547, ||W|| = 0.5771\n",
            "Iteration 2809: Loss = 0.5613, ||Grad|| = 0.4543, ||W|| = 0.5768\n",
            "Iteration 2810: Loss = 0.5611, ||Grad|| = 0.4538, ||W|| = 0.5765\n",
            "Iteration 2811: Loss = 0.5609, ||Grad|| = 0.4533, ||W|| = 0.5762\n",
            "Iteration 2812: Loss = 0.5608, ||Grad|| = 0.4529, ||W|| = 0.5759\n",
            "Iteration 2813: Loss = 0.5606, ||Grad|| = 0.4524, ||W|| = 0.5756\n",
            "Iteration 2814: Loss = 0.5604, ||Grad|| = 0.4520, ||W|| = 0.5754\n",
            "Iteration 2815: Loss = 0.5603, ||Grad|| = 0.4515, ||W|| = 0.5751\n",
            "Iteration 2816: Loss = 0.5601, ||Grad|| = 0.4511, ||W|| = 0.5748\n",
            "Iteration 2817: Loss = 0.5600, ||Grad|| = 0.4506, ||W|| = 0.5745\n",
            "Iteration 2818: Loss = 0.5598, ||Grad|| = 0.4502, ||W|| = 0.5742\n",
            "Iteration 2819: Loss = 0.5596, ||Grad|| = 0.4497, ||W|| = 0.5739\n",
            "Iteration 2820: Loss = 0.5595, ||Grad|| = 0.4493, ||W|| = 0.5736\n",
            "Iteration 2821: Loss = 0.5593, ||Grad|| = 0.4488, ||W|| = 0.5733\n",
            "Iteration 2822: Loss = 0.5591, ||Grad|| = 0.4484, ||W|| = 0.5730\n",
            "Iteration 2823: Loss = 0.5590, ||Grad|| = 0.4479, ||W|| = 0.5728\n",
            "Iteration 2824: Loss = 0.5588, ||Grad|| = 0.4475, ||W|| = 0.5725\n",
            "Iteration 2825: Loss = 0.5587, ||Grad|| = 0.4470, ||W|| = 0.5722\n",
            "Iteration 2826: Loss = 0.5585, ||Grad|| = 0.4466, ||W|| = 0.5719\n",
            "Iteration 2827: Loss = 0.5583, ||Grad|| = 0.4461, ||W|| = 0.5716\n",
            "Iteration 2828: Loss = 0.5582, ||Grad|| = 0.4457, ||W|| = 0.5713\n",
            "Iteration 2829: Loss = 0.5580, ||Grad|| = 0.4452, ||W|| = 0.5710\n",
            "Iteration 2830: Loss = 0.5579, ||Grad|| = 0.4448, ||W|| = 0.5708\n",
            "Iteration 2831: Loss = 0.5577, ||Grad|| = 0.4444, ||W|| = 0.5705\n",
            "Iteration 2832: Loss = 0.5575, ||Grad|| = 0.4439, ||W|| = 0.5702\n",
            "Iteration 2833: Loss = 0.5574, ||Grad|| = 0.4435, ||W|| = 0.5699\n",
            "Iteration 2834: Loss = 0.5572, ||Grad|| = 0.4430, ||W|| = 0.5696\n",
            "Iteration 2835: Loss = 0.5571, ||Grad|| = 0.4426, ||W|| = 0.5693\n",
            "Iteration 2836: Loss = 0.5569, ||Grad|| = 0.4421, ||W|| = 0.5691\n",
            "Iteration 2837: Loss = 0.5567, ||Grad|| = 0.4417, ||W|| = 0.5688\n",
            "Iteration 2838: Loss = 0.5566, ||Grad|| = 0.4413, ||W|| = 0.5685\n",
            "Iteration 2839: Loss = 0.5564, ||Grad|| = 0.4408, ||W|| = 0.5682\n",
            "Iteration 2840: Loss = 0.5563, ||Grad|| = 0.4404, ||W|| = 0.5679\n",
            "Iteration 2841: Loss = 0.5561, ||Grad|| = 0.4399, ||W|| = 0.5677\n",
            "Iteration 2842: Loss = 0.5560, ||Grad|| = 0.4395, ||W|| = 0.5674\n",
            "Iteration 2843: Loss = 0.5558, ||Grad|| = 0.4391, ||W|| = 0.5671\n",
            "Iteration 2844: Loss = 0.5557, ||Grad|| = 0.4386, ||W|| = 0.5668\n",
            "Iteration 2845: Loss = 0.5555, ||Grad|| = 0.4382, ||W|| = 0.5665\n",
            "Iteration 2846: Loss = 0.5553, ||Grad|| = 0.4377, ||W|| = 0.5663\n",
            "Iteration 2847: Loss = 0.5552, ||Grad|| = 0.4373, ||W|| = 0.5660\n",
            "Iteration 2848: Loss = 0.5550, ||Grad|| = 0.4369, ||W|| = 0.5657\n",
            "Iteration 2849: Loss = 0.5549, ||Grad|| = 0.4364, ||W|| = 0.5654\n",
            "Iteration 2850: Loss = 0.5547, ||Grad|| = 0.4360, ||W|| = 0.5652\n",
            "Iteration 2851: Loss = 0.5546, ||Grad|| = 0.4356, ||W|| = 0.5649\n",
            "Iteration 2852: Loss = 0.5544, ||Grad|| = 0.4351, ||W|| = 0.5646\n",
            "Iteration 2853: Loss = 0.5543, ||Grad|| = 0.4347, ||W|| = 0.5643\n",
            "Iteration 2854: Loss = 0.5541, ||Grad|| = 0.4343, ||W|| = 0.5641\n",
            "Iteration 2855: Loss = 0.5540, ||Grad|| = 0.4338, ||W|| = 0.5638\n",
            "Iteration 2856: Loss = 0.5538, ||Grad|| = 0.4334, ||W|| = 0.5635\n",
            "Iteration 2857: Loss = 0.5537, ||Grad|| = 0.4330, ||W|| = 0.5632\n",
            "Iteration 2858: Loss = 0.5535, ||Grad|| = 0.4325, ||W|| = 0.5630\n",
            "Iteration 2859: Loss = 0.5534, ||Grad|| = 0.4321, ||W|| = 0.5627\n",
            "Iteration 2860: Loss = 0.5532, ||Grad|| = 0.4317, ||W|| = 0.5624\n",
            "Iteration 2861: Loss = 0.5531, ||Grad|| = 0.4312, ||W|| = 0.5622\n",
            "Iteration 2862: Loss = 0.5529, ||Grad|| = 0.4308, ||W|| = 0.5619\n",
            "Iteration 2863: Loss = 0.5528, ||Grad|| = 0.4304, ||W|| = 0.5616\n",
            "Iteration 2864: Loss = 0.5526, ||Grad|| = 0.4299, ||W|| = 0.5614\n",
            "Iteration 2865: Loss = 0.5525, ||Grad|| = 0.4295, ||W|| = 0.5611\n",
            "Iteration 2866: Loss = 0.5523, ||Grad|| = 0.4291, ||W|| = 0.5608\n",
            "Iteration 2867: Loss = 0.5522, ||Grad|| = 0.4287, ||W|| = 0.5606\n",
            "Iteration 2868: Loss = 0.5520, ||Grad|| = 0.4282, ||W|| = 0.5603\n",
            "Iteration 2869: Loss = 0.5519, ||Grad|| = 0.4278, ||W|| = 0.5600\n",
            "Iteration 2870: Loss = 0.5517, ||Grad|| = 0.4274, ||W|| = 0.5598\n",
            "Iteration 2871: Loss = 0.5516, ||Grad|| = 0.4270, ||W|| = 0.5595\n",
            "Iteration 2872: Loss = 0.5515, ||Grad|| = 0.4265, ||W|| = 0.5592\n",
            "Iteration 2873: Loss = 0.5513, ||Grad|| = 0.4261, ||W|| = 0.5590\n",
            "Iteration 2874: Loss = 0.5512, ||Grad|| = 0.4257, ||W|| = 0.5587\n",
            "Iteration 2875: Loss = 0.5510, ||Grad|| = 0.4253, ||W|| = 0.5584\n",
            "Iteration 2876: Loss = 0.5509, ||Grad|| = 0.4248, ||W|| = 0.5582\n",
            "Iteration 2877: Loss = 0.5507, ||Grad|| = 0.4244, ||W|| = 0.5579\n",
            "Iteration 2878: Loss = 0.5506, ||Grad|| = 0.4240, ||W|| = 0.5576\n",
            "Iteration 2879: Loss = 0.5504, ||Grad|| = 0.4236, ||W|| = 0.5574\n",
            "Iteration 2880: Loss = 0.5503, ||Grad|| = 0.4231, ||W|| = 0.5571\n",
            "Iteration 2881: Loss = 0.5502, ||Grad|| = 0.4227, ||W|| = 0.5569\n",
            "Iteration 2882: Loss = 0.5500, ||Grad|| = 0.4223, ||W|| = 0.5566\n",
            "Iteration 2883: Loss = 0.5499, ||Grad|| = 0.4219, ||W|| = 0.5563\n",
            "Iteration 2884: Loss = 0.5497, ||Grad|| = 0.4215, ||W|| = 0.5561\n",
            "Iteration 2885: Loss = 0.5496, ||Grad|| = 0.4210, ||W|| = 0.5558\n",
            "Iteration 2886: Loss = 0.5494, ||Grad|| = 0.4206, ||W|| = 0.5556\n",
            "Iteration 2887: Loss = 0.5493, ||Grad|| = 0.4202, ||W|| = 0.5553\n",
            "Iteration 2888: Loss = 0.5492, ||Grad|| = 0.4198, ||W|| = 0.5550\n",
            "Iteration 2889: Loss = 0.5490, ||Grad|| = 0.4194, ||W|| = 0.5548\n",
            "Iteration 2890: Loss = 0.5489, ||Grad|| = 0.4189, ||W|| = 0.5545\n",
            "Iteration 2891: Loss = 0.5487, ||Grad|| = 0.4185, ||W|| = 0.5543\n",
            "Iteration 2892: Loss = 0.5486, ||Grad|| = 0.4181, ||W|| = 0.5540\n",
            "Iteration 2893: Loss = 0.5485, ||Grad|| = 0.4177, ||W|| = 0.5538\n",
            "Iteration 2894: Loss = 0.5483, ||Grad|| = 0.4173, ||W|| = 0.5535\n",
            "Iteration 2895: Loss = 0.5482, ||Grad|| = 0.4169, ||W|| = 0.5532\n",
            "Iteration 2896: Loss = 0.5481, ||Grad|| = 0.4165, ||W|| = 0.5530\n",
            "Iteration 2897: Loss = 0.5479, ||Grad|| = 0.4160, ||W|| = 0.5527\n",
            "Iteration 2898: Loss = 0.5478, ||Grad|| = 0.4156, ||W|| = 0.5525\n",
            "Iteration 2899: Loss = 0.5476, ||Grad|| = 0.4152, ||W|| = 0.5522\n",
            "Iteration 2900: Loss = 0.5475, ||Grad|| = 0.4148, ||W|| = 0.5520\n",
            "Iteration 2901: Loss = 0.5474, ||Grad|| = 0.4144, ||W|| = 0.5517\n",
            "Iteration 2902: Loss = 0.5472, ||Grad|| = 0.4140, ||W|| = 0.5515\n",
            "Iteration 2903: Loss = 0.5471, ||Grad|| = 0.4136, ||W|| = 0.5512\n",
            "Iteration 2904: Loss = 0.5470, ||Grad|| = 0.4132, ||W|| = 0.5510\n",
            "Iteration 2905: Loss = 0.5468, ||Grad|| = 0.4127, ||W|| = 0.5507\n",
            "Iteration 2906: Loss = 0.5467, ||Grad|| = 0.4123, ||W|| = 0.5505\n",
            "Iteration 2907: Loss = 0.5466, ||Grad|| = 0.4119, ||W|| = 0.5502\n",
            "Iteration 2908: Loss = 0.5464, ||Grad|| = 0.4115, ||W|| = 0.5500\n",
            "Iteration 2909: Loss = 0.5463, ||Grad|| = 0.4111, ||W|| = 0.5497\n",
            "Iteration 2910: Loss = 0.5461, ||Grad|| = 0.4107, ||W|| = 0.5495\n",
            "Iteration 2911: Loss = 0.5460, ||Grad|| = 0.4103, ||W|| = 0.5492\n",
            "Iteration 2912: Loss = 0.5459, ||Grad|| = 0.4099, ||W|| = 0.5490\n",
            "Iteration 2913: Loss = 0.5457, ||Grad|| = 0.4095, ||W|| = 0.5487\n",
            "Iteration 2914: Loss = 0.5456, ||Grad|| = 0.4091, ||W|| = 0.5485\n",
            "Iteration 2915: Loss = 0.5455, ||Grad|| = 0.4087, ||W|| = 0.5482\n",
            "Iteration 2916: Loss = 0.5454, ||Grad|| = 0.4083, ||W|| = 0.5480\n",
            "Iteration 2917: Loss = 0.5452, ||Grad|| = 0.4078, ||W|| = 0.5477\n",
            "Iteration 2918: Loss = 0.5451, ||Grad|| = 0.4074, ||W|| = 0.5475\n",
            "Iteration 2919: Loss = 0.5450, ||Grad|| = 0.4070, ||W|| = 0.5472\n",
            "Iteration 2920: Loss = 0.5448, ||Grad|| = 0.4066, ||W|| = 0.5470\n",
            "Iteration 2921: Loss = 0.5447, ||Grad|| = 0.4062, ||W|| = 0.5468\n",
            "Iteration 2922: Loss = 0.5446, ||Grad|| = 0.4058, ||W|| = 0.5465\n",
            "Iteration 2923: Loss = 0.5444, ||Grad|| = 0.4054, ||W|| = 0.5463\n",
            "Iteration 2924: Loss = 0.5443, ||Grad|| = 0.4050, ||W|| = 0.5460\n",
            "Iteration 2925: Loss = 0.5442, ||Grad|| = 0.4046, ||W|| = 0.5458\n",
            "Iteration 2926: Loss = 0.5440, ||Grad|| = 0.4042, ||W|| = 0.5455\n",
            "Iteration 2927: Loss = 0.5439, ||Grad|| = 0.4038, ||W|| = 0.5453\n",
            "Iteration 2928: Loss = 0.5438, ||Grad|| = 0.4034, ||W|| = 0.5451\n",
            "Iteration 2929: Loss = 0.5437, ||Grad|| = 0.4030, ||W|| = 0.5448\n",
            "Iteration 2930: Loss = 0.5435, ||Grad|| = 0.4026, ||W|| = 0.5446\n",
            "Iteration 2931: Loss = 0.5434, ||Grad|| = 0.4022, ||W|| = 0.5443\n",
            "Iteration 2932: Loss = 0.5433, ||Grad|| = 0.4018, ||W|| = 0.5441\n",
            "Iteration 2933: Loss = 0.5431, ||Grad|| = 0.4014, ||W|| = 0.5439\n",
            "Iteration 2934: Loss = 0.5430, ||Grad|| = 0.4010, ||W|| = 0.5436\n",
            "Iteration 2935: Loss = 0.5429, ||Grad|| = 0.4006, ||W|| = 0.5434\n",
            "Iteration 2936: Loss = 0.5428, ||Grad|| = 0.4002, ||W|| = 0.5431\n",
            "Iteration 2937: Loss = 0.5426, ||Grad|| = 0.3998, ||W|| = 0.5429\n",
            "Iteration 2938: Loss = 0.5425, ||Grad|| = 0.3994, ||W|| = 0.5427\n",
            "Iteration 2939: Loss = 0.5424, ||Grad|| = 0.3990, ||W|| = 0.5424\n",
            "Iteration 2940: Loss = 0.5423, ||Grad|| = 0.3987, ||W|| = 0.5422\n",
            "Iteration 2941: Loss = 0.5421, ||Grad|| = 0.3983, ||W|| = 0.5420\n",
            "Iteration 2942: Loss = 0.5420, ||Grad|| = 0.3979, ||W|| = 0.5417\n",
            "Iteration 2943: Loss = 0.5419, ||Grad|| = 0.3975, ||W|| = 0.5415\n",
            "Iteration 2944: Loss = 0.5418, ||Grad|| = 0.3971, ||W|| = 0.5412\n",
            "Iteration 2945: Loss = 0.5416, ||Grad|| = 0.3967, ||W|| = 0.5410\n",
            "Iteration 2946: Loss = 0.5415, ||Grad|| = 0.3963, ||W|| = 0.5408\n",
            "Iteration 2947: Loss = 0.5414, ||Grad|| = 0.3959, ||W|| = 0.5405\n",
            "Iteration 2948: Loss = 0.5413, ||Grad|| = 0.3955, ||W|| = 0.5403\n",
            "Iteration 2949: Loss = 0.5411, ||Grad|| = 0.3951, ||W|| = 0.5401\n",
            "Iteration 2950: Loss = 0.5410, ||Grad|| = 0.3947, ||W|| = 0.5398\n",
            "Iteration 2951: Loss = 0.5409, ||Grad|| = 0.3943, ||W|| = 0.5396\n",
            "Iteration 2952: Loss = 0.5408, ||Grad|| = 0.3939, ||W|| = 0.5394\n",
            "Iteration 2953: Loss = 0.5407, ||Grad|| = 0.3936, ||W|| = 0.5391\n",
            "Iteration 2954: Loss = 0.5405, ||Grad|| = 0.3932, ||W|| = 0.5389\n",
            "Iteration 2955: Loss = 0.5404, ||Grad|| = 0.3928, ||W|| = 0.5387\n",
            "Iteration 2956: Loss = 0.5403, ||Grad|| = 0.3924, ||W|| = 0.5385\n",
            "Iteration 2957: Loss = 0.5402, ||Grad|| = 0.3920, ||W|| = 0.5382\n",
            "Iteration 2958: Loss = 0.5401, ||Grad|| = 0.3916, ||W|| = 0.5380\n",
            "Iteration 2959: Loss = 0.5399, ||Grad|| = 0.3912, ||W|| = 0.5378\n",
            "Iteration 2960: Loss = 0.5398, ||Grad|| = 0.3908, ||W|| = 0.5375\n",
            "Iteration 2961: Loss = 0.5397, ||Grad|| = 0.3905, ||W|| = 0.5373\n",
            "Iteration 2962: Loss = 0.5396, ||Grad|| = 0.3901, ||W|| = 0.5371\n",
            "Iteration 2963: Loss = 0.5395, ||Grad|| = 0.3897, ||W|| = 0.5369\n",
            "Iteration 2964: Loss = 0.5393, ||Grad|| = 0.3893, ||W|| = 0.5366\n",
            "Iteration 2965: Loss = 0.5392, ||Grad|| = 0.3889, ||W|| = 0.5364\n",
            "Iteration 2966: Loss = 0.5391, ||Grad|| = 0.3885, ||W|| = 0.5362\n",
            "Iteration 2967: Loss = 0.5390, ||Grad|| = 0.3881, ||W|| = 0.5359\n",
            "Iteration 2968: Loss = 0.5389, ||Grad|| = 0.3878, ||W|| = 0.5357\n",
            "Iteration 2969: Loss = 0.5387, ||Grad|| = 0.3874, ||W|| = 0.5355\n",
            "Iteration 2970: Loss = 0.5386, ||Grad|| = 0.3870, ||W|| = 0.5353\n",
            "Iteration 2971: Loss = 0.5385, ||Grad|| = 0.3866, ||W|| = 0.5350\n",
            "Iteration 2972: Loss = 0.5384, ||Grad|| = 0.3862, ||W|| = 0.5348\n",
            "Iteration 2973: Loss = 0.5383, ||Grad|| = 0.3858, ||W|| = 0.5346\n",
            "Iteration 2974: Loss = 0.5382, ||Grad|| = 0.3855, ||W|| = 0.5344\n",
            "Iteration 2975: Loss = 0.5380, ||Grad|| = 0.3851, ||W|| = 0.5342\n",
            "Iteration 2976: Loss = 0.5379, ||Grad|| = 0.3847, ||W|| = 0.5339\n",
            "Iteration 2977: Loss = 0.5378, ||Grad|| = 0.3843, ||W|| = 0.5337\n",
            "Iteration 2978: Loss = 0.5377, ||Grad|| = 0.3839, ||W|| = 0.5335\n",
            "Iteration 2979: Loss = 0.5376, ||Grad|| = 0.3836, ||W|| = 0.5333\n",
            "Iteration 2980: Loss = 0.5375, ||Grad|| = 0.3832, ||W|| = 0.5330\n",
            "Iteration 2981: Loss = 0.5374, ||Grad|| = 0.3828, ||W|| = 0.5328\n",
            "Iteration 2982: Loss = 0.5372, ||Grad|| = 0.3824, ||W|| = 0.5326\n",
            "Iteration 2983: Loss = 0.5371, ||Grad|| = 0.3821, ||W|| = 0.5324\n",
            "Iteration 2984: Loss = 0.5370, ||Grad|| = 0.3817, ||W|| = 0.5322\n",
            "Iteration 2985: Loss = 0.5369, ||Grad|| = 0.3813, ||W|| = 0.5319\n",
            "Iteration 2986: Loss = 0.5368, ||Grad|| = 0.3809, ||W|| = 0.5317\n",
            "Iteration 2987: Loss = 0.5367, ||Grad|| = 0.3806, ||W|| = 0.5315\n",
            "Iteration 2988: Loss = 0.5366, ||Grad|| = 0.3802, ||W|| = 0.5313\n",
            "Iteration 2989: Loss = 0.5364, ||Grad|| = 0.3798, ||W|| = 0.5311\n",
            "Iteration 2990: Loss = 0.5363, ||Grad|| = 0.3794, ||W|| = 0.5309\n",
            "Iteration 2991: Loss = 0.5362, ||Grad|| = 0.3791, ||W|| = 0.5306\n",
            "Iteration 2992: Loss = 0.5361, ||Grad|| = 0.3787, ||W|| = 0.5304\n",
            "Iteration 2993: Loss = 0.5360, ||Grad|| = 0.3783, ||W|| = 0.5302\n",
            "Iteration 2994: Loss = 0.5359, ||Grad|| = 0.3779, ||W|| = 0.5300\n",
            "Iteration 2995: Loss = 0.5358, ||Grad|| = 0.3776, ||W|| = 0.5298\n",
            "Iteration 2996: Loss = 0.5357, ||Grad|| = 0.3772, ||W|| = 0.5296\n",
            "Iteration 2997: Loss = 0.5355, ||Grad|| = 0.3768, ||W|| = 0.5293\n",
            "Iteration 2998: Loss = 0.5354, ||Grad|| = 0.3764, ||W|| = 0.5291\n",
            "Iteration 2999: Loss = 0.5353, ||Grad|| = 0.3761, ||W|| = 0.5289\n",
            "Iteration 3000: Loss = 0.5352, ||Grad|| = 0.3757, ||W|| = 0.5287\n",
            "Iteration 3001: Loss = 0.5351, ||Grad|| = 0.3753, ||W|| = 0.5285\n",
            "Iteration 3002: Loss = 0.5350, ||Grad|| = 0.3750, ||W|| = 0.5283\n",
            "Iteration 3003: Loss = 0.5349, ||Grad|| = 0.3746, ||W|| = 0.5281\n",
            "Iteration 3004: Loss = 0.5348, ||Grad|| = 0.3742, ||W|| = 0.5279\n",
            "Iteration 3005: Loss = 0.5347, ||Grad|| = 0.3739, ||W|| = 0.5276\n",
            "Iteration 3006: Loss = 0.5346, ||Grad|| = 0.3735, ||W|| = 0.5274\n",
            "Iteration 3007: Loss = 0.5345, ||Grad|| = 0.3731, ||W|| = 0.5272\n",
            "Iteration 3008: Loss = 0.5343, ||Grad|| = 0.3728, ||W|| = 0.5270\n",
            "Iteration 3009: Loss = 0.5342, ||Grad|| = 0.3724, ||W|| = 0.5268\n",
            "Iteration 3010: Loss = 0.5341, ||Grad|| = 0.3720, ||W|| = 0.5266\n",
            "Iteration 3011: Loss = 0.5340, ||Grad|| = 0.3717, ||W|| = 0.5264\n",
            "Iteration 3012: Loss = 0.5339, ||Grad|| = 0.3713, ||W|| = 0.5262\n",
            "Iteration 3013: Loss = 0.5338, ||Grad|| = 0.3709, ||W|| = 0.5260\n",
            "Iteration 3014: Loss = 0.5337, ||Grad|| = 0.3706, ||W|| = 0.5258\n",
            "Iteration 3015: Loss = 0.5336, ||Grad|| = 0.3702, ||W|| = 0.5255\n",
            "Iteration 3016: Loss = 0.5335, ||Grad|| = 0.3698, ||W|| = 0.5253\n",
            "Iteration 3017: Loss = 0.5334, ||Grad|| = 0.3695, ||W|| = 0.5251\n",
            "Iteration 3018: Loss = 0.5333, ||Grad|| = 0.3691, ||W|| = 0.5249\n",
            "Iteration 3019: Loss = 0.5332, ||Grad|| = 0.3687, ||W|| = 0.5247\n",
            "Iteration 3020: Loss = 0.5331, ||Grad|| = 0.3684, ||W|| = 0.5245\n",
            "Iteration 3021: Loss = 0.5330, ||Grad|| = 0.3680, ||W|| = 0.5243\n",
            "Iteration 3022: Loss = 0.5329, ||Grad|| = 0.3677, ||W|| = 0.5241\n",
            "Iteration 3023: Loss = 0.5328, ||Grad|| = 0.3673, ||W|| = 0.5239\n",
            "Iteration 3024: Loss = 0.5326, ||Grad|| = 0.3669, ||W|| = 0.5237\n",
            "Iteration 3025: Loss = 0.5325, ||Grad|| = 0.3666, ||W|| = 0.5235\n",
            "Iteration 3026: Loss = 0.5324, ||Grad|| = 0.3662, ||W|| = 0.5233\n",
            "Iteration 3027: Loss = 0.5323, ||Grad|| = 0.3659, ||W|| = 0.5231\n",
            "Iteration 3028: Loss = 0.5322, ||Grad|| = 0.3655, ||W|| = 0.5229\n",
            "Iteration 3029: Loss = 0.5321, ||Grad|| = 0.3651, ||W|| = 0.5227\n",
            "Iteration 3030: Loss = 0.5320, ||Grad|| = 0.3648, ||W|| = 0.5225\n",
            "Iteration 3031: Loss = 0.5319, ||Grad|| = 0.3644, ||W|| = 0.5223\n",
            "Iteration 3032: Loss = 0.5318, ||Grad|| = 0.3641, ||W|| = 0.5221\n",
            "Iteration 3033: Loss = 0.5317, ||Grad|| = 0.3637, ||W|| = 0.5219\n",
            "Iteration 3034: Loss = 0.5316, ||Grad|| = 0.3634, ||W|| = 0.5217\n",
            "Iteration 3035: Loss = 0.5315, ||Grad|| = 0.3630, ||W|| = 0.5215\n",
            "Iteration 3036: Loss = 0.5314, ||Grad|| = 0.3626, ||W|| = 0.5213\n",
            "Iteration 3037: Loss = 0.5313, ||Grad|| = 0.3623, ||W|| = 0.5211\n",
            "Iteration 3038: Loss = 0.5312, ||Grad|| = 0.3619, ||W|| = 0.5209\n",
            "Iteration 3039: Loss = 0.5311, ||Grad|| = 0.3616, ||W|| = 0.5207\n",
            "Iteration 3040: Loss = 0.5310, ||Grad|| = 0.3612, ||W|| = 0.5205\n",
            "Iteration 3041: Loss = 0.5309, ||Grad|| = 0.3609, ||W|| = 0.5203\n",
            "Iteration 3042: Loss = 0.5308, ||Grad|| = 0.3605, ||W|| = 0.5201\n",
            "Iteration 3043: Loss = 0.5307, ||Grad|| = 0.3602, ||W|| = 0.5199\n",
            "Iteration 3044: Loss = 0.5306, ||Grad|| = 0.3598, ||W|| = 0.5197\n",
            "Iteration 3045: Loss = 0.5305, ||Grad|| = 0.3595, ||W|| = 0.5195\n",
            "Iteration 3046: Loss = 0.5304, ||Grad|| = 0.3591, ||W|| = 0.5193\n",
            "Iteration 3047: Loss = 0.5303, ||Grad|| = 0.3587, ||W|| = 0.5191\n",
            "Iteration 3048: Loss = 0.5302, ||Grad|| = 0.3584, ||W|| = 0.5189\n",
            "Iteration 3049: Loss = 0.5301, ||Grad|| = 0.3580, ||W|| = 0.5187\n",
            "Iteration 3050: Loss = 0.5300, ||Grad|| = 0.3577, ||W|| = 0.5185\n",
            "Iteration 3051: Loss = 0.5299, ||Grad|| = 0.3573, ||W|| = 0.5183\n",
            "Iteration 3052: Loss = 0.5298, ||Grad|| = 0.3570, ||W|| = 0.5181\n",
            "Iteration 3053: Loss = 0.5297, ||Grad|| = 0.3566, ||W|| = 0.5179\n",
            "Iteration 3054: Loss = 0.5296, ||Grad|| = 0.3563, ||W|| = 0.5177\n",
            "Iteration 3055: Loss = 0.5295, ||Grad|| = 0.3559, ||W|| = 0.5175\n",
            "Iteration 3056: Loss = 0.5294, ||Grad|| = 0.3556, ||W|| = 0.5173\n",
            "Iteration 3057: Loss = 0.5293, ||Grad|| = 0.3553, ||W|| = 0.5171\n",
            "Iteration 3058: Loss = 0.5292, ||Grad|| = 0.3549, ||W|| = 0.5169\n",
            "Iteration 3059: Loss = 0.5291, ||Grad|| = 0.3546, ||W|| = 0.5167\n",
            "Iteration 3060: Loss = 0.5290, ||Grad|| = 0.3542, ||W|| = 0.5165\n",
            "Iteration 3061: Loss = 0.5289, ||Grad|| = 0.3539, ||W|| = 0.5164\n",
            "Iteration 3062: Loss = 0.5288, ||Grad|| = 0.3535, ||W|| = 0.5162\n",
            "Iteration 3063: Loss = 0.5288, ||Grad|| = 0.3532, ||W|| = 0.5160\n",
            "Iteration 3064: Loss = 0.5287, ||Grad|| = 0.3528, ||W|| = 0.5158\n",
            "Iteration 3065: Loss = 0.5286, ||Grad|| = 0.3525, ||W|| = 0.5156\n",
            "Iteration 3066: Loss = 0.5285, ||Grad|| = 0.3521, ||W|| = 0.5154\n",
            "Iteration 3067: Loss = 0.5284, ||Grad|| = 0.3518, ||W|| = 0.5152\n",
            "Iteration 3068: Loss = 0.5283, ||Grad|| = 0.3514, ||W|| = 0.5150\n",
            "Iteration 3069: Loss = 0.5282, ||Grad|| = 0.3511, ||W|| = 0.5148\n",
            "Iteration 3070: Loss = 0.5281, ||Grad|| = 0.3508, ||W|| = 0.5146\n",
            "Iteration 3071: Loss = 0.5280, ||Grad|| = 0.3504, ||W|| = 0.5144\n",
            "Iteration 3072: Loss = 0.5279, ||Grad|| = 0.3501, ||W|| = 0.5143\n",
            "Iteration 3073: Loss = 0.5278, ||Grad|| = 0.3497, ||W|| = 0.5141\n",
            "Iteration 3074: Loss = 0.5277, ||Grad|| = 0.3494, ||W|| = 0.5139\n",
            "Iteration 3075: Loss = 0.5276, ||Grad|| = 0.3490, ||W|| = 0.5137\n",
            "Iteration 3076: Loss = 0.5275, ||Grad|| = 0.3487, ||W|| = 0.5135\n",
            "Iteration 3077: Loss = 0.5274, ||Grad|| = 0.3484, ||W|| = 0.5133\n",
            "Iteration 3078: Loss = 0.5273, ||Grad|| = 0.3480, ||W|| = 0.5131\n",
            "Iteration 3079: Loss = 0.5272, ||Grad|| = 0.3477, ||W|| = 0.5130\n",
            "Iteration 3080: Loss = 0.5272, ||Grad|| = 0.3473, ||W|| = 0.5128\n",
            "Iteration 3081: Loss = 0.5271, ||Grad|| = 0.3470, ||W|| = 0.5126\n",
            "Iteration 3082: Loss = 0.5270, ||Grad|| = 0.3467, ||W|| = 0.5124\n",
            "Iteration 3083: Loss = 0.5269, ||Grad|| = 0.3463, ||W|| = 0.5122\n",
            "Iteration 3084: Loss = 0.5268, ||Grad|| = 0.3460, ||W|| = 0.5120\n",
            "Iteration 3085: Loss = 0.5267, ||Grad|| = 0.3457, ||W|| = 0.5118\n",
            "Iteration 3086: Loss = 0.5266, ||Grad|| = 0.3453, ||W|| = 0.5117\n",
            "Iteration 3087: Loss = 0.5265, ||Grad|| = 0.3450, ||W|| = 0.5115\n",
            "Iteration 3088: Loss = 0.5264, ||Grad|| = 0.3446, ||W|| = 0.5113\n",
            "Iteration 3089: Loss = 0.5263, ||Grad|| = 0.3443, ||W|| = 0.5111\n",
            "Iteration 3090: Loss = 0.5262, ||Grad|| = 0.3440, ||W|| = 0.5109\n",
            "Iteration 3091: Loss = 0.5262, ||Grad|| = 0.3436, ||W|| = 0.5107\n",
            "Iteration 3092: Loss = 0.5261, ||Grad|| = 0.3433, ||W|| = 0.5106\n",
            "Iteration 3093: Loss = 0.5260, ||Grad|| = 0.3430, ||W|| = 0.5104\n",
            "Iteration 3094: Loss = 0.5259, ||Grad|| = 0.3426, ||W|| = 0.5102\n",
            "Iteration 3095: Loss = 0.5258, ||Grad|| = 0.3423, ||W|| = 0.5100\n",
            "Iteration 3096: Loss = 0.5257, ||Grad|| = 0.3420, ||W|| = 0.5098\n",
            "Iteration 3097: Loss = 0.5256, ||Grad|| = 0.3416, ||W|| = 0.5097\n",
            "Iteration 3098: Loss = 0.5255, ||Grad|| = 0.3413, ||W|| = 0.5095\n",
            "Iteration 3099: Loss = 0.5254, ||Grad|| = 0.3410, ||W|| = 0.5093\n",
            "Iteration 3100: Loss = 0.5253, ||Grad|| = 0.3406, ||W|| = 0.5091\n",
            "Iteration 3101: Loss = 0.5253, ||Grad|| = 0.3403, ||W|| = 0.5089\n",
            "Iteration 3102: Loss = 0.5252, ||Grad|| = 0.3400, ||W|| = 0.5088\n",
            "Iteration 3103: Loss = 0.5251, ||Grad|| = 0.3396, ||W|| = 0.5086\n",
            "Iteration 3104: Loss = 0.5250, ||Grad|| = 0.3393, ||W|| = 0.5084\n",
            "Iteration 3105: Loss = 0.5249, ||Grad|| = 0.3390, ||W|| = 0.5082\n",
            "Iteration 3106: Loss = 0.5248, ||Grad|| = 0.3386, ||W|| = 0.5080\n",
            "Iteration 3107: Loss = 0.5247, ||Grad|| = 0.3383, ||W|| = 0.5079\n",
            "Iteration 3108: Loss = 0.5246, ||Grad|| = 0.3380, ||W|| = 0.5077\n",
            "Iteration 3109: Loss = 0.5246, ||Grad|| = 0.3377, ||W|| = 0.5075\n",
            "Iteration 3110: Loss = 0.5245, ||Grad|| = 0.3373, ||W|| = 0.5073\n",
            "Iteration 3111: Loss = 0.5244, ||Grad|| = 0.3370, ||W|| = 0.5072\n",
            "Iteration 3112: Loss = 0.5243, ||Grad|| = 0.3367, ||W|| = 0.5070\n",
            "Iteration 3113: Loss = 0.5242, ||Grad|| = 0.3363, ||W|| = 0.5068\n",
            "Iteration 3114: Loss = 0.5241, ||Grad|| = 0.3360, ||W|| = 0.5066\n",
            "Iteration 3115: Loss = 0.5240, ||Grad|| = 0.3357, ||W|| = 0.5065\n",
            "Iteration 3116: Loss = 0.5240, ||Grad|| = 0.3354, ||W|| = 0.5063\n",
            "Iteration 3117: Loss = 0.5239, ||Grad|| = 0.3350, ||W|| = 0.5061\n",
            "Iteration 3118: Loss = 0.5238, ||Grad|| = 0.3347, ||W|| = 0.5059\n",
            "Iteration 3119: Loss = 0.5237, ||Grad|| = 0.3344, ||W|| = 0.5058\n",
            "Iteration 3120: Loss = 0.5236, ||Grad|| = 0.3341, ||W|| = 0.5056\n",
            "Iteration 3121: Loss = 0.5235, ||Grad|| = 0.3337, ||W|| = 0.5054\n",
            "Iteration 3122: Loss = 0.5235, ||Grad|| = 0.3334, ||W|| = 0.5053\n",
            "Iteration 3123: Loss = 0.5234, ||Grad|| = 0.3331, ||W|| = 0.5051\n",
            "Iteration 3124: Loss = 0.5233, ||Grad|| = 0.3328, ||W|| = 0.5049\n",
            "Iteration 3125: Loss = 0.5232, ||Grad|| = 0.3324, ||W|| = 0.5047\n",
            "Iteration 3126: Loss = 0.5231, ||Grad|| = 0.3321, ||W|| = 0.5046\n",
            "Iteration 3127: Loss = 0.5230, ||Grad|| = 0.3318, ||W|| = 0.5044\n",
            "Iteration 3128: Loss = 0.5230, ||Grad|| = 0.3315, ||W|| = 0.5042\n",
            "Iteration 3129: Loss = 0.5229, ||Grad|| = 0.3312, ||W|| = 0.5041\n",
            "Iteration 3130: Loss = 0.5228, ||Grad|| = 0.3308, ||W|| = 0.5039\n",
            "Iteration 3131: Loss = 0.5227, ||Grad|| = 0.3305, ||W|| = 0.5037\n",
            "Iteration 3132: Loss = 0.5226, ||Grad|| = 0.3302, ||W|| = 0.5035\n",
            "Iteration 3133: Loss = 0.5225, ||Grad|| = 0.3299, ||W|| = 0.5034\n",
            "Iteration 3134: Loss = 0.5225, ||Grad|| = 0.3295, ||W|| = 0.5032\n",
            "Iteration 3135: Loss = 0.5224, ||Grad|| = 0.3292, ||W|| = 0.5030\n",
            "Iteration 3136: Loss = 0.5223, ||Grad|| = 0.3289, ||W|| = 0.5029\n",
            "Iteration 3137: Loss = 0.5222, ||Grad|| = 0.3286, ||W|| = 0.5027\n",
            "Iteration 3138: Loss = 0.5221, ||Grad|| = 0.3283, ||W|| = 0.5025\n",
            "Iteration 3139: Loss = 0.5220, ||Grad|| = 0.3280, ||W|| = 0.5024\n",
            "Iteration 3140: Loss = 0.5220, ||Grad|| = 0.3276, ||W|| = 0.5022\n",
            "Iteration 3141: Loss = 0.5219, ||Grad|| = 0.3273, ||W|| = 0.5020\n",
            "Iteration 3142: Loss = 0.5218, ||Grad|| = 0.3270, ||W|| = 0.5019\n",
            "Iteration 3143: Loss = 0.5217, ||Grad|| = 0.3267, ||W|| = 0.5017\n",
            "Iteration 3144: Loss = 0.5216, ||Grad|| = 0.3264, ||W|| = 0.5015\n",
            "Iteration 3145: Loss = 0.5216, ||Grad|| = 0.3260, ||W|| = 0.5014\n",
            "Iteration 3146: Loss = 0.5215, ||Grad|| = 0.3257, ||W|| = 0.5012\n",
            "Iteration 3147: Loss = 0.5214, ||Grad|| = 0.3254, ||W|| = 0.5010\n",
            "Iteration 3148: Loss = 0.5213, ||Grad|| = 0.3251, ||W|| = 0.5009\n",
            "Iteration 3149: Loss = 0.5212, ||Grad|| = 0.3248, ||W|| = 0.5007\n",
            "Iteration 3150: Loss = 0.5212, ||Grad|| = 0.3245, ||W|| = 0.5005\n",
            "Iteration 3151: Loss = 0.5211, ||Grad|| = 0.3242, ||W|| = 0.5004\n",
            "Iteration 3152: Loss = 0.5210, ||Grad|| = 0.3238, ||W|| = 0.5002\n",
            "Iteration 3153: Loss = 0.5209, ||Grad|| = 0.3235, ||W|| = 0.5001\n",
            "Iteration 3154: Loss = 0.5208, ||Grad|| = 0.3232, ||W|| = 0.4999\n",
            "Iteration 3155: Loss = 0.5208, ||Grad|| = 0.3229, ||W|| = 0.4997\n",
            "Iteration 3156: Loss = 0.5207, ||Grad|| = 0.3226, ||W|| = 0.4996\n",
            "Iteration 3157: Loss = 0.5206, ||Grad|| = 0.3223, ||W|| = 0.4994\n",
            "Iteration 3158: Loss = 0.5205, ||Grad|| = 0.3220, ||W|| = 0.4992\n",
            "Iteration 3159: Loss = 0.5205, ||Grad|| = 0.3217, ||W|| = 0.4991\n",
            "Iteration 3160: Loss = 0.5204, ||Grad|| = 0.3213, ||W|| = 0.4989\n",
            "Iteration 3161: Loss = 0.5203, ||Grad|| = 0.3210, ||W|| = 0.4988\n",
            "Iteration 3162: Loss = 0.5202, ||Grad|| = 0.3207, ||W|| = 0.4986\n",
            "Iteration 3163: Loss = 0.5201, ||Grad|| = 0.3204, ||W|| = 0.4984\n",
            "Iteration 3164: Loss = 0.5201, ||Grad|| = 0.3201, ||W|| = 0.4983\n",
            "Iteration 3165: Loss = 0.5200, ||Grad|| = 0.3198, ||W|| = 0.4981\n",
            "Iteration 3166: Loss = 0.5199, ||Grad|| = 0.3195, ||W|| = 0.4980\n",
            "Iteration 3167: Loss = 0.5198, ||Grad|| = 0.3192, ||W|| = 0.4978\n",
            "Iteration 3168: Loss = 0.5198, ||Grad|| = 0.3189, ||W|| = 0.4976\n",
            "Iteration 3169: Loss = 0.5197, ||Grad|| = 0.3186, ||W|| = 0.4975\n",
            "Iteration 3170: Loss = 0.5196, ||Grad|| = 0.3182, ||W|| = 0.4973\n",
            "Iteration 3171: Loss = 0.5195, ||Grad|| = 0.3179, ||W|| = 0.4972\n",
            "Iteration 3172: Loss = 0.5195, ||Grad|| = 0.3176, ||W|| = 0.4970\n",
            "Iteration 3173: Loss = 0.5194, ||Grad|| = 0.3173, ||W|| = 0.4969\n",
            "Iteration 3174: Loss = 0.5193, ||Grad|| = 0.3170, ||W|| = 0.4967\n",
            "Iteration 3175: Loss = 0.5192, ||Grad|| = 0.3167, ||W|| = 0.4965\n",
            "Iteration 3176: Loss = 0.5192, ||Grad|| = 0.3164, ||W|| = 0.4964\n",
            "Iteration 3177: Loss = 0.5191, ||Grad|| = 0.3161, ||W|| = 0.4962\n",
            "Iteration 3178: Loss = 0.5190, ||Grad|| = 0.3158, ||W|| = 0.4961\n",
            "Iteration 3179: Loss = 0.5189, ||Grad|| = 0.3155, ||W|| = 0.4959\n",
            "Iteration 3180: Loss = 0.5189, ||Grad|| = 0.3152, ||W|| = 0.4958\n",
            "Iteration 3181: Loss = 0.5188, ||Grad|| = 0.3149, ||W|| = 0.4956\n",
            "Iteration 3182: Loss = 0.5187, ||Grad|| = 0.3146, ||W|| = 0.4954\n",
            "Iteration 3183: Loss = 0.5186, ||Grad|| = 0.3143, ||W|| = 0.4953\n",
            "Iteration 3184: Loss = 0.5186, ||Grad|| = 0.3140, ||W|| = 0.4951\n",
            "Iteration 3185: Loss = 0.5185, ||Grad|| = 0.3137, ||W|| = 0.4950\n",
            "Iteration 3186: Loss = 0.5184, ||Grad|| = 0.3134, ||W|| = 0.4948\n",
            "Iteration 3187: Loss = 0.5183, ||Grad|| = 0.3131, ||W|| = 0.4947\n",
            "Iteration 3188: Loss = 0.5183, ||Grad|| = 0.3128, ||W|| = 0.4945\n",
            "Iteration 3189: Loss = 0.5182, ||Grad|| = 0.3125, ||W|| = 0.4944\n",
            "Iteration 3190: Loss = 0.5181, ||Grad|| = 0.3122, ||W|| = 0.4942\n",
            "Iteration 3191: Loss = 0.5181, ||Grad|| = 0.3119, ||W|| = 0.4941\n",
            "Iteration 3192: Loss = 0.5180, ||Grad|| = 0.3116, ||W|| = 0.4939\n",
            "Iteration 3193: Loss = 0.5179, ||Grad|| = 0.3113, ||W|| = 0.4938\n",
            "Iteration 3194: Loss = 0.5178, ||Grad|| = 0.3110, ||W|| = 0.4936\n",
            "Iteration 3195: Loss = 0.5178, ||Grad|| = 0.3107, ||W|| = 0.4935\n",
            "Iteration 3196: Loss = 0.5177, ||Grad|| = 0.3104, ||W|| = 0.4933\n",
            "Iteration 3197: Loss = 0.5176, ||Grad|| = 0.3101, ||W|| = 0.4932\n",
            "Iteration 3198: Loss = 0.5176, ||Grad|| = 0.3098, ||W|| = 0.4930\n",
            "Iteration 3199: Loss = 0.5175, ||Grad|| = 0.3095, ||W|| = 0.4929\n",
            "Iteration 3200: Loss = 0.5174, ||Grad|| = 0.3092, ||W|| = 0.4927\n",
            "Iteration 3201: Loss = 0.5173, ||Grad|| = 0.3089, ||W|| = 0.4926\n",
            "Iteration 3202: Loss = 0.5173, ||Grad|| = 0.3086, ||W|| = 0.4924\n",
            "Iteration 3203: Loss = 0.5172, ||Grad|| = 0.3083, ||W|| = 0.4923\n",
            "Iteration 3204: Loss = 0.5171, ||Grad|| = 0.3080, ||W|| = 0.4921\n",
            "Iteration 3205: Loss = 0.5171, ||Grad|| = 0.3077, ||W|| = 0.4920\n",
            "Iteration 3206: Loss = 0.5170, ||Grad|| = 0.3074, ||W|| = 0.4918\n",
            "Iteration 3207: Loss = 0.5169, ||Grad|| = 0.3071, ||W|| = 0.4917\n",
            "Iteration 3208: Loss = 0.5168, ||Grad|| = 0.3068, ||W|| = 0.4915\n",
            "Iteration 3209: Loss = 0.5168, ||Grad|| = 0.3065, ||W|| = 0.4914\n",
            "Iteration 3210: Loss = 0.5167, ||Grad|| = 0.3062, ||W|| = 0.4912\n",
            "Iteration 3211: Loss = 0.5166, ||Grad|| = 0.3059, ||W|| = 0.4911\n",
            "Iteration 3212: Loss = 0.5166, ||Grad|| = 0.3056, ||W|| = 0.4909\n",
            "Iteration 3213: Loss = 0.5165, ||Grad|| = 0.3053, ||W|| = 0.4908\n",
            "Iteration 3214: Loss = 0.5164, ||Grad|| = 0.3050, ||W|| = 0.4906\n",
            "Iteration 3215: Loss = 0.5164, ||Grad|| = 0.3047, ||W|| = 0.4905\n",
            "Iteration 3216: Loss = 0.5163, ||Grad|| = 0.3044, ||W|| = 0.4903\n",
            "Iteration 3217: Loss = 0.5162, ||Grad|| = 0.3041, ||W|| = 0.4902\n",
            "Iteration 3218: Loss = 0.5162, ||Grad|| = 0.3038, ||W|| = 0.4901\n",
            "Iteration 3219: Loss = 0.5161, ||Grad|| = 0.3036, ||W|| = 0.4899\n",
            "Iteration 3220: Loss = 0.5160, ||Grad|| = 0.3033, ||W|| = 0.4898\n",
            "Iteration 3221: Loss = 0.5160, ||Grad|| = 0.3030, ||W|| = 0.4896\n",
            "Iteration 3222: Loss = 0.5159, ||Grad|| = 0.3027, ||W|| = 0.4895\n",
            "Iteration 3223: Loss = 0.5158, ||Grad|| = 0.3024, ||W|| = 0.4893\n",
            "Iteration 3224: Loss = 0.5157, ||Grad|| = 0.3021, ||W|| = 0.4892\n",
            "Iteration 3225: Loss = 0.5157, ||Grad|| = 0.3018, ||W|| = 0.4890\n",
            "Iteration 3226: Loss = 0.5156, ||Grad|| = 0.3015, ||W|| = 0.4889\n",
            "Iteration 3227: Loss = 0.5155, ||Grad|| = 0.3012, ||W|| = 0.4888\n",
            "Iteration 3228: Loss = 0.5155, ||Grad|| = 0.3009, ||W|| = 0.4886\n",
            "Iteration 3229: Loss = 0.5154, ||Grad|| = 0.3006, ||W|| = 0.4885\n",
            "Iteration 3230: Loss = 0.5153, ||Grad|| = 0.3004, ||W|| = 0.4883\n",
            "Iteration 3231: Loss = 0.5153, ||Grad|| = 0.3001, ||W|| = 0.4882\n",
            "Iteration 3232: Loss = 0.5152, ||Grad|| = 0.2998, ||W|| = 0.4880\n",
            "Iteration 3233: Loss = 0.5151, ||Grad|| = 0.2995, ||W|| = 0.4879\n",
            "Iteration 3234: Loss = 0.5151, ||Grad|| = 0.2992, ||W|| = 0.4878\n",
            "Iteration 3235: Loss = 0.5150, ||Grad|| = 0.2989, ||W|| = 0.4876\n",
            "Iteration 3236: Loss = 0.5150, ||Grad|| = 0.2986, ||W|| = 0.4875\n",
            "Iteration 3237: Loss = 0.5149, ||Grad|| = 0.2983, ||W|| = 0.4873\n",
            "Iteration 3238: Loss = 0.5148, ||Grad|| = 0.2981, ||W|| = 0.4872\n",
            "Iteration 3239: Loss = 0.5148, ||Grad|| = 0.2978, ||W|| = 0.4871\n",
            "Iteration 3240: Loss = 0.5147, ||Grad|| = 0.2975, ||W|| = 0.4869\n",
            "Iteration 3241: Loss = 0.5146, ||Grad|| = 0.2972, ||W|| = 0.4868\n",
            "Iteration 3242: Loss = 0.5146, ||Grad|| = 0.2969, ||W|| = 0.4866\n",
            "Iteration 3243: Loss = 0.5145, ||Grad|| = 0.2966, ||W|| = 0.4865\n",
            "Iteration 3244: Loss = 0.5144, ||Grad|| = 0.2964, ||W|| = 0.4864\n",
            "Iteration 3245: Loss = 0.5144, ||Grad|| = 0.2961, ||W|| = 0.4862\n",
            "Iteration 3246: Loss = 0.5143, ||Grad|| = 0.2958, ||W|| = 0.4861\n",
            "Iteration 3247: Loss = 0.5142, ||Grad|| = 0.2955, ||W|| = 0.4860\n",
            "Iteration 3248: Loss = 0.5142, ||Grad|| = 0.2952, ||W|| = 0.4858\n",
            "Iteration 3249: Loss = 0.5141, ||Grad|| = 0.2949, ||W|| = 0.4857\n",
            "Iteration 3250: Loss = 0.5140, ||Grad|| = 0.2947, ||W|| = 0.4855\n",
            "Iteration 3251: Loss = 0.5140, ||Grad|| = 0.2944, ||W|| = 0.4854\n",
            "Iteration 3252: Loss = 0.5139, ||Grad|| = 0.2941, ||W|| = 0.4853\n",
            "Iteration 3253: Loss = 0.5139, ||Grad|| = 0.2938, ||W|| = 0.4851\n",
            "Iteration 3254: Loss = 0.5138, ||Grad|| = 0.2935, ||W|| = 0.4850\n",
            "Iteration 3255: Loss = 0.5137, ||Grad|| = 0.2932, ||W|| = 0.4849\n",
            "Iteration 3256: Loss = 0.5137, ||Grad|| = 0.2930, ||W|| = 0.4847\n",
            "Iteration 3257: Loss = 0.5136, ||Grad|| = 0.2927, ||W|| = 0.4846\n",
            "Iteration 3258: Loss = 0.5135, ||Grad|| = 0.2924, ||W|| = 0.4845\n",
            "Iteration 3259: Loss = 0.5135, ||Grad|| = 0.2921, ||W|| = 0.4843\n",
            "Iteration 3260: Loss = 0.5134, ||Grad|| = 0.2918, ||W|| = 0.4842\n",
            "Iteration 3261: Loss = 0.5134, ||Grad|| = 0.2916, ||W|| = 0.4841\n",
            "Iteration 3262: Loss = 0.5133, ||Grad|| = 0.2913, ||W|| = 0.4839\n",
            "Iteration 3263: Loss = 0.5132, ||Grad|| = 0.2910, ||W|| = 0.4838\n",
            "Iteration 3264: Loss = 0.5132, ||Grad|| = 0.2907, ||W|| = 0.4837\n",
            "Iteration 3265: Loss = 0.5131, ||Grad|| = 0.2905, ||W|| = 0.4835\n",
            "Iteration 3266: Loss = 0.5130, ||Grad|| = 0.2902, ||W|| = 0.4834\n",
            "Iteration 3267: Loss = 0.5130, ||Grad|| = 0.2899, ||W|| = 0.4833\n",
            "Iteration 3268: Loss = 0.5129, ||Grad|| = 0.2896, ||W|| = 0.4831\n",
            "Iteration 3269: Loss = 0.5129, ||Grad|| = 0.2893, ||W|| = 0.4830\n",
            "Iteration 3270: Loss = 0.5128, ||Grad|| = 0.2891, ||W|| = 0.4829\n",
            "Iteration 3271: Loss = 0.5127, ||Grad|| = 0.2888, ||W|| = 0.4827\n",
            "Iteration 3272: Loss = 0.5127, ||Grad|| = 0.2885, ||W|| = 0.4826\n",
            "Iteration 3273: Loss = 0.5126, ||Grad|| = 0.2882, ||W|| = 0.4825\n",
            "Iteration 3274: Loss = 0.5126, ||Grad|| = 0.2880, ||W|| = 0.4823\n",
            "Iteration 3275: Loss = 0.5125, ||Grad|| = 0.2877, ||W|| = 0.4822\n",
            "Iteration 3276: Loss = 0.5124, ||Grad|| = 0.2874, ||W|| = 0.4821\n",
            "Iteration 3277: Loss = 0.5124, ||Grad|| = 0.2871, ||W|| = 0.4819\n",
            "Iteration 3278: Loss = 0.5123, ||Grad|| = 0.2869, ||W|| = 0.4818\n",
            "Iteration 3279: Loss = 0.5123, ||Grad|| = 0.2866, ||W|| = 0.4817\n",
            "Iteration 3280: Loss = 0.5122, ||Grad|| = 0.2863, ||W|| = 0.4816\n",
            "Iteration 3281: Loss = 0.5121, ||Grad|| = 0.2860, ||W|| = 0.4814\n",
            "Iteration 3282: Loss = 0.5121, ||Grad|| = 0.2858, ||W|| = 0.4813\n",
            "Iteration 3283: Loss = 0.5120, ||Grad|| = 0.2855, ||W|| = 0.4812\n",
            "Iteration 3284: Loss = 0.5120, ||Grad|| = 0.2852, ||W|| = 0.4810\n",
            "Iteration 3285: Loss = 0.5119, ||Grad|| = 0.2850, ||W|| = 0.4809\n",
            "Iteration 3286: Loss = 0.5118, ||Grad|| = 0.2847, ||W|| = 0.4808\n",
            "Iteration 3287: Loss = 0.5118, ||Grad|| = 0.2844, ||W|| = 0.4806\n",
            "Iteration 3288: Loss = 0.5117, ||Grad|| = 0.2841, ||W|| = 0.4805\n",
            "Iteration 3289: Loss = 0.5117, ||Grad|| = 0.2839, ||W|| = 0.4804\n",
            "Iteration 3290: Loss = 0.5116, ||Grad|| = 0.2836, ||W|| = 0.4803\n",
            "Iteration 3291: Loss = 0.5115, ||Grad|| = 0.2833, ||W|| = 0.4801\n",
            "Iteration 3292: Loss = 0.5115, ||Grad|| = 0.2831, ||W|| = 0.4800\n",
            "Iteration 3293: Loss = 0.5114, ||Grad|| = 0.2828, ||W|| = 0.4799\n",
            "Iteration 3294: Loss = 0.5114, ||Grad|| = 0.2825, ||W|| = 0.4798\n",
            "Iteration 3295: Loss = 0.5113, ||Grad|| = 0.2822, ||W|| = 0.4796\n",
            "Iteration 3296: Loss = 0.5113, ||Grad|| = 0.2820, ||W|| = 0.4795\n",
            "Iteration 3297: Loss = 0.5112, ||Grad|| = 0.2817, ||W|| = 0.4794\n",
            "Iteration 3298: Loss = 0.5111, ||Grad|| = 0.2814, ||W|| = 0.4793\n",
            "Iteration 3299: Loss = 0.5111, ||Grad|| = 0.2812, ||W|| = 0.4791\n",
            "Iteration 3300: Loss = 0.5110, ||Grad|| = 0.2809, ||W|| = 0.4790\n",
            "Iteration 3301: Loss = 0.5110, ||Grad|| = 0.2806, ||W|| = 0.4789\n",
            "Iteration 3302: Loss = 0.5109, ||Grad|| = 0.2804, ||W|| = 0.4788\n",
            "Iteration 3303: Loss = 0.5109, ||Grad|| = 0.2801, ||W|| = 0.4786\n",
            "Iteration 3304: Loss = 0.5108, ||Grad|| = 0.2798, ||W|| = 0.4785\n",
            "Iteration 3305: Loss = 0.5107, ||Grad|| = 0.2796, ||W|| = 0.4784\n",
            "Iteration 3306: Loss = 0.5107, ||Grad|| = 0.2793, ||W|| = 0.4783\n",
            "Iteration 3307: Loss = 0.5106, ||Grad|| = 0.2790, ||W|| = 0.4781\n",
            "Iteration 3308: Loss = 0.5106, ||Grad|| = 0.2788, ||W|| = 0.4780\n",
            "Iteration 3309: Loss = 0.5105, ||Grad|| = 0.2785, ||W|| = 0.4779\n",
            "Iteration 3310: Loss = 0.5105, ||Grad|| = 0.2782, ||W|| = 0.4778\n",
            "Iteration 3311: Loss = 0.5104, ||Grad|| = 0.2780, ||W|| = 0.4776\n",
            "Iteration 3312: Loss = 0.5103, ||Grad|| = 0.2777, ||W|| = 0.4775\n",
            "Iteration 3313: Loss = 0.5103, ||Grad|| = 0.2775, ||W|| = 0.4774\n",
            "Iteration 3314: Loss = 0.5102, ||Grad|| = 0.2772, ||W|| = 0.4773\n",
            "Iteration 3315: Loss = 0.5102, ||Grad|| = 0.2769, ||W|| = 0.4772\n",
            "Iteration 3316: Loss = 0.5101, ||Grad|| = 0.2767, ||W|| = 0.4770\n",
            "Iteration 3317: Loss = 0.5101, ||Grad|| = 0.2764, ||W|| = 0.4769\n",
            "Iteration 3318: Loss = 0.5100, ||Grad|| = 0.2761, ||W|| = 0.4768\n",
            "Iteration 3319: Loss = 0.5100, ||Grad|| = 0.2759, ||W|| = 0.4767\n",
            "Iteration 3320: Loss = 0.5099, ||Grad|| = 0.2756, ||W|| = 0.4766\n",
            "Iteration 3321: Loss = 0.5098, ||Grad|| = 0.2754, ||W|| = 0.4764\n",
            "Iteration 3322: Loss = 0.5098, ||Grad|| = 0.2751, ||W|| = 0.4763\n",
            "Iteration 3323: Loss = 0.5097, ||Grad|| = 0.2748, ||W|| = 0.4762\n",
            "Iteration 3324: Loss = 0.5097, ||Grad|| = 0.2746, ||W|| = 0.4761\n",
            "Iteration 3325: Loss = 0.5096, ||Grad|| = 0.2743, ||W|| = 0.4760\n",
            "Iteration 3326: Loss = 0.5096, ||Grad|| = 0.2740, ||W|| = 0.4758\n",
            "Iteration 3327: Loss = 0.5095, ||Grad|| = 0.2738, ||W|| = 0.4757\n",
            "Iteration 3328: Loss = 0.5095, ||Grad|| = 0.2735, ||W|| = 0.4756\n",
            "Iteration 3329: Loss = 0.5094, ||Grad|| = 0.2733, ||W|| = 0.4755\n",
            "Iteration 3330: Loss = 0.5094, ||Grad|| = 0.2730, ||W|| = 0.4754\n",
            "Iteration 3331: Loss = 0.5093, ||Grad|| = 0.2728, ||W|| = 0.4752\n",
            "Iteration 3332: Loss = 0.5093, ||Grad|| = 0.2725, ||W|| = 0.4751\n",
            "Iteration 3333: Loss = 0.5092, ||Grad|| = 0.2722, ||W|| = 0.4750\n",
            "Iteration 3334: Loss = 0.5091, ||Grad|| = 0.2720, ||W|| = 0.4749\n",
            "Iteration 3335: Loss = 0.5091, ||Grad|| = 0.2717, ||W|| = 0.4748\n",
            "Iteration 3336: Loss = 0.5090, ||Grad|| = 0.2715, ||W|| = 0.4747\n",
            "Iteration 3337: Loss = 0.5090, ||Grad|| = 0.2712, ||W|| = 0.4745\n",
            "Iteration 3338: Loss = 0.5089, ||Grad|| = 0.2709, ||W|| = 0.4744\n",
            "Iteration 3339: Loss = 0.5089, ||Grad|| = 0.2707, ||W|| = 0.4743\n",
            "Iteration 3340: Loss = 0.5088, ||Grad|| = 0.2704, ||W|| = 0.4742\n",
            "Iteration 3341: Loss = 0.5088, ||Grad|| = 0.2702, ||W|| = 0.4741\n",
            "Iteration 3342: Loss = 0.5087, ||Grad|| = 0.2699, ||W|| = 0.4740\n",
            "Iteration 3343: Loss = 0.5087, ||Grad|| = 0.2697, ||W|| = 0.4738\n",
            "Iteration 3344: Loss = 0.5086, ||Grad|| = 0.2694, ||W|| = 0.4737\n",
            "Iteration 3345: Loss = 0.5086, ||Grad|| = 0.2692, ||W|| = 0.4736\n",
            "Iteration 3346: Loss = 0.5085, ||Grad|| = 0.2689, ||W|| = 0.4735\n",
            "Iteration 3347: Loss = 0.5085, ||Grad|| = 0.2686, ||W|| = 0.4734\n",
            "Iteration 3348: Loss = 0.5084, ||Grad|| = 0.2684, ||W|| = 0.4733\n",
            "Iteration 3349: Loss = 0.5084, ||Grad|| = 0.2681, ||W|| = 0.4732\n",
            "Iteration 3350: Loss = 0.5083, ||Grad|| = 0.2679, ||W|| = 0.4730\n",
            "Iteration 3351: Loss = 0.5083, ||Grad|| = 0.2676, ||W|| = 0.4729\n",
            "Iteration 3352: Loss = 0.5082, ||Grad|| = 0.2674, ||W|| = 0.4728\n",
            "Iteration 3353: Loss = 0.5082, ||Grad|| = 0.2671, ||W|| = 0.4727\n",
            "Iteration 3354: Loss = 0.5081, ||Grad|| = 0.2669, ||W|| = 0.4726\n",
            "Iteration 3355: Loss = 0.5081, ||Grad|| = 0.2666, ||W|| = 0.4725\n",
            "Iteration 3356: Loss = 0.5080, ||Grad|| = 0.2664, ||W|| = 0.4724\n",
            "Iteration 3357: Loss = 0.5080, ||Grad|| = 0.2661, ||W|| = 0.4723\n",
            "Iteration 3358: Loss = 0.5079, ||Grad|| = 0.2659, ||W|| = 0.4721\n",
            "Iteration 3359: Loss = 0.5078, ||Grad|| = 0.2656, ||W|| = 0.4720\n",
            "Iteration 3360: Loss = 0.5078, ||Grad|| = 0.2654, ||W|| = 0.4719\n",
            "Iteration 3361: Loss = 0.5077, ||Grad|| = 0.2651, ||W|| = 0.4718\n",
            "Iteration 3362: Loss = 0.5077, ||Grad|| = 0.2649, ||W|| = 0.4717\n",
            "Iteration 3363: Loss = 0.5076, ||Grad|| = 0.2646, ||W|| = 0.4716\n",
            "Iteration 3364: Loss = 0.5076, ||Grad|| = 0.2644, ||W|| = 0.4715\n",
            "Iteration 3365: Loss = 0.5075, ||Grad|| = 0.2641, ||W|| = 0.4714\n",
            "Iteration 3366: Loss = 0.5075, ||Grad|| = 0.2639, ||W|| = 0.4712\n",
            "Iteration 3367: Loss = 0.5074, ||Grad|| = 0.2636, ||W|| = 0.4711\n",
            "Iteration 3368: Loss = 0.5074, ||Grad|| = 0.2634, ||W|| = 0.4710\n",
            "Iteration 3369: Loss = 0.5074, ||Grad|| = 0.2631, ||W|| = 0.4709\n",
            "Iteration 3370: Loss = 0.5073, ||Grad|| = 0.2629, ||W|| = 0.4708\n",
            "Iteration 3371: Loss = 0.5073, ||Grad|| = 0.2626, ||W|| = 0.4707\n",
            "Iteration 3372: Loss = 0.5072, ||Grad|| = 0.2624, ||W|| = 0.4706\n",
            "Iteration 3373: Loss = 0.5072, ||Grad|| = 0.2621, ||W|| = 0.4705\n",
            "Iteration 3374: Loss = 0.5071, ||Grad|| = 0.2619, ||W|| = 0.4704\n",
            "Iteration 3375: Loss = 0.5071, ||Grad|| = 0.2616, ||W|| = 0.4703\n",
            "Iteration 3376: Loss = 0.5070, ||Grad|| = 0.2614, ||W|| = 0.4702\n",
            "Iteration 3377: Loss = 0.5070, ||Grad|| = 0.2611, ||W|| = 0.4700\n",
            "Iteration 3378: Loss = 0.5069, ||Grad|| = 0.2609, ||W|| = 0.4699\n",
            "Iteration 3379: Loss = 0.5069, ||Grad|| = 0.2606, ||W|| = 0.4698\n",
            "Iteration 3380: Loss = 0.5068, ||Grad|| = 0.2604, ||W|| = 0.4697\n",
            "Iteration 3381: Loss = 0.5068, ||Grad|| = 0.2602, ||W|| = 0.4696\n",
            "Iteration 3382: Loss = 0.5067, ||Grad|| = 0.2599, ||W|| = 0.4695\n",
            "Iteration 3383: Loss = 0.5067, ||Grad|| = 0.2597, ||W|| = 0.4694\n",
            "Iteration 3384: Loss = 0.5066, ||Grad|| = 0.2594, ||W|| = 0.4693\n",
            "Iteration 3385: Loss = 0.5066, ||Grad|| = 0.2592, ||W|| = 0.4692\n",
            "Iteration 3386: Loss = 0.5065, ||Grad|| = 0.2589, ||W|| = 0.4691\n",
            "Iteration 3387: Loss = 0.5065, ||Grad|| = 0.2587, ||W|| = 0.4690\n",
            "Iteration 3388: Loss = 0.5064, ||Grad|| = 0.2584, ||W|| = 0.4689\n",
            "Iteration 3389: Loss = 0.5064, ||Grad|| = 0.2582, ||W|| = 0.4688\n",
            "Iteration 3390: Loss = 0.5063, ||Grad|| = 0.2580, ||W|| = 0.4687\n",
            "Iteration 3391: Loss = 0.5063, ||Grad|| = 0.2577, ||W|| = 0.4685\n",
            "Iteration 3392: Loss = 0.5062, ||Grad|| = 0.2575, ||W|| = 0.4684\n",
            "Iteration 3393: Loss = 0.5062, ||Grad|| = 0.2572, ||W|| = 0.4683\n",
            "Iteration 3394: Loss = 0.5061, ||Grad|| = 0.2570, ||W|| = 0.4682\n",
            "Iteration 3395: Loss = 0.5061, ||Grad|| = 0.2568, ||W|| = 0.4681\n",
            "Iteration 3396: Loss = 0.5061, ||Grad|| = 0.2565, ||W|| = 0.4680\n",
            "Iteration 3397: Loss = 0.5060, ||Grad|| = 0.2563, ||W|| = 0.4679\n",
            "Iteration 3398: Loss = 0.5060, ||Grad|| = 0.2560, ||W|| = 0.4678\n",
            "Iteration 3399: Loss = 0.5059, ||Grad|| = 0.2558, ||W|| = 0.4677\n",
            "Iteration 3400: Loss = 0.5059, ||Grad|| = 0.2555, ||W|| = 0.4676\n",
            "Iteration 3401: Loss = 0.5058, ||Grad|| = 0.2553, ||W|| = 0.4675\n",
            "Iteration 3402: Loss = 0.5058, ||Grad|| = 0.2551, ||W|| = 0.4674\n",
            "Iteration 3403: Loss = 0.5057, ||Grad|| = 0.2548, ||W|| = 0.4673\n",
            "Iteration 3404: Loss = 0.5057, ||Grad|| = 0.2546, ||W|| = 0.4672\n",
            "Iteration 3405: Loss = 0.5056, ||Grad|| = 0.2543, ||W|| = 0.4671\n",
            "Iteration 3406: Loss = 0.5056, ||Grad|| = 0.2541, ||W|| = 0.4670\n",
            "Iteration 3407: Loss = 0.5055, ||Grad|| = 0.2539, ||W|| = 0.4669\n",
            "Iteration 3408: Loss = 0.5055, ||Grad|| = 0.2536, ||W|| = 0.4668\n",
            "Iteration 3409: Loss = 0.5055, ||Grad|| = 0.2534, ||W|| = 0.4667\n",
            "Iteration 3410: Loss = 0.5054, ||Grad|| = 0.2532, ||W|| = 0.4666\n",
            "Iteration 3411: Loss = 0.5054, ||Grad|| = 0.2529, ||W|| = 0.4665\n",
            "Iteration 3412: Loss = 0.5053, ||Grad|| = 0.2527, ||W|| = 0.4664\n",
            "Iteration 3413: Loss = 0.5053, ||Grad|| = 0.2524, ||W|| = 0.4663\n",
            "Iteration 3414: Loss = 0.5052, ||Grad|| = 0.2522, ||W|| = 0.4662\n",
            "Iteration 3415: Loss = 0.5052, ||Grad|| = 0.2520, ||W|| = 0.4661\n",
            "Iteration 3416: Loss = 0.5051, ||Grad|| = 0.2517, ||W|| = 0.4660\n",
            "Iteration 3417: Loss = 0.5051, ||Grad|| = 0.2515, ||W|| = 0.4659\n",
            "Iteration 3418: Loss = 0.5051, ||Grad|| = 0.2513, ||W|| = 0.4658\n",
            "Iteration 3419: Loss = 0.5050, ||Grad|| = 0.2510, ||W|| = 0.4657\n",
            "Iteration 3420: Loss = 0.5050, ||Grad|| = 0.2508, ||W|| = 0.4656\n",
            "Iteration 3421: Loss = 0.5049, ||Grad|| = 0.2506, ||W|| = 0.4655\n",
            "Iteration 3422: Loss = 0.5049, ||Grad|| = 0.2503, ||W|| = 0.4654\n",
            "Iteration 3423: Loss = 0.5048, ||Grad|| = 0.2501, ||W|| = 0.4653\n",
            "Iteration 3424: Loss = 0.5048, ||Grad|| = 0.2499, ||W|| = 0.4652\n",
            "Iteration 3425: Loss = 0.5047, ||Grad|| = 0.2496, ||W|| = 0.4651\n",
            "Iteration 3426: Loss = 0.5047, ||Grad|| = 0.2494, ||W|| = 0.4650\n",
            "Iteration 3427: Loss = 0.5047, ||Grad|| = 0.2492, ||W|| = 0.4649\n",
            "Iteration 3428: Loss = 0.5046, ||Grad|| = 0.2489, ||W|| = 0.4648\n",
            "Iteration 3429: Loss = 0.5046, ||Grad|| = 0.2487, ||W|| = 0.4647\n",
            "Iteration 3430: Loss = 0.5045, ||Grad|| = 0.2485, ||W|| = 0.4646\n",
            "Iteration 3431: Loss = 0.5045, ||Grad|| = 0.2482, ||W|| = 0.4645\n",
            "Iteration 3432: Loss = 0.5044, ||Grad|| = 0.2480, ||W|| = 0.4644\n",
            "Iteration 3433: Loss = 0.5044, ||Grad|| = 0.2478, ||W|| = 0.4643\n",
            "Iteration 3434: Loss = 0.5044, ||Grad|| = 0.2475, ||W|| = 0.4642\n",
            "Iteration 3435: Loss = 0.5043, ||Grad|| = 0.2473, ||W|| = 0.4641\n",
            "Iteration 3436: Loss = 0.5043, ||Grad|| = 0.2471, ||W|| = 0.4640\n",
            "Iteration 3437: Loss = 0.5042, ||Grad|| = 0.2468, ||W|| = 0.4639\n",
            "Iteration 3438: Loss = 0.5042, ||Grad|| = 0.2466, ||W|| = 0.4638\n",
            "Iteration 3439: Loss = 0.5041, ||Grad|| = 0.2464, ||W|| = 0.4637\n",
            "Iteration 3440: Loss = 0.5041, ||Grad|| = 0.2461, ||W|| = 0.4636\n",
            "Iteration 3441: Loss = 0.5041, ||Grad|| = 0.2459, ||W|| = 0.4635\n",
            "Iteration 3442: Loss = 0.5040, ||Grad|| = 0.2457, ||W|| = 0.4634\n",
            "Iteration 3443: Loss = 0.5040, ||Grad|| = 0.2455, ||W|| = 0.4633\n",
            "Iteration 3444: Loss = 0.5039, ||Grad|| = 0.2452, ||W|| = 0.4632\n",
            "Iteration 3445: Loss = 0.5039, ||Grad|| = 0.2450, ||W|| = 0.4631\n",
            "Iteration 3446: Loss = 0.5038, ||Grad|| = 0.2448, ||W|| = 0.4630\n",
            "Iteration 3447: Loss = 0.5038, ||Grad|| = 0.2445, ||W|| = 0.4629\n",
            "Iteration 3448: Loss = 0.5038, ||Grad|| = 0.2443, ||W|| = 0.4628\n",
            "Iteration 3449: Loss = 0.5037, ||Grad|| = 0.2441, ||W|| = 0.4628\n",
            "Iteration 3450: Loss = 0.5037, ||Grad|| = 0.2439, ||W|| = 0.4627\n",
            "Iteration 3451: Loss = 0.5036, ||Grad|| = 0.2436, ||W|| = 0.4626\n",
            "Iteration 3452: Loss = 0.5036, ||Grad|| = 0.2434, ||W|| = 0.4625\n",
            "Iteration 3453: Loss = 0.5036, ||Grad|| = 0.2432, ||W|| = 0.4624\n",
            "Iteration 3454: Loss = 0.5035, ||Grad|| = 0.2429, ||W|| = 0.4623\n",
            "Iteration 3455: Loss = 0.5035, ||Grad|| = 0.2427, ||W|| = 0.4622\n",
            "Iteration 3456: Loss = 0.5034, ||Grad|| = 0.2425, ||W|| = 0.4621\n",
            "Iteration 3457: Loss = 0.5034, ||Grad|| = 0.2423, ||W|| = 0.4620\n",
            "Iteration 3458: Loss = 0.5034, ||Grad|| = 0.2420, ||W|| = 0.4619\n",
            "Iteration 3459: Loss = 0.5033, ||Grad|| = 0.2418, ||W|| = 0.4618\n",
            "Iteration 3460: Loss = 0.5033, ||Grad|| = 0.2416, ||W|| = 0.4617\n",
            "Iteration 3461: Loss = 0.5032, ||Grad|| = 0.2414, ||W|| = 0.4616\n",
            "Iteration 3462: Loss = 0.5032, ||Grad|| = 0.2411, ||W|| = 0.4615\n",
            "Iteration 3463: Loss = 0.5031, ||Grad|| = 0.2409, ||W|| = 0.4614\n",
            "Iteration 3464: Loss = 0.5031, ||Grad|| = 0.2407, ||W|| = 0.4614\n",
            "Iteration 3465: Loss = 0.5031, ||Grad|| = 0.2405, ||W|| = 0.4613\n",
            "Iteration 3466: Loss = 0.5030, ||Grad|| = 0.2402, ||W|| = 0.4612\n",
            "Iteration 3467: Loss = 0.5030, ||Grad|| = 0.2400, ||W|| = 0.4611\n",
            "Iteration 3468: Loss = 0.5029, ||Grad|| = 0.2398, ||W|| = 0.4610\n",
            "Iteration 3469: Loss = 0.5029, ||Grad|| = 0.2396, ||W|| = 0.4609\n",
            "Iteration 3470: Loss = 0.5029, ||Grad|| = 0.2394, ||W|| = 0.4608\n",
            "Iteration 3471: Loss = 0.5028, ||Grad|| = 0.2391, ||W|| = 0.4607\n",
            "Iteration 3472: Loss = 0.5028, ||Grad|| = 0.2389, ||W|| = 0.4606\n",
            "Iteration 3473: Loss = 0.5027, ||Grad|| = 0.2387, ||W|| = 0.4605\n",
            "Iteration 3474: Loss = 0.5027, ||Grad|| = 0.2385, ||W|| = 0.4604\n",
            "Iteration 3475: Loss = 0.5027, ||Grad|| = 0.2382, ||W|| = 0.4603\n",
            "Iteration 3476: Loss = 0.5026, ||Grad|| = 0.2380, ||W|| = 0.4603\n",
            "Iteration 3477: Loss = 0.5026, ||Grad|| = 0.2378, ||W|| = 0.4602\n",
            "Iteration 3478: Loss = 0.5026, ||Grad|| = 0.2376, ||W|| = 0.4601\n",
            "Iteration 3479: Loss = 0.5025, ||Grad|| = 0.2374, ||W|| = 0.4600\n",
            "Iteration 3480: Loss = 0.5025, ||Grad|| = 0.2371, ||W|| = 0.4599\n",
            "Iteration 3481: Loss = 0.5024, ||Grad|| = 0.2369, ||W|| = 0.4598\n",
            "Iteration 3482: Loss = 0.5024, ||Grad|| = 0.2367, ||W|| = 0.4597\n",
            "Iteration 3483: Loss = 0.5024, ||Grad|| = 0.2365, ||W|| = 0.4596\n",
            "Iteration 3484: Loss = 0.5023, ||Grad|| = 0.2363, ||W|| = 0.4595\n",
            "Iteration 3485: Loss = 0.5023, ||Grad|| = 0.2360, ||W|| = 0.4595\n",
            "Iteration 3486: Loss = 0.5022, ||Grad|| = 0.2358, ||W|| = 0.4594\n",
            "Iteration 3487: Loss = 0.5022, ||Grad|| = 0.2356, ||W|| = 0.4593\n",
            "Iteration 3488: Loss = 0.5022, ||Grad|| = 0.2354, ||W|| = 0.4592\n",
            "Iteration 3489: Loss = 0.5021, ||Grad|| = 0.2352, ||W|| = 0.4591\n",
            "Iteration 3490: Loss = 0.5021, ||Grad|| = 0.2349, ||W|| = 0.4590\n",
            "Iteration 3491: Loss = 0.5021, ||Grad|| = 0.2347, ||W|| = 0.4589\n",
            "Iteration 3492: Loss = 0.5020, ||Grad|| = 0.2345, ||W|| = 0.4588\n",
            "Iteration 3493: Loss = 0.5020, ||Grad|| = 0.2343, ||W|| = 0.4588\n",
            "Iteration 3494: Loss = 0.5019, ||Grad|| = 0.2341, ||W|| = 0.4587\n",
            "Iteration 3495: Loss = 0.5019, ||Grad|| = 0.2339, ||W|| = 0.4586\n",
            "Iteration 3496: Loss = 0.5019, ||Grad|| = 0.2336, ||W|| = 0.4585\n",
            "Iteration 3497: Loss = 0.5018, ||Grad|| = 0.2334, ||W|| = 0.4584\n",
            "Iteration 3498: Loss = 0.5018, ||Grad|| = 0.2332, ||W|| = 0.4583\n",
            "Iteration 3499: Loss = 0.5017, ||Grad|| = 0.2330, ||W|| = 0.4582\n",
            "Iteration 3500: Loss = 0.5017, ||Grad|| = 0.2328, ||W|| = 0.4581\n",
            "Iteration 3501: Loss = 0.5017, ||Grad|| = 0.2326, ||W|| = 0.4581\n",
            "Iteration 3502: Loss = 0.5016, ||Grad|| = 0.2323, ||W|| = 0.4580\n",
            "Iteration 3503: Loss = 0.5016, ||Grad|| = 0.2321, ||W|| = 0.4579\n",
            "Iteration 3504: Loss = 0.5016, ||Grad|| = 0.2319, ||W|| = 0.4578\n",
            "Iteration 3505: Loss = 0.5015, ||Grad|| = 0.2317, ||W|| = 0.4577\n",
            "Iteration 3506: Loss = 0.5015, ||Grad|| = 0.2315, ||W|| = 0.4576\n",
            "Iteration 3507: Loss = 0.5015, ||Grad|| = 0.2313, ||W|| = 0.4576\n",
            "Iteration 3508: Loss = 0.5014, ||Grad|| = 0.2311, ||W|| = 0.4575\n",
            "Iteration 3509: Loss = 0.5014, ||Grad|| = 0.2308, ||W|| = 0.4574\n",
            "Iteration 3510: Loss = 0.5013, ||Grad|| = 0.2306, ||W|| = 0.4573\n",
            "Iteration 3511: Loss = 0.5013, ||Grad|| = 0.2304, ||W|| = 0.4572\n",
            "Iteration 3512: Loss = 0.5013, ||Grad|| = 0.2302, ||W|| = 0.4571\n",
            "Iteration 3513: Loss = 0.5012, ||Grad|| = 0.2300, ||W|| = 0.4570\n",
            "Iteration 3514: Loss = 0.5012, ||Grad|| = 0.2298, ||W|| = 0.4570\n",
            "Iteration 3515: Loss = 0.5012, ||Grad|| = 0.2296, ||W|| = 0.4569\n",
            "Iteration 3516: Loss = 0.5011, ||Grad|| = 0.2294, ||W|| = 0.4568\n",
            "Iteration 3517: Loss = 0.5011, ||Grad|| = 0.2291, ||W|| = 0.4567\n",
            "Iteration 3518: Loss = 0.5011, ||Grad|| = 0.2289, ||W|| = 0.4566\n",
            "Iteration 3519: Loss = 0.5010, ||Grad|| = 0.2287, ||W|| = 0.4565\n",
            "Iteration 3520: Loss = 0.5010, ||Grad|| = 0.2285, ||W|| = 0.4565\n",
            "Iteration 3521: Loss = 0.5009, ||Grad|| = 0.2283, ||W|| = 0.4564\n",
            "Iteration 3522: Loss = 0.5009, ||Grad|| = 0.2281, ||W|| = 0.4563\n",
            "Iteration 3523: Loss = 0.5009, ||Grad|| = 0.2279, ||W|| = 0.4562\n",
            "Iteration 3524: Loss = 0.5008, ||Grad|| = 0.2277, ||W|| = 0.4561\n",
            "Iteration 3525: Loss = 0.5008, ||Grad|| = 0.2275, ||W|| = 0.4560\n",
            "Iteration 3526: Loss = 0.5008, ||Grad|| = 0.2272, ||W|| = 0.4560\n",
            "Iteration 3527: Loss = 0.5007, ||Grad|| = 0.2270, ||W|| = 0.4559\n",
            "Iteration 3528: Loss = 0.5007, ||Grad|| = 0.2268, ||W|| = 0.4558\n",
            "Iteration 3529: Loss = 0.5007, ||Grad|| = 0.2266, ||W|| = 0.4557\n",
            "Iteration 3530: Loss = 0.5006, ||Grad|| = 0.2264, ||W|| = 0.4556\n",
            "Iteration 3531: Loss = 0.5006, ||Grad|| = 0.2262, ||W|| = 0.4556\n",
            "Iteration 3532: Loss = 0.5006, ||Grad|| = 0.2260, ||W|| = 0.4555\n",
            "Iteration 3533: Loss = 0.5005, ||Grad|| = 0.2258, ||W|| = 0.4554\n",
            "Iteration 3534: Loss = 0.5005, ||Grad|| = 0.2256, ||W|| = 0.4553\n",
            "Iteration 3535: Loss = 0.5005, ||Grad|| = 0.2254, ||W|| = 0.4552\n",
            "Iteration 3536: Loss = 0.5004, ||Grad|| = 0.2252, ||W|| = 0.4552\n",
            "Iteration 3537: Loss = 0.5004, ||Grad|| = 0.2249, ||W|| = 0.4551\n",
            "Iteration 3538: Loss = 0.5003, ||Grad|| = 0.2247, ||W|| = 0.4550\n",
            "Iteration 3539: Loss = 0.5003, ||Grad|| = 0.2245, ||W|| = 0.4549\n",
            "Iteration 3540: Loss = 0.5003, ||Grad|| = 0.2243, ||W|| = 0.4548\n",
            "Iteration 3541: Loss = 0.5002, ||Grad|| = 0.2241, ||W|| = 0.4548\n",
            "Iteration 3542: Loss = 0.5002, ||Grad|| = 0.2239, ||W|| = 0.4547\n",
            "Iteration 3543: Loss = 0.5002, ||Grad|| = 0.2237, ||W|| = 0.4546\n",
            "Iteration 3544: Loss = 0.5001, ||Grad|| = 0.2235, ||W|| = 0.4545\n",
            "Iteration 3545: Loss = 0.5001, ||Grad|| = 0.2233, ||W|| = 0.4544\n",
            "Iteration 3546: Loss = 0.5001, ||Grad|| = 0.2231, ||W|| = 0.4544\n",
            "Iteration 3547: Loss = 0.5000, ||Grad|| = 0.2229, ||W|| = 0.4543\n",
            "Iteration 3548: Loss = 0.5000, ||Grad|| = 0.2227, ||W|| = 0.4542\n",
            "Iteration 3549: Loss = 0.5000, ||Grad|| = 0.2225, ||W|| = 0.4541\n",
            "Iteration 3550: Loss = 0.4999, ||Grad|| = 0.2223, ||W|| = 0.4540\n",
            "Iteration 3551: Loss = 0.4999, ||Grad|| = 0.2221, ||W|| = 0.4540\n",
            "Iteration 3552: Loss = 0.4999, ||Grad|| = 0.2219, ||W|| = 0.4539\n",
            "Iteration 3553: Loss = 0.4998, ||Grad|| = 0.2217, ||W|| = 0.4538\n",
            "Iteration 3554: Loss = 0.4998, ||Grad|| = 0.2215, ||W|| = 0.4537\n",
            "Iteration 3555: Loss = 0.4998, ||Grad|| = 0.2213, ||W|| = 0.4537\n",
            "Iteration 3556: Loss = 0.4997, ||Grad|| = 0.2210, ||W|| = 0.4536\n",
            "Iteration 3557: Loss = 0.4997, ||Grad|| = 0.2208, ||W|| = 0.4535\n",
            "Iteration 3558: Loss = 0.4997, ||Grad|| = 0.2206, ||W|| = 0.4534\n",
            "Iteration 3559: Loss = 0.4996, ||Grad|| = 0.2204, ||W|| = 0.4533\n",
            "Iteration 3560: Loss = 0.4996, ||Grad|| = 0.2202, ||W|| = 0.4533\n",
            "Iteration 3561: Loss = 0.4996, ||Grad|| = 0.2200, ||W|| = 0.4532\n",
            "Iteration 3562: Loss = 0.4995, ||Grad|| = 0.2198, ||W|| = 0.4531\n",
            "Iteration 3563: Loss = 0.4995, ||Grad|| = 0.2196, ||W|| = 0.4530\n",
            "Iteration 3564: Loss = 0.4995, ||Grad|| = 0.2194, ||W|| = 0.4530\n",
            "Iteration 3565: Loss = 0.4994, ||Grad|| = 0.2192, ||W|| = 0.4529\n",
            "Iteration 3566: Loss = 0.4994, ||Grad|| = 0.2190, ||W|| = 0.4528\n",
            "Iteration 3567: Loss = 0.4994, ||Grad|| = 0.2188, ||W|| = 0.4527\n",
            "Iteration 3568: Loss = 0.4993, ||Grad|| = 0.2186, ||W|| = 0.4527\n",
            "Iteration 3569: Loss = 0.4993, ||Grad|| = 0.2184, ||W|| = 0.4526\n",
            "Iteration 3570: Loss = 0.4993, ||Grad|| = 0.2182, ||W|| = 0.4525\n",
            "Iteration 3571: Loss = 0.4993, ||Grad|| = 0.2180, ||W|| = 0.4524\n",
            "Iteration 3572: Loss = 0.4992, ||Grad|| = 0.2178, ||W|| = 0.4524\n",
            "Iteration 3573: Loss = 0.4992, ||Grad|| = 0.2176, ||W|| = 0.4523\n",
            "Iteration 3574: Loss = 0.4992, ||Grad|| = 0.2174, ||W|| = 0.4522\n",
            "Iteration 3575: Loss = 0.4991, ||Grad|| = 0.2172, ||W|| = 0.4521\n",
            "Iteration 3576: Loss = 0.4991, ||Grad|| = 0.2170, ||W|| = 0.4521\n",
            "Iteration 3577: Loss = 0.4991, ||Grad|| = 0.2168, ||W|| = 0.4520\n",
            "Iteration 3578: Loss = 0.4990, ||Grad|| = 0.2166, ||W|| = 0.4519\n",
            "Iteration 3579: Loss = 0.4990, ||Grad|| = 0.2164, ||W|| = 0.4518\n",
            "Iteration 3580: Loss = 0.4990, ||Grad|| = 0.2162, ||W|| = 0.4518\n",
            "Iteration 3581: Loss = 0.4989, ||Grad|| = 0.2160, ||W|| = 0.4517\n",
            "Iteration 3582: Loss = 0.4989, ||Grad|| = 0.2158, ||W|| = 0.4516\n",
            "Iteration 3583: Loss = 0.4989, ||Grad|| = 0.2156, ||W|| = 0.4515\n",
            "Iteration 3584: Loss = 0.4988, ||Grad|| = 0.2154, ||W|| = 0.4515\n",
            "Iteration 3585: Loss = 0.4988, ||Grad|| = 0.2152, ||W|| = 0.4514\n",
            "Iteration 3586: Loss = 0.4988, ||Grad|| = 0.2151, ||W|| = 0.4513\n",
            "Iteration 3587: Loss = 0.4987, ||Grad|| = 0.2149, ||W|| = 0.4513\n",
            "Iteration 3588: Loss = 0.4987, ||Grad|| = 0.2147, ||W|| = 0.4512\n",
            "Iteration 3589: Loss = 0.4987, ||Grad|| = 0.2145, ||W|| = 0.4511\n",
            "Iteration 3590: Loss = 0.4987, ||Grad|| = 0.2143, ||W|| = 0.4510\n",
            "Iteration 3591: Loss = 0.4986, ||Grad|| = 0.2141, ||W|| = 0.4510\n",
            "Iteration 3592: Loss = 0.4986, ||Grad|| = 0.2139, ||W|| = 0.4509\n",
            "Iteration 3593: Loss = 0.4986, ||Grad|| = 0.2137, ||W|| = 0.4508\n",
            "Iteration 3594: Loss = 0.4985, ||Grad|| = 0.2135, ||W|| = 0.4507\n",
            "Iteration 3595: Loss = 0.4985, ||Grad|| = 0.2133, ||W|| = 0.4507\n",
            "Iteration 3596: Loss = 0.4985, ||Grad|| = 0.2131, ||W|| = 0.4506\n",
            "Iteration 3597: Loss = 0.4984, ||Grad|| = 0.2129, ||W|| = 0.4505\n",
            "Iteration 3598: Loss = 0.4984, ||Grad|| = 0.2127, ||W|| = 0.4505\n",
            "Iteration 3599: Loss = 0.4984, ||Grad|| = 0.2125, ||W|| = 0.4504\n",
            "Iteration 3600: Loss = 0.4983, ||Grad|| = 0.2123, ||W|| = 0.4503\n",
            "Iteration 3601: Loss = 0.4983, ||Grad|| = 0.2121, ||W|| = 0.4502\n",
            "Iteration 3602: Loss = 0.4983, ||Grad|| = 0.2119, ||W|| = 0.4502\n",
            "Iteration 3603: Loss = 0.4983, ||Grad|| = 0.2117, ||W|| = 0.4501\n",
            "Iteration 3604: Loss = 0.4982, ||Grad|| = 0.2115, ||W|| = 0.4500\n",
            "Iteration 3605: Loss = 0.4982, ||Grad|| = 0.2114, ||W|| = 0.4500\n",
            "Iteration 3606: Loss = 0.4982, ||Grad|| = 0.2112, ||W|| = 0.4499\n",
            "Iteration 3607: Loss = 0.4981, ||Grad|| = 0.2110, ||W|| = 0.4498\n",
            "Iteration 3608: Loss = 0.4981, ||Grad|| = 0.2108, ||W|| = 0.4497\n",
            "Iteration 3609: Loss = 0.4981, ||Grad|| = 0.2106, ||W|| = 0.4497\n",
            "Iteration 3610: Loss = 0.4980, ||Grad|| = 0.2104, ||W|| = 0.4496\n",
            "Iteration 3611: Loss = 0.4980, ||Grad|| = 0.2102, ||W|| = 0.4495\n",
            "Iteration 3612: Loss = 0.4980, ||Grad|| = 0.2100, ||W|| = 0.4495\n",
            "Iteration 3613: Loss = 0.4980, ||Grad|| = 0.2098, ||W|| = 0.4494\n",
            "Iteration 3614: Loss = 0.4979, ||Grad|| = 0.2096, ||W|| = 0.4493\n",
            "Iteration 3615: Loss = 0.4979, ||Grad|| = 0.2094, ||W|| = 0.4493\n",
            "Iteration 3616: Loss = 0.4979, ||Grad|| = 0.2092, ||W|| = 0.4492\n",
            "Iteration 3617: Loss = 0.4978, ||Grad|| = 0.2091, ||W|| = 0.4491\n",
            "Iteration 3618: Loss = 0.4978, ||Grad|| = 0.2089, ||W|| = 0.4491\n",
            "Iteration 3619: Loss = 0.4978, ||Grad|| = 0.2087, ||W|| = 0.4490\n",
            "Iteration 3620: Loss = 0.4978, ||Grad|| = 0.2085, ||W|| = 0.4489\n",
            "Iteration 3621: Loss = 0.4977, ||Grad|| = 0.2083, ||W|| = 0.4489\n",
            "Iteration 3622: Loss = 0.4977, ||Grad|| = 0.2081, ||W|| = 0.4488\n",
            "Iteration 3623: Loss = 0.4977, ||Grad|| = 0.2079, ||W|| = 0.4487\n",
            "Iteration 3624: Loss = 0.4976, ||Grad|| = 0.2077, ||W|| = 0.4486\n",
            "Iteration 3625: Loss = 0.4976, ||Grad|| = 0.2075, ||W|| = 0.4486\n",
            "Iteration 3626: Loss = 0.4976, ||Grad|| = 0.2073, ||W|| = 0.4485\n",
            "Iteration 3627: Loss = 0.4976, ||Grad|| = 0.2072, ||W|| = 0.4484\n",
            "Iteration 3628: Loss = 0.4975, ||Grad|| = 0.2070, ||W|| = 0.4484\n",
            "Iteration 3629: Loss = 0.4975, ||Grad|| = 0.2068, ||W|| = 0.4483\n",
            "Iteration 3630: Loss = 0.4975, ||Grad|| = 0.2066, ||W|| = 0.4482\n",
            "Iteration 3631: Loss = 0.4974, ||Grad|| = 0.2064, ||W|| = 0.4482\n",
            "Iteration 3632: Loss = 0.4974, ||Grad|| = 0.2062, ||W|| = 0.4481\n",
            "Iteration 3633: Loss = 0.4974, ||Grad|| = 0.2060, ||W|| = 0.4480\n",
            "Iteration 3634: Loss = 0.4974, ||Grad|| = 0.2058, ||W|| = 0.4480\n",
            "Iteration 3635: Loss = 0.4973, ||Grad|| = 0.2057, ||W|| = 0.4479\n",
            "Iteration 3636: Loss = 0.4973, ||Grad|| = 0.2055, ||W|| = 0.4478\n",
            "Iteration 3637: Loss = 0.4973, ||Grad|| = 0.2053, ||W|| = 0.4478\n",
            "Iteration 3638: Loss = 0.4972, ||Grad|| = 0.2051, ||W|| = 0.4477\n",
            "Iteration 3639: Loss = 0.4972, ||Grad|| = 0.2049, ||W|| = 0.4476\n",
            "Iteration 3640: Loss = 0.4972, ||Grad|| = 0.2047, ||W|| = 0.4476\n",
            "Iteration 3641: Loss = 0.4972, ||Grad|| = 0.2045, ||W|| = 0.4475\n",
            "Iteration 3642: Loss = 0.4971, ||Grad|| = 0.2044, ||W|| = 0.4474\n",
            "Iteration 3643: Loss = 0.4971, ||Grad|| = 0.2042, ||W|| = 0.4474\n",
            "Iteration 3644: Loss = 0.4971, ||Grad|| = 0.2040, ||W|| = 0.4473\n",
            "Iteration 3645: Loss = 0.4971, ||Grad|| = 0.2038, ||W|| = 0.4472\n",
            "Iteration 3646: Loss = 0.4970, ||Grad|| = 0.2036, ||W|| = 0.4472\n",
            "Iteration 3647: Loss = 0.4970, ||Grad|| = 0.2034, ||W|| = 0.4471\n",
            "Iteration 3648: Loss = 0.4970, ||Grad|| = 0.2033, ||W|| = 0.4471\n",
            "Iteration 3649: Loss = 0.4969, ||Grad|| = 0.2031, ||W|| = 0.4470\n",
            "Iteration 3650: Loss = 0.4969, ||Grad|| = 0.2029, ||W|| = 0.4469\n",
            "Iteration 3651: Loss = 0.4969, ||Grad|| = 0.2027, ||W|| = 0.4469\n",
            "Iteration 3652: Loss = 0.4969, ||Grad|| = 0.2025, ||W|| = 0.4468\n",
            "Iteration 3653: Loss = 0.4968, ||Grad|| = 0.2023, ||W|| = 0.4467\n",
            "Iteration 3654: Loss = 0.4968, ||Grad|| = 0.2022, ||W|| = 0.4467\n",
            "Iteration 3655: Loss = 0.4968, ||Grad|| = 0.2020, ||W|| = 0.4466\n",
            "Iteration 3656: Loss = 0.4968, ||Grad|| = 0.2018, ||W|| = 0.4465\n",
            "Iteration 3657: Loss = 0.4967, ||Grad|| = 0.2016, ||W|| = 0.4465\n",
            "Iteration 3658: Loss = 0.4967, ||Grad|| = 0.2014, ||W|| = 0.4464\n",
            "Iteration 3659: Loss = 0.4967, ||Grad|| = 0.2012, ||W|| = 0.4463\n",
            "Iteration 3660: Loss = 0.4966, ||Grad|| = 0.2011, ||W|| = 0.4463\n",
            "Iteration 3661: Loss = 0.4966, ||Grad|| = 0.2009, ||W|| = 0.4462\n",
            "Iteration 3662: Loss = 0.4966, ||Grad|| = 0.2007, ||W|| = 0.4462\n",
            "Iteration 3663: Loss = 0.4966, ||Grad|| = 0.2005, ||W|| = 0.4461\n",
            "Iteration 3664: Loss = 0.4965, ||Grad|| = 0.2003, ||W|| = 0.4460\n",
            "Iteration 3665: Loss = 0.4965, ||Grad|| = 0.2002, ||W|| = 0.4460\n",
            "Iteration 3666: Loss = 0.4965, ||Grad|| = 0.2000, ||W|| = 0.4459\n",
            "Iteration 3667: Loss = 0.4965, ||Grad|| = 0.1998, ||W|| = 0.4458\n",
            "Iteration 3668: Loss = 0.4964, ||Grad|| = 0.1996, ||W|| = 0.4458\n",
            "Iteration 3669: Loss = 0.4964, ||Grad|| = 0.1994, ||W|| = 0.4457\n",
            "Iteration 3670: Loss = 0.4964, ||Grad|| = 0.1992, ||W|| = 0.4457\n",
            "Iteration 3671: Loss = 0.4964, ||Grad|| = 0.1991, ||W|| = 0.4456\n",
            "Iteration 3672: Loss = 0.4963, ||Grad|| = 0.1989, ||W|| = 0.4455\n",
            "Iteration 3673: Loss = 0.4963, ||Grad|| = 0.1987, ||W|| = 0.4455\n",
            "Iteration 3674: Loss = 0.4963, ||Grad|| = 0.1985, ||W|| = 0.4454\n",
            "Iteration 3675: Loss = 0.4963, ||Grad|| = 0.1984, ||W|| = 0.4453\n",
            "Iteration 3676: Loss = 0.4962, ||Grad|| = 0.1982, ||W|| = 0.4453\n",
            "Iteration 3677: Loss = 0.4962, ||Grad|| = 0.1980, ||W|| = 0.4452\n",
            "Iteration 3678: Loss = 0.4962, ||Grad|| = 0.1978, ||W|| = 0.4452\n",
            "Iteration 3679: Loss = 0.4961, ||Grad|| = 0.1976, ||W|| = 0.4451\n",
            "Iteration 3680: Loss = 0.4961, ||Grad|| = 0.1975, ||W|| = 0.4450\n",
            "Iteration 3681: Loss = 0.4961, ||Grad|| = 0.1973, ||W|| = 0.4450\n",
            "Iteration 3682: Loss = 0.4961, ||Grad|| = 0.1971, ||W|| = 0.4449\n",
            "Iteration 3683: Loss = 0.4960, ||Grad|| = 0.1969, ||W|| = 0.4449\n",
            "Iteration 3684: Loss = 0.4960, ||Grad|| = 0.1968, ||W|| = 0.4448\n",
            "Iteration 3685: Loss = 0.4960, ||Grad|| = 0.1966, ||W|| = 0.4447\n",
            "Iteration 3686: Loss = 0.4960, ||Grad|| = 0.1964, ||W|| = 0.4447\n",
            "Iteration 3687: Loss = 0.4959, ||Grad|| = 0.1962, ||W|| = 0.4446\n",
            "Iteration 3688: Loss = 0.4959, ||Grad|| = 0.1960, ||W|| = 0.4445\n",
            "Iteration 3689: Loss = 0.4959, ||Grad|| = 0.1959, ||W|| = 0.4445\n",
            "Iteration 3690: Loss = 0.4959, ||Grad|| = 0.1957, ||W|| = 0.4444\n",
            "Iteration 3691: Loss = 0.4958, ||Grad|| = 0.1955, ||W|| = 0.4444\n",
            "Iteration 3692: Loss = 0.4958, ||Grad|| = 0.1953, ||W|| = 0.4443\n",
            "Iteration 3693: Loss = 0.4958, ||Grad|| = 0.1952, ||W|| = 0.4443\n",
            "Iteration 3694: Loss = 0.4958, ||Grad|| = 0.1950, ||W|| = 0.4442\n",
            "Iteration 3695: Loss = 0.4957, ||Grad|| = 0.1948, ||W|| = 0.4441\n",
            "Iteration 3696: Loss = 0.4957, ||Grad|| = 0.1946, ||W|| = 0.4441\n",
            "Iteration 3697: Loss = 0.4957, ||Grad|| = 0.1945, ||W|| = 0.4440\n",
            "Iteration 3698: Loss = 0.4957, ||Grad|| = 0.1943, ||W|| = 0.4440\n",
            "Iteration 3699: Loss = 0.4956, ||Grad|| = 0.1941, ||W|| = 0.4439\n",
            "Iteration 3700: Loss = 0.4956, ||Grad|| = 0.1939, ||W|| = 0.4438\n",
            "Iteration 3701: Loss = 0.4956, ||Grad|| = 0.1938, ||W|| = 0.4438\n",
            "Iteration 3702: Loss = 0.4956, ||Grad|| = 0.1936, ||W|| = 0.4437\n",
            "Iteration 3703: Loss = 0.4955, ||Grad|| = 0.1934, ||W|| = 0.4437\n",
            "Iteration 3704: Loss = 0.4955, ||Grad|| = 0.1932, ||W|| = 0.4436\n",
            "Iteration 3705: Loss = 0.4955, ||Grad|| = 0.1931, ||W|| = 0.4435\n",
            "Iteration 3706: Loss = 0.4955, ||Grad|| = 0.1929, ||W|| = 0.4435\n",
            "Iteration 3707: Loss = 0.4955, ||Grad|| = 0.1927, ||W|| = 0.4434\n",
            "Iteration 3708: Loss = 0.4954, ||Grad|| = 0.1926, ||W|| = 0.4434\n",
            "Iteration 3709: Loss = 0.4954, ||Grad|| = 0.1924, ||W|| = 0.4433\n",
            "Iteration 3710: Loss = 0.4954, ||Grad|| = 0.1922, ||W|| = 0.4433\n",
            "Iteration 3711: Loss = 0.4954, ||Grad|| = 0.1920, ||W|| = 0.4432\n",
            "Iteration 3712: Loss = 0.4953, ||Grad|| = 0.1919, ||W|| = 0.4431\n",
            "Iteration 3713: Loss = 0.4953, ||Grad|| = 0.1917, ||W|| = 0.4431\n",
            "Iteration 3714: Loss = 0.4953, ||Grad|| = 0.1915, ||W|| = 0.4430\n",
            "Iteration 3715: Loss = 0.4953, ||Grad|| = 0.1914, ||W|| = 0.4430\n",
            "Iteration 3716: Loss = 0.4952, ||Grad|| = 0.1912, ||W|| = 0.4429\n",
            "Iteration 3717: Loss = 0.4952, ||Grad|| = 0.1910, ||W|| = 0.4429\n",
            "Iteration 3718: Loss = 0.4952, ||Grad|| = 0.1908, ||W|| = 0.4428\n",
            "Iteration 3719: Loss = 0.4952, ||Grad|| = 0.1907, ||W|| = 0.4427\n",
            "Iteration 3720: Loss = 0.4951, ||Grad|| = 0.1905, ||W|| = 0.4427\n",
            "Iteration 3721: Loss = 0.4951, ||Grad|| = 0.1903, ||W|| = 0.4426\n",
            "Iteration 3722: Loss = 0.4951, ||Grad|| = 0.1902, ||W|| = 0.4426\n",
            "Iteration 3723: Loss = 0.4951, ||Grad|| = 0.1900, ||W|| = 0.4425\n",
            "Iteration 3724: Loss = 0.4950, ||Grad|| = 0.1898, ||W|| = 0.4425\n",
            "Iteration 3725: Loss = 0.4950, ||Grad|| = 0.1896, ||W|| = 0.4424\n",
            "Iteration 3726: Loss = 0.4950, ||Grad|| = 0.1895, ||W|| = 0.4423\n",
            "Iteration 3727: Loss = 0.4950, ||Grad|| = 0.1893, ||W|| = 0.4423\n",
            "Iteration 3728: Loss = 0.4950, ||Grad|| = 0.1891, ||W|| = 0.4422\n",
            "Iteration 3729: Loss = 0.4949, ||Grad|| = 0.1890, ||W|| = 0.4422\n",
            "Iteration 3730: Loss = 0.4949, ||Grad|| = 0.1888, ||W|| = 0.4421\n",
            "Iteration 3731: Loss = 0.4949, ||Grad|| = 0.1886, ||W|| = 0.4421\n",
            "Iteration 3732: Loss = 0.4949, ||Grad|| = 0.1885, ||W|| = 0.4420\n",
            "Iteration 3733: Loss = 0.4948, ||Grad|| = 0.1883, ||W|| = 0.4420\n",
            "Iteration 3734: Loss = 0.4948, ||Grad|| = 0.1881, ||W|| = 0.4419\n",
            "Iteration 3735: Loss = 0.4948, ||Grad|| = 0.1880, ||W|| = 0.4418\n",
            "Iteration 3736: Loss = 0.4948, ||Grad|| = 0.1878, ||W|| = 0.4418\n",
            "Iteration 3737: Loss = 0.4948, ||Grad|| = 0.1876, ||W|| = 0.4417\n",
            "Iteration 3738: Loss = 0.4947, ||Grad|| = 0.1875, ||W|| = 0.4417\n",
            "Iteration 3739: Loss = 0.4947, ||Grad|| = 0.1873, ||W|| = 0.4416\n",
            "Iteration 3740: Loss = 0.4947, ||Grad|| = 0.1871, ||W|| = 0.4416\n",
            "Iteration 3741: Loss = 0.4947, ||Grad|| = 0.1870, ||W|| = 0.4415\n",
            "Iteration 3742: Loss = 0.4946, ||Grad|| = 0.1868, ||W|| = 0.4415\n",
            "Iteration 3743: Loss = 0.4946, ||Grad|| = 0.1866, ||W|| = 0.4414\n",
            "Iteration 3744: Loss = 0.4946, ||Grad|| = 0.1865, ||W|| = 0.4414\n",
            "Iteration 3745: Loss = 0.4946, ||Grad|| = 0.1863, ||W|| = 0.4413\n",
            "Iteration 3746: Loss = 0.4945, ||Grad|| = 0.1861, ||W|| = 0.4412\n",
            "Iteration 3747: Loss = 0.4945, ||Grad|| = 0.1860, ||W|| = 0.4412\n",
            "Iteration 3748: Loss = 0.4945, ||Grad|| = 0.1858, ||W|| = 0.4411\n",
            "Iteration 3749: Loss = 0.4945, ||Grad|| = 0.1856, ||W|| = 0.4411\n",
            "Iteration 3750: Loss = 0.4945, ||Grad|| = 0.1855, ||W|| = 0.4410\n",
            "Iteration 3751: Loss = 0.4944, ||Grad|| = 0.1853, ||W|| = 0.4410\n",
            "Iteration 3752: Loss = 0.4944, ||Grad|| = 0.1851, ||W|| = 0.4409\n",
            "Iteration 3753: Loss = 0.4944, ||Grad|| = 0.1850, ||W|| = 0.4409\n",
            "Iteration 3754: Loss = 0.4944, ||Grad|| = 0.1848, ||W|| = 0.4408\n",
            "Iteration 3755: Loss = 0.4943, ||Grad|| = 0.1846, ||W|| = 0.4408\n",
            "Iteration 3756: Loss = 0.4943, ||Grad|| = 0.1845, ||W|| = 0.4407\n",
            "Iteration 3757: Loss = 0.4943, ||Grad|| = 0.1843, ||W|| = 0.4407\n",
            "Iteration 3758: Loss = 0.4943, ||Grad|| = 0.1841, ||W|| = 0.4406\n",
            "Iteration 3759: Loss = 0.4943, ||Grad|| = 0.1840, ||W|| = 0.4406\n",
            "Iteration 3760: Loss = 0.4942, ||Grad|| = 0.1838, ||W|| = 0.4405\n",
            "Iteration 3761: Loss = 0.4942, ||Grad|| = 0.1837, ||W|| = 0.4404\n",
            "Iteration 3762: Loss = 0.4942, ||Grad|| = 0.1835, ||W|| = 0.4404\n",
            "Iteration 3763: Loss = 0.4942, ||Grad|| = 0.1833, ||W|| = 0.4403\n",
            "Iteration 3764: Loss = 0.4942, ||Grad|| = 0.1832, ||W|| = 0.4403\n",
            "Iteration 3765: Loss = 0.4941, ||Grad|| = 0.1830, ||W|| = 0.4402\n",
            "Iteration 3766: Loss = 0.4941, ||Grad|| = 0.1828, ||W|| = 0.4402\n",
            "Iteration 3767: Loss = 0.4941, ||Grad|| = 0.1827, ||W|| = 0.4401\n",
            "Iteration 3768: Loss = 0.4941, ||Grad|| = 0.1825, ||W|| = 0.4401\n",
            "Iteration 3769: Loss = 0.4940, ||Grad|| = 0.1824, ||W|| = 0.4400\n",
            "Iteration 3770: Loss = 0.4940, ||Grad|| = 0.1822, ||W|| = 0.4400\n",
            "Iteration 3771: Loss = 0.4940, ||Grad|| = 0.1820, ||W|| = 0.4399\n",
            "Iteration 3772: Loss = 0.4940, ||Grad|| = 0.1819, ||W|| = 0.4399\n",
            "Iteration 3773: Loss = 0.4940, ||Grad|| = 0.1817, ||W|| = 0.4398\n",
            "Iteration 3774: Loss = 0.4939, ||Grad|| = 0.1816, ||W|| = 0.4398\n",
            "Iteration 3775: Loss = 0.4939, ||Grad|| = 0.1814, ||W|| = 0.4397\n",
            "Iteration 3776: Loss = 0.4939, ||Grad|| = 0.1812, ||W|| = 0.4397\n",
            "Iteration 3777: Loss = 0.4939, ||Grad|| = 0.1811, ||W|| = 0.4396\n",
            "Iteration 3778: Loss = 0.4939, ||Grad|| = 0.1809, ||W|| = 0.4396\n",
            "Iteration 3779: Loss = 0.4938, ||Grad|| = 0.1807, ||W|| = 0.4395\n",
            "Iteration 3780: Loss = 0.4938, ||Grad|| = 0.1806, ||W|| = 0.4395\n",
            "Iteration 3781: Loss = 0.4938, ||Grad|| = 0.1804, ||W|| = 0.4394\n",
            "Iteration 3782: Loss = 0.4938, ||Grad|| = 0.1803, ||W|| = 0.4394\n",
            "Iteration 3783: Loss = 0.4938, ||Grad|| = 0.1801, ||W|| = 0.4393\n",
            "Iteration 3784: Loss = 0.4937, ||Grad|| = 0.1800, ||W|| = 0.4393\n",
            "Iteration 3785: Loss = 0.4937, ||Grad|| = 0.1798, ||W|| = 0.4392\n",
            "Iteration 3786: Loss = 0.4937, ||Grad|| = 0.1796, ||W|| = 0.4392\n",
            "Iteration 3787: Loss = 0.4937, ||Grad|| = 0.1795, ||W|| = 0.4391\n",
            "Iteration 3788: Loss = 0.4937, ||Grad|| = 0.1793, ||W|| = 0.4391\n",
            "Iteration 3789: Loss = 0.4936, ||Grad|| = 0.1792, ||W|| = 0.4390\n",
            "Iteration 3790: Loss = 0.4936, ||Grad|| = 0.1790, ||W|| = 0.4390\n",
            "Iteration 3791: Loss = 0.4936, ||Grad|| = 0.1788, ||W|| = 0.4389\n",
            "Iteration 3792: Loss = 0.4936, ||Grad|| = 0.1787, ||W|| = 0.4389\n",
            "Iteration 3793: Loss = 0.4935, ||Grad|| = 0.1785, ||W|| = 0.4388\n",
            "Iteration 3794: Loss = 0.4935, ||Grad|| = 0.1784, ||W|| = 0.4388\n",
            "Iteration 3795: Loss = 0.4935, ||Grad|| = 0.1782, ||W|| = 0.4387\n",
            "Iteration 3796: Loss = 0.4935, ||Grad|| = 0.1781, ||W|| = 0.4387\n",
            "Iteration 3797: Loss = 0.4935, ||Grad|| = 0.1779, ||W|| = 0.4386\n",
            "Iteration 3798: Loss = 0.4934, ||Grad|| = 0.1777, ||W|| = 0.4386\n",
            "Iteration 3799: Loss = 0.4934, ||Grad|| = 0.1776, ||W|| = 0.4385\n",
            "Iteration 3800: Loss = 0.4934, ||Grad|| = 0.1774, ||W|| = 0.4385\n",
            "Iteration 3801: Loss = 0.4934, ||Grad|| = 0.1773, ||W|| = 0.4384\n",
            "Iteration 3802: Loss = 0.4934, ||Grad|| = 0.1771, ||W|| = 0.4384\n",
            "Iteration 3803: Loss = 0.4933, ||Grad|| = 0.1770, ||W|| = 0.4383\n",
            "Iteration 3804: Loss = 0.4933, ||Grad|| = 0.1768, ||W|| = 0.4383\n",
            "Iteration 3805: Loss = 0.4933, ||Grad|| = 0.1766, ||W|| = 0.4382\n",
            "Iteration 3806: Loss = 0.4933, ||Grad|| = 0.1765, ||W|| = 0.4382\n",
            "Iteration 3807: Loss = 0.4933, ||Grad|| = 0.1763, ||W|| = 0.4381\n",
            "Iteration 3808: Loss = 0.4933, ||Grad|| = 0.1762, ||W|| = 0.4381\n",
            "Iteration 3809: Loss = 0.4932, ||Grad|| = 0.1760, ||W|| = 0.4380\n",
            "Iteration 3810: Loss = 0.4932, ||Grad|| = 0.1759, ||W|| = 0.4380\n",
            "Iteration 3811: Loss = 0.4932, ||Grad|| = 0.1757, ||W|| = 0.4380\n",
            "Iteration 3812: Loss = 0.4932, ||Grad|| = 0.1756, ||W|| = 0.4379\n",
            "Iteration 3813: Loss = 0.4932, ||Grad|| = 0.1754, ||W|| = 0.4379\n",
            "Iteration 3814: Loss = 0.4931, ||Grad|| = 0.1753, ||W|| = 0.4378\n",
            "Iteration 3815: Loss = 0.4931, ||Grad|| = 0.1751, ||W|| = 0.4378\n",
            "Iteration 3816: Loss = 0.4931, ||Grad|| = 0.1749, ||W|| = 0.4377\n",
            "Iteration 3817: Loss = 0.4931, ||Grad|| = 0.1748, ||W|| = 0.4377\n",
            "Iteration 3818: Loss = 0.4931, ||Grad|| = 0.1746, ||W|| = 0.4376\n",
            "Iteration 3819: Loss = 0.4930, ||Grad|| = 0.1745, ||W|| = 0.4376\n",
            "Iteration 3820: Loss = 0.4930, ||Grad|| = 0.1743, ||W|| = 0.4375\n",
            "Iteration 3821: Loss = 0.4930, ||Grad|| = 0.1742, ||W|| = 0.4375\n",
            "Iteration 3822: Loss = 0.4930, ||Grad|| = 0.1740, ||W|| = 0.4374\n",
            "Iteration 3823: Loss = 0.4930, ||Grad|| = 0.1739, ||W|| = 0.4374\n",
            "Iteration 3824: Loss = 0.4929, ||Grad|| = 0.1737, ||W|| = 0.4373\n",
            "Iteration 3825: Loss = 0.4929, ||Grad|| = 0.1736, ||W|| = 0.4373\n",
            "Iteration 3826: Loss = 0.4929, ||Grad|| = 0.1734, ||W|| = 0.4372\n",
            "Iteration 3827: Loss = 0.4929, ||Grad|| = 0.1733, ||W|| = 0.4372\n",
            "Iteration 3828: Loss = 0.4929, ||Grad|| = 0.1731, ||W|| = 0.4372\n",
            "Iteration 3829: Loss = 0.4928, ||Grad|| = 0.1730, ||W|| = 0.4371\n",
            "Iteration 3830: Loss = 0.4928, ||Grad|| = 0.1728, ||W|| = 0.4371\n",
            "Iteration 3831: Loss = 0.4928, ||Grad|| = 0.1727, ||W|| = 0.4370\n",
            "Iteration 3832: Loss = 0.4928, ||Grad|| = 0.1725, ||W|| = 0.4370\n",
            "Iteration 3833: Loss = 0.4928, ||Grad|| = 0.1723, ||W|| = 0.4369\n",
            "Iteration 3834: Loss = 0.4928, ||Grad|| = 0.1722, ||W|| = 0.4369\n",
            "Iteration 3835: Loss = 0.4927, ||Grad|| = 0.1720, ||W|| = 0.4368\n",
            "Iteration 3836: Loss = 0.4927, ||Grad|| = 0.1719, ||W|| = 0.4368\n",
            "Iteration 3837: Loss = 0.4927, ||Grad|| = 0.1717, ||W|| = 0.4367\n",
            "Iteration 3838: Loss = 0.4927, ||Grad|| = 0.1716, ||W|| = 0.4367\n",
            "Iteration 3839: Loss = 0.4927, ||Grad|| = 0.1714, ||W|| = 0.4367\n",
            "Iteration 3840: Loss = 0.4926, ||Grad|| = 0.1713, ||W|| = 0.4366\n",
            "Iteration 3841: Loss = 0.4926, ||Grad|| = 0.1711, ||W|| = 0.4366\n",
            "Iteration 3842: Loss = 0.4926, ||Grad|| = 0.1710, ||W|| = 0.4365\n",
            "Iteration 3843: Loss = 0.4926, ||Grad|| = 0.1708, ||W|| = 0.4365\n",
            "Iteration 3844: Loss = 0.4926, ||Grad|| = 0.1707, ||W|| = 0.4364\n",
            "Iteration 3845: Loss = 0.4926, ||Grad|| = 0.1705, ||W|| = 0.4364\n",
            "Iteration 3846: Loss = 0.4925, ||Grad|| = 0.1704, ||W|| = 0.4363\n",
            "Iteration 3847: Loss = 0.4925, ||Grad|| = 0.1702, ||W|| = 0.4363\n",
            "Iteration 3848: Loss = 0.4925, ||Grad|| = 0.1701, ||W|| = 0.4363\n",
            "Iteration 3849: Loss = 0.4925, ||Grad|| = 0.1700, ||W|| = 0.4362\n",
            "Iteration 3850: Loss = 0.4925, ||Grad|| = 0.1698, ||W|| = 0.4362\n",
            "Iteration 3851: Loss = 0.4924, ||Grad|| = 0.1697, ||W|| = 0.4361\n",
            "Iteration 3852: Loss = 0.4924, ||Grad|| = 0.1695, ||W|| = 0.4361\n",
            "Iteration 3853: Loss = 0.4924, ||Grad|| = 0.1694, ||W|| = 0.4360\n",
            "Iteration 3854: Loss = 0.4924, ||Grad|| = 0.1692, ||W|| = 0.4360\n",
            "Iteration 3855: Loss = 0.4924, ||Grad|| = 0.1691, ||W|| = 0.4359\n",
            "Iteration 3856: Loss = 0.4924, ||Grad|| = 0.1689, ||W|| = 0.4359\n",
            "Iteration 3857: Loss = 0.4923, ||Grad|| = 0.1688, ||W|| = 0.4359\n",
            "Iteration 3858: Loss = 0.4923, ||Grad|| = 0.1686, ||W|| = 0.4358\n",
            "Iteration 3859: Loss = 0.4923, ||Grad|| = 0.1685, ||W|| = 0.4358\n",
            "Iteration 3860: Loss = 0.4923, ||Grad|| = 0.1683, ||W|| = 0.4357\n",
            "Iteration 3861: Loss = 0.4923, ||Grad|| = 0.1682, ||W|| = 0.4357\n",
            "Iteration 3862: Loss = 0.4922, ||Grad|| = 0.1680, ||W|| = 0.4356\n",
            "Iteration 3863: Loss = 0.4922, ||Grad|| = 0.1679, ||W|| = 0.4356\n",
            "Iteration 3864: Loss = 0.4922, ||Grad|| = 0.1677, ||W|| = 0.4356\n",
            "Iteration 3865: Loss = 0.4922, ||Grad|| = 0.1676, ||W|| = 0.4355\n",
            "Iteration 3866: Loss = 0.4922, ||Grad|| = 0.1674, ||W|| = 0.4355\n",
            "Iteration 3867: Loss = 0.4922, ||Grad|| = 0.1673, ||W|| = 0.4354\n",
            "Iteration 3868: Loss = 0.4921, ||Grad|| = 0.1672, ||W|| = 0.4354\n",
            "Iteration 3869: Loss = 0.4921, ||Grad|| = 0.1670, ||W|| = 0.4353\n",
            "Iteration 3870: Loss = 0.4921, ||Grad|| = 0.1669, ||W|| = 0.4353\n",
            "Iteration 3871: Loss = 0.4921, ||Grad|| = 0.1667, ||W|| = 0.4353\n",
            "Iteration 3872: Loss = 0.4921, ||Grad|| = 0.1666, ||W|| = 0.4352\n",
            "Iteration 3873: Loss = 0.4921, ||Grad|| = 0.1664, ||W|| = 0.4352\n",
            "Iteration 3874: Loss = 0.4920, ||Grad|| = 0.1663, ||W|| = 0.4351\n",
            "Iteration 3875: Loss = 0.4920, ||Grad|| = 0.1661, ||W|| = 0.4351\n",
            "Iteration 3876: Loss = 0.4920, ||Grad|| = 0.1660, ||W|| = 0.4350\n",
            "Iteration 3877: Loss = 0.4920, ||Grad|| = 0.1659, ||W|| = 0.4350\n",
            "Iteration 3878: Loss = 0.4920, ||Grad|| = 0.1657, ||W|| = 0.4350\n",
            "Iteration 3879: Loss = 0.4920, ||Grad|| = 0.1656, ||W|| = 0.4349\n",
            "Iteration 3880: Loss = 0.4919, ||Grad|| = 0.1654, ||W|| = 0.4349\n",
            "Iteration 3881: Loss = 0.4919, ||Grad|| = 0.1653, ||W|| = 0.4348\n",
            "Iteration 3882: Loss = 0.4919, ||Grad|| = 0.1651, ||W|| = 0.4348\n",
            "Iteration 3883: Loss = 0.4919, ||Grad|| = 0.1650, ||W|| = 0.4348\n",
            "Iteration 3884: Loss = 0.4919, ||Grad|| = 0.1648, ||W|| = 0.4347\n",
            "Iteration 3885: Loss = 0.4919, ||Grad|| = 0.1647, ||W|| = 0.4347\n",
            "Iteration 3886: Loss = 0.4918, ||Grad|| = 0.1646, ||W|| = 0.4346\n",
            "Iteration 3887: Loss = 0.4918, ||Grad|| = 0.1644, ||W|| = 0.4346\n",
            "Iteration 3888: Loss = 0.4918, ||Grad|| = 0.1643, ||W|| = 0.4345\n",
            "Iteration 3889: Loss = 0.4918, ||Grad|| = 0.1641, ||W|| = 0.4345\n",
            "Iteration 3890: Loss = 0.4918, ||Grad|| = 0.1640, ||W|| = 0.4345\n",
            "Iteration 3891: Loss = 0.4918, ||Grad|| = 0.1638, ||W|| = 0.4344\n",
            "Iteration 3892: Loss = 0.4917, ||Grad|| = 0.1637, ||W|| = 0.4344\n",
            "Iteration 3893: Loss = 0.4917, ||Grad|| = 0.1636, ||W|| = 0.4343\n",
            "Iteration 3894: Loss = 0.4917, ||Grad|| = 0.1634, ||W|| = 0.4343\n",
            "Iteration 3895: Loss = 0.4917, ||Grad|| = 0.1633, ||W|| = 0.4343\n",
            "Iteration 3896: Loss = 0.4917, ||Grad|| = 0.1631, ||W|| = 0.4342\n",
            "Iteration 3897: Loss = 0.4917, ||Grad|| = 0.1630, ||W|| = 0.4342\n",
            "Iteration 3898: Loss = 0.4916, ||Grad|| = 0.1629, ||W|| = 0.4341\n",
            "Iteration 3899: Loss = 0.4916, ||Grad|| = 0.1627, ||W|| = 0.4341\n",
            "Iteration 3900: Loss = 0.4916, ||Grad|| = 0.1626, ||W|| = 0.4341\n",
            "Iteration 3901: Loss = 0.4916, ||Grad|| = 0.1624, ||W|| = 0.4340\n",
            "Iteration 3902: Loss = 0.4916, ||Grad|| = 0.1623, ||W|| = 0.4340\n",
            "Iteration 3903: Loss = 0.4916, ||Grad|| = 0.1622, ||W|| = 0.4339\n",
            "Iteration 3904: Loss = 0.4915, ||Grad|| = 0.1620, ||W|| = 0.4339\n",
            "Iteration 3905: Loss = 0.4915, ||Grad|| = 0.1619, ||W|| = 0.4339\n",
            "Iteration 3906: Loss = 0.4915, ||Grad|| = 0.1617, ||W|| = 0.4338\n",
            "Iteration 3907: Loss = 0.4915, ||Grad|| = 0.1616, ||W|| = 0.4338\n",
            "Iteration 3908: Loss = 0.4915, ||Grad|| = 0.1615, ||W|| = 0.4337\n",
            "Iteration 3909: Loss = 0.4915, ||Grad|| = 0.1613, ||W|| = 0.4337\n",
            "Iteration 3910: Loss = 0.4914, ||Grad|| = 0.1612, ||W|| = 0.4337\n",
            "Iteration 3911: Loss = 0.4914, ||Grad|| = 0.1610, ||W|| = 0.4336\n",
            "Iteration 3912: Loss = 0.4914, ||Grad|| = 0.1609, ||W|| = 0.4336\n",
            "Iteration 3913: Loss = 0.4914, ||Grad|| = 0.1608, ||W|| = 0.4335\n",
            "Iteration 3914: Loss = 0.4914, ||Grad|| = 0.1606, ||W|| = 0.4335\n",
            "Iteration 3915: Loss = 0.4914, ||Grad|| = 0.1605, ||W|| = 0.4335\n",
            "Iteration 3916: Loss = 0.4913, ||Grad|| = 0.1603, ||W|| = 0.4334\n",
            "Iteration 3917: Loss = 0.4913, ||Grad|| = 0.1602, ||W|| = 0.4334\n",
            "Iteration 3918: Loss = 0.4913, ||Grad|| = 0.1601, ||W|| = 0.4333\n",
            "Iteration 3919: Loss = 0.4913, ||Grad|| = 0.1599, ||W|| = 0.4333\n",
            "Iteration 3920: Loss = 0.4913, ||Grad|| = 0.1598, ||W|| = 0.4333\n",
            "Iteration 3921: Loss = 0.4913, ||Grad|| = 0.1597, ||W|| = 0.4332\n",
            "Iteration 3922: Loss = 0.4913, ||Grad|| = 0.1595, ||W|| = 0.4332\n",
            "Iteration 3923: Loss = 0.4912, ||Grad|| = 0.1594, ||W|| = 0.4332\n",
            "Iteration 3924: Loss = 0.4912, ||Grad|| = 0.1592, ||W|| = 0.4331\n",
            "Iteration 3925: Loss = 0.4912, ||Grad|| = 0.1591, ||W|| = 0.4331\n",
            "Iteration 3926: Loss = 0.4912, ||Grad|| = 0.1590, ||W|| = 0.4330\n",
            "Iteration 3927: Loss = 0.4912, ||Grad|| = 0.1588, ||W|| = 0.4330\n",
            "Iteration 3928: Loss = 0.4912, ||Grad|| = 0.1587, ||W|| = 0.4330\n",
            "Iteration 3929: Loss = 0.4911, ||Grad|| = 0.1586, ||W|| = 0.4329\n",
            "Iteration 3930: Loss = 0.4911, ||Grad|| = 0.1584, ||W|| = 0.4329\n",
            "Iteration 3931: Loss = 0.4911, ||Grad|| = 0.1583, ||W|| = 0.4328\n",
            "Iteration 3932: Loss = 0.4911, ||Grad|| = 0.1581, ||W|| = 0.4328\n",
            "Iteration 3933: Loss = 0.4911, ||Grad|| = 0.1580, ||W|| = 0.4328\n",
            "Iteration 3934: Loss = 0.4911, ||Grad|| = 0.1579, ||W|| = 0.4327\n",
            "Iteration 3935: Loss = 0.4911, ||Grad|| = 0.1577, ||W|| = 0.4327\n",
            "Iteration 3936: Loss = 0.4910, ||Grad|| = 0.1576, ||W|| = 0.4327\n",
            "Iteration 3937: Loss = 0.4910, ||Grad|| = 0.1575, ||W|| = 0.4326\n",
            "Iteration 3938: Loss = 0.4910, ||Grad|| = 0.1573, ||W|| = 0.4326\n",
            "Iteration 3939: Loss = 0.4910, ||Grad|| = 0.1572, ||W|| = 0.4325\n",
            "Iteration 3940: Loss = 0.4910, ||Grad|| = 0.1571, ||W|| = 0.4325\n",
            "Iteration 3941: Loss = 0.4910, ||Grad|| = 0.1569, ||W|| = 0.4325\n",
            "Iteration 3942: Loss = 0.4910, ||Grad|| = 0.1568, ||W|| = 0.4324\n",
            "Iteration 3943: Loss = 0.4909, ||Grad|| = 0.1567, ||W|| = 0.4324\n",
            "Iteration 3944: Loss = 0.4909, ||Grad|| = 0.1565, ||W|| = 0.4324\n",
            "Iteration 3945: Loss = 0.4909, ||Grad|| = 0.1564, ||W|| = 0.4323\n",
            "Iteration 3946: Loss = 0.4909, ||Grad|| = 0.1563, ||W|| = 0.4323\n",
            "Iteration 3947: Loss = 0.4909, ||Grad|| = 0.1561, ||W|| = 0.4323\n",
            "Iteration 3948: Loss = 0.4909, ||Grad|| = 0.1560, ||W|| = 0.4322\n",
            "Iteration 3949: Loss = 0.4908, ||Grad|| = 0.1559, ||W|| = 0.4322\n",
            "Iteration 3950: Loss = 0.4908, ||Grad|| = 0.1557, ||W|| = 0.4321\n",
            "Iteration 3951: Loss = 0.4908, ||Grad|| = 0.1556, ||W|| = 0.4321\n",
            "Iteration 3952: Loss = 0.4908, ||Grad|| = 0.1555, ||W|| = 0.4321\n",
            "Iteration 3953: Loss = 0.4908, ||Grad|| = 0.1553, ||W|| = 0.4320\n",
            "Iteration 3954: Loss = 0.4908, ||Grad|| = 0.1552, ||W|| = 0.4320\n",
            "Iteration 3955: Loss = 0.4908, ||Grad|| = 0.1551, ||W|| = 0.4320\n",
            "Iteration 3956: Loss = 0.4907, ||Grad|| = 0.1549, ||W|| = 0.4319\n",
            "Iteration 3957: Loss = 0.4907, ||Grad|| = 0.1548, ||W|| = 0.4319\n",
            "Iteration 3958: Loss = 0.4907, ||Grad|| = 0.1547, ||W|| = 0.4319\n",
            "Iteration 3959: Loss = 0.4907, ||Grad|| = 0.1545, ||W|| = 0.4318\n",
            "Iteration 3960: Loss = 0.4907, ||Grad|| = 0.1544, ||W|| = 0.4318\n",
            "Iteration 3961: Loss = 0.4907, ||Grad|| = 0.1543, ||W|| = 0.4317\n",
            "Iteration 3962: Loss = 0.4907, ||Grad|| = 0.1541, ||W|| = 0.4317\n",
            "Iteration 3963: Loss = 0.4906, ||Grad|| = 0.1540, ||W|| = 0.4317\n",
            "Iteration 3964: Loss = 0.4906, ||Grad|| = 0.1539, ||W|| = 0.4316\n",
            "Iteration 3965: Loss = 0.4906, ||Grad|| = 0.1537, ||W|| = 0.4316\n",
            "Iteration 3966: Loss = 0.4906, ||Grad|| = 0.1536, ||W|| = 0.4316\n",
            "Iteration 3967: Loss = 0.4906, ||Grad|| = 0.1535, ||W|| = 0.4315\n",
            "Iteration 3968: Loss = 0.4906, ||Grad|| = 0.1533, ||W|| = 0.4315\n",
            "Iteration 3969: Loss = 0.4906, ||Grad|| = 0.1532, ||W|| = 0.4315\n",
            "Iteration 3970: Loss = 0.4905, ||Grad|| = 0.1531, ||W|| = 0.4314\n",
            "Iteration 3971: Loss = 0.4905, ||Grad|| = 0.1530, ||W|| = 0.4314\n",
            "Iteration 3972: Loss = 0.4905, ||Grad|| = 0.1528, ||W|| = 0.4314\n",
            "Iteration 3973: Loss = 0.4905, ||Grad|| = 0.1527, ||W|| = 0.4313\n",
            "Iteration 3974: Loss = 0.4905, ||Grad|| = 0.1526, ||W|| = 0.4313\n",
            "Iteration 3975: Loss = 0.4905, ||Grad|| = 0.1524, ||W|| = 0.4312\n",
            "Iteration 3976: Loss = 0.4905, ||Grad|| = 0.1523, ||W|| = 0.4312\n",
            "Iteration 3977: Loss = 0.4904, ||Grad|| = 0.1522, ||W|| = 0.4312\n",
            "Iteration 3978: Loss = 0.4904, ||Grad|| = 0.1520, ||W|| = 0.4311\n",
            "Iteration 3979: Loss = 0.4904, ||Grad|| = 0.1519, ||W|| = 0.4311\n",
            "Iteration 3980: Loss = 0.4904, ||Grad|| = 0.1518, ||W|| = 0.4311\n",
            "Iteration 3981: Loss = 0.4904, ||Grad|| = 0.1517, ||W|| = 0.4310\n",
            "Iteration 3982: Loss = 0.4904, ||Grad|| = 0.1515, ||W|| = 0.4310\n",
            "Iteration 3983: Loss = 0.4904, ||Grad|| = 0.1514, ||W|| = 0.4310\n",
            "Iteration 3984: Loss = 0.4903, ||Grad|| = 0.1513, ||W|| = 0.4309\n",
            "Iteration 3985: Loss = 0.4903, ||Grad|| = 0.1511, ||W|| = 0.4309\n",
            "Iteration 3986: Loss = 0.4903, ||Grad|| = 0.1510, ||W|| = 0.4309\n",
            "Iteration 3987: Loss = 0.4903, ||Grad|| = 0.1509, ||W|| = 0.4308\n",
            "Iteration 3988: Loss = 0.4903, ||Grad|| = 0.1508, ||W|| = 0.4308\n",
            "Iteration 3989: Loss = 0.4903, ||Grad|| = 0.1506, ||W|| = 0.4308\n",
            "Iteration 3990: Loss = 0.4903, ||Grad|| = 0.1505, ||W|| = 0.4307\n",
            "Iteration 3991: Loss = 0.4903, ||Grad|| = 0.1504, ||W|| = 0.4307\n",
            "Iteration 3992: Loss = 0.4902, ||Grad|| = 0.1502, ||W|| = 0.4307\n",
            "Iteration 3993: Loss = 0.4902, ||Grad|| = 0.1501, ||W|| = 0.4306\n",
            "Iteration 3994: Loss = 0.4902, ||Grad|| = 0.1500, ||W|| = 0.4306\n",
            "Iteration 3995: Loss = 0.4902, ||Grad|| = 0.1499, ||W|| = 0.4306\n",
            "Iteration 3996: Loss = 0.4902, ||Grad|| = 0.1497, ||W|| = 0.4305\n",
            "Iteration 3997: Loss = 0.4902, ||Grad|| = 0.1496, ||W|| = 0.4305\n",
            "Iteration 3998: Loss = 0.4902, ||Grad|| = 0.1495, ||W|| = 0.4305\n",
            "Iteration 3999: Loss = 0.4901, ||Grad|| = 0.1493, ||W|| = 0.4304\n",
            "Iteration 4000: Loss = 0.4901, ||Grad|| = 0.1492, ||W|| = 0.4304\n",
            "Iteration 4001: Loss = 0.4901, ||Grad|| = 0.1491, ||W|| = 0.4304\n",
            "Iteration 4002: Loss = 0.4901, ||Grad|| = 0.1490, ||W|| = 0.4303\n",
            "Iteration 4003: Loss = 0.4901, ||Grad|| = 0.1488, ||W|| = 0.4303\n",
            "Iteration 4004: Loss = 0.4901, ||Grad|| = 0.1487, ||W|| = 0.4303\n",
            "Iteration 4005: Loss = 0.4901, ||Grad|| = 0.1486, ||W|| = 0.4302\n",
            "Iteration 4006: Loss = 0.4901, ||Grad|| = 0.1485, ||W|| = 0.4302\n",
            "Iteration 4007: Loss = 0.4900, ||Grad|| = 0.1483, ||W|| = 0.4302\n",
            "Iteration 4008: Loss = 0.4900, ||Grad|| = 0.1482, ||W|| = 0.4301\n",
            "Iteration 4009: Loss = 0.4900, ||Grad|| = 0.1481, ||W|| = 0.4301\n",
            "Iteration 4010: Loss = 0.4900, ||Grad|| = 0.1480, ||W|| = 0.4301\n",
            "Iteration 4011: Loss = 0.4900, ||Grad|| = 0.1478, ||W|| = 0.4300\n",
            "Iteration 4012: Loss = 0.4900, ||Grad|| = 0.1477, ||W|| = 0.4300\n",
            "Iteration 4013: Loss = 0.4900, ||Grad|| = 0.1476, ||W|| = 0.4300\n",
            "Iteration 4014: Loss = 0.4899, ||Grad|| = 0.1475, ||W|| = 0.4299\n",
            "Iteration 4015: Loss = 0.4899, ||Grad|| = 0.1473, ||W|| = 0.4299\n",
            "Iteration 4016: Loss = 0.4899, ||Grad|| = 0.1472, ||W|| = 0.4299\n",
            "Iteration 4017: Loss = 0.4899, ||Grad|| = 0.1471, ||W|| = 0.4298\n",
            "Iteration 4018: Loss = 0.4899, ||Grad|| = 0.1470, ||W|| = 0.4298\n",
            "Iteration 4019: Loss = 0.4899, ||Grad|| = 0.1468, ||W|| = 0.4298\n",
            "Iteration 4020: Loss = 0.4899, ||Grad|| = 0.1467, ||W|| = 0.4297\n",
            "Iteration 4021: Loss = 0.4899, ||Grad|| = 0.1466, ||W|| = 0.4297\n",
            "Iteration 4022: Loss = 0.4898, ||Grad|| = 0.1465, ||W|| = 0.4297\n",
            "Iteration 4023: Loss = 0.4898, ||Grad|| = 0.1463, ||W|| = 0.4297\n",
            "Iteration 4024: Loss = 0.4898, ||Grad|| = 0.1462, ||W|| = 0.4296\n",
            "Iteration 4025: Loss = 0.4898, ||Grad|| = 0.1461, ||W|| = 0.4296\n",
            "Iteration 4026: Loss = 0.4898, ||Grad|| = 0.1460, ||W|| = 0.4296\n",
            "Iteration 4027: Loss = 0.4898, ||Grad|| = 0.1459, ||W|| = 0.4295\n",
            "Iteration 4028: Loss = 0.4898, ||Grad|| = 0.1457, ||W|| = 0.4295\n",
            "Iteration 4029: Loss = 0.4898, ||Grad|| = 0.1456, ||W|| = 0.4295\n",
            "Iteration 4030: Loss = 0.4897, ||Grad|| = 0.1455, ||W|| = 0.4294\n",
            "Iteration 4031: Loss = 0.4897, ||Grad|| = 0.1454, ||W|| = 0.4294\n",
            "Iteration 4032: Loss = 0.4897, ||Grad|| = 0.1452, ||W|| = 0.4294\n",
            "Iteration 4033: Loss = 0.4897, ||Grad|| = 0.1451, ||W|| = 0.4293\n",
            "Iteration 4034: Loss = 0.4897, ||Grad|| = 0.1450, ||W|| = 0.4293\n",
            "Iteration 4035: Loss = 0.4897, ||Grad|| = 0.1449, ||W|| = 0.4293\n",
            "Iteration 4036: Loss = 0.4897, ||Grad|| = 0.1447, ||W|| = 0.4292\n",
            "Iteration 4037: Loss = 0.4897, ||Grad|| = 0.1446, ||W|| = 0.4292\n",
            "Iteration 4038: Loss = 0.4896, ||Grad|| = 0.1445, ||W|| = 0.4292\n",
            "Iteration 4039: Loss = 0.4896, ||Grad|| = 0.1444, ||W|| = 0.4292\n",
            "Iteration 4040: Loss = 0.4896, ||Grad|| = 0.1443, ||W|| = 0.4291\n",
            "Iteration 4041: Loss = 0.4896, ||Grad|| = 0.1441, ||W|| = 0.4291\n",
            "Iteration 4042: Loss = 0.4896, ||Grad|| = 0.1440, ||W|| = 0.4291\n",
            "Iteration 4043: Loss = 0.4896, ||Grad|| = 0.1439, ||W|| = 0.4290\n",
            "Iteration 4044: Loss = 0.4896, ||Grad|| = 0.1438, ||W|| = 0.4290\n",
            "Iteration 4045: Loss = 0.4896, ||Grad|| = 0.1437, ||W|| = 0.4290\n",
            "Iteration 4046: Loss = 0.4895, ||Grad|| = 0.1435, ||W|| = 0.4289\n",
            "Iteration 4047: Loss = 0.4895, ||Grad|| = 0.1434, ||W|| = 0.4289\n",
            "Iteration 4048: Loss = 0.4895, ||Grad|| = 0.1433, ||W|| = 0.4289\n",
            "Iteration 4049: Loss = 0.4895, ||Grad|| = 0.1432, ||W|| = 0.4288\n",
            "Iteration 4050: Loss = 0.4895, ||Grad|| = 0.1431, ||W|| = 0.4288\n",
            "Iteration 4051: Loss = 0.4895, ||Grad|| = 0.1429, ||W|| = 0.4288\n",
            "Iteration 4052: Loss = 0.4895, ||Grad|| = 0.1428, ||W|| = 0.4288\n",
            "Iteration 4053: Loss = 0.4895, ||Grad|| = 0.1427, ||W|| = 0.4287\n",
            "Iteration 4054: Loss = 0.4894, ||Grad|| = 0.1426, ||W|| = 0.4287\n",
            "Iteration 4055: Loss = 0.4894, ||Grad|| = 0.1425, ||W|| = 0.4287\n",
            "Iteration 4056: Loss = 0.4894, ||Grad|| = 0.1423, ||W|| = 0.4286\n",
            "Iteration 4057: Loss = 0.4894, ||Grad|| = 0.1422, ||W|| = 0.4286\n",
            "Iteration 4058: Loss = 0.4894, ||Grad|| = 0.1421, ||W|| = 0.4286\n",
            "Iteration 4059: Loss = 0.4894, ||Grad|| = 0.1420, ||W|| = 0.4285\n",
            "Iteration 4060: Loss = 0.4894, ||Grad|| = 0.1419, ||W|| = 0.4285\n",
            "Iteration 4061: Loss = 0.4894, ||Grad|| = 0.1417, ||W|| = 0.4285\n",
            "Iteration 4062: Loss = 0.4894, ||Grad|| = 0.1416, ||W|| = 0.4285\n",
            "Iteration 4063: Loss = 0.4893, ||Grad|| = 0.1415, ||W|| = 0.4284\n",
            "Iteration 4064: Loss = 0.4893, ||Grad|| = 0.1414, ||W|| = 0.4284\n",
            "Iteration 4065: Loss = 0.4893, ||Grad|| = 0.1413, ||W|| = 0.4284\n",
            "Iteration 4066: Loss = 0.4893, ||Grad|| = 0.1411, ||W|| = 0.4283\n",
            "Iteration 4067: Loss = 0.4893, ||Grad|| = 0.1410, ||W|| = 0.4283\n",
            "Iteration 4068: Loss = 0.4893, ||Grad|| = 0.1409, ||W|| = 0.4283\n",
            "Iteration 4069: Loss = 0.4893, ||Grad|| = 0.1408, ||W|| = 0.4283\n",
            "Iteration 4070: Loss = 0.4893, ||Grad|| = 0.1407, ||W|| = 0.4282\n",
            "Iteration 4071: Loss = 0.4892, ||Grad|| = 0.1406, ||W|| = 0.4282\n",
            "Iteration 4072: Loss = 0.4892, ||Grad|| = 0.1404, ||W|| = 0.4282\n",
            "Iteration 4073: Loss = 0.4892, ||Grad|| = 0.1403, ||W|| = 0.4281\n",
            "Iteration 4074: Loss = 0.4892, ||Grad|| = 0.1402, ||W|| = 0.4281\n",
            "Iteration 4075: Loss = 0.4892, ||Grad|| = 0.1401, ||W|| = 0.4281\n",
            "Iteration 4076: Loss = 0.4892, ||Grad|| = 0.1400, ||W|| = 0.4280\n",
            "Iteration 4077: Loss = 0.4892, ||Grad|| = 0.1399, ||W|| = 0.4280\n",
            "Iteration 4078: Loss = 0.4892, ||Grad|| = 0.1397, ||W|| = 0.4280\n",
            "Iteration 4079: Loss = 0.4892, ||Grad|| = 0.1396, ||W|| = 0.4280\n",
            "Iteration 4080: Loss = 0.4891, ||Grad|| = 0.1395, ||W|| = 0.4279\n",
            "Iteration 4081: Loss = 0.4891, ||Grad|| = 0.1394, ||W|| = 0.4279\n",
            "Iteration 4082: Loss = 0.4891, ||Grad|| = 0.1393, ||W|| = 0.4279\n",
            "Iteration 4083: Loss = 0.4891, ||Grad|| = 0.1392, ||W|| = 0.4278\n",
            "Iteration 4084: Loss = 0.4891, ||Grad|| = 0.1390, ||W|| = 0.4278\n",
            "Iteration 4085: Loss = 0.4891, ||Grad|| = 0.1389, ||W|| = 0.4278\n",
            "Iteration 4086: Loss = 0.4891, ||Grad|| = 0.1388, ||W|| = 0.4278\n",
            "Iteration 4087: Loss = 0.4891, ||Grad|| = 0.1387, ||W|| = 0.4277\n",
            "Iteration 4088: Loss = 0.4891, ||Grad|| = 0.1386, ||W|| = 0.4277\n",
            "Iteration 4089: Loss = 0.4890, ||Grad|| = 0.1385, ||W|| = 0.4277\n",
            "Iteration 4090: Loss = 0.4890, ||Grad|| = 0.1384, ||W|| = 0.4277\n",
            "Iteration 4091: Loss = 0.4890, ||Grad|| = 0.1382, ||W|| = 0.4276\n",
            "Iteration 4092: Loss = 0.4890, ||Grad|| = 0.1381, ||W|| = 0.4276\n",
            "Iteration 4093: Loss = 0.4890, ||Grad|| = 0.1380, ||W|| = 0.4276\n",
            "Iteration 4094: Loss = 0.4890, ||Grad|| = 0.1379, ||W|| = 0.4275\n",
            "Iteration 4095: Loss = 0.4890, ||Grad|| = 0.1378, ||W|| = 0.4275\n",
            "Iteration 4096: Loss = 0.4890, ||Grad|| = 0.1377, ||W|| = 0.4275\n",
            "Iteration 4097: Loss = 0.4890, ||Grad|| = 0.1375, ||W|| = 0.4275\n",
            "Iteration 4098: Loss = 0.4889, ||Grad|| = 0.1374, ||W|| = 0.4274\n",
            "Iteration 4099: Loss = 0.4889, ||Grad|| = 0.1373, ||W|| = 0.4274\n",
            "Iteration 4100: Loss = 0.4889, ||Grad|| = 0.1372, ||W|| = 0.4274\n",
            "Iteration 4101: Loss = 0.4889, ||Grad|| = 0.1371, ||W|| = 0.4273\n",
            "Iteration 4102: Loss = 0.4889, ||Grad|| = 0.1370, ||W|| = 0.4273\n",
            "Iteration 4103: Loss = 0.4889, ||Grad|| = 0.1369, ||W|| = 0.4273\n",
            "Iteration 4104: Loss = 0.4889, ||Grad|| = 0.1368, ||W|| = 0.4273\n",
            "Iteration 4105: Loss = 0.4889, ||Grad|| = 0.1366, ||W|| = 0.4272\n",
            "Iteration 4106: Loss = 0.4889, ||Grad|| = 0.1365, ||W|| = 0.4272\n",
            "Iteration 4107: Loss = 0.4888, ||Grad|| = 0.1364, ||W|| = 0.4272\n",
            "Iteration 4108: Loss = 0.4888, ||Grad|| = 0.1363, ||W|| = 0.4272\n",
            "Iteration 4109: Loss = 0.4888, ||Grad|| = 0.1362, ||W|| = 0.4271\n",
            "Iteration 4110: Loss = 0.4888, ||Grad|| = 0.1361, ||W|| = 0.4271\n",
            "Iteration 4111: Loss = 0.4888, ||Grad|| = 0.1360, ||W|| = 0.4271\n",
            "Iteration 4112: Loss = 0.4888, ||Grad|| = 0.1358, ||W|| = 0.4270\n",
            "Iteration 4113: Loss = 0.4888, ||Grad|| = 0.1357, ||W|| = 0.4270\n",
            "Iteration 4114: Loss = 0.4888, ||Grad|| = 0.1356, ||W|| = 0.4270\n",
            "Iteration 4115: Loss = 0.4888, ||Grad|| = 0.1355, ||W|| = 0.4270\n",
            "Iteration 4116: Loss = 0.4887, ||Grad|| = 0.1354, ||W|| = 0.4269\n",
            "Iteration 4117: Loss = 0.4887, ||Grad|| = 0.1353, ||W|| = 0.4269\n",
            "Iteration 4118: Loss = 0.4887, ||Grad|| = 0.1352, ||W|| = 0.4269\n",
            "Iteration 4119: Loss = 0.4887, ||Grad|| = 0.1351, ||W|| = 0.4269\n",
            "Iteration 4120: Loss = 0.4887, ||Grad|| = 0.1350, ||W|| = 0.4268\n",
            "Iteration 4121: Loss = 0.4887, ||Grad|| = 0.1348, ||W|| = 0.4268\n",
            "Iteration 4122: Loss = 0.4887, ||Grad|| = 0.1347, ||W|| = 0.4268\n",
            "Iteration 4123: Loss = 0.4887, ||Grad|| = 0.1346, ||W|| = 0.4268\n",
            "Iteration 4124: Loss = 0.4887, ||Grad|| = 0.1345, ||W|| = 0.4267\n",
            "Iteration 4125: Loss = 0.4887, ||Grad|| = 0.1344, ||W|| = 0.4267\n",
            "Iteration 4126: Loss = 0.4886, ||Grad|| = 0.1343, ||W|| = 0.4267\n",
            "Iteration 4127: Loss = 0.4886, ||Grad|| = 0.1342, ||W|| = 0.4266\n",
            "Iteration 4128: Loss = 0.4886, ||Grad|| = 0.1341, ||W|| = 0.4266\n",
            "Iteration 4129: Loss = 0.4886, ||Grad|| = 0.1340, ||W|| = 0.4266\n",
            "Iteration 4130: Loss = 0.4886, ||Grad|| = 0.1338, ||W|| = 0.4266\n",
            "Iteration 4131: Loss = 0.4886, ||Grad|| = 0.1337, ||W|| = 0.4265\n",
            "Iteration 4132: Loss = 0.4886, ||Grad|| = 0.1336, ||W|| = 0.4265\n",
            "Iteration 4133: Loss = 0.4886, ||Grad|| = 0.1335, ||W|| = 0.4265\n",
            "Iteration 4134: Loss = 0.4886, ||Grad|| = 0.1334, ||W|| = 0.4265\n",
            "Iteration 4135: Loss = 0.4886, ||Grad|| = 0.1333, ||W|| = 0.4264\n",
            "Iteration 4136: Loss = 0.4885, ||Grad|| = 0.1332, ||W|| = 0.4264\n",
            "Iteration 4137: Loss = 0.4885, ||Grad|| = 0.1331, ||W|| = 0.4264\n",
            "Iteration 4138: Loss = 0.4885, ||Grad|| = 0.1330, ||W|| = 0.4264\n",
            "Iteration 4139: Loss = 0.4885, ||Grad|| = 0.1329, ||W|| = 0.4263\n",
            "Iteration 4140: Loss = 0.4885, ||Grad|| = 0.1327, ||W|| = 0.4263\n",
            "Iteration 4141: Loss = 0.4885, ||Grad|| = 0.1326, ||W|| = 0.4263\n",
            "Iteration 4142: Loss = 0.4885, ||Grad|| = 0.1325, ||W|| = 0.4263\n",
            "Iteration 4143: Loss = 0.4885, ||Grad|| = 0.1324, ||W|| = 0.4262\n",
            "Iteration 4144: Loss = 0.4885, ||Grad|| = 0.1323, ||W|| = 0.4262\n",
            "Iteration 4145: Loss = 0.4885, ||Grad|| = 0.1322, ||W|| = 0.4262\n",
            "Iteration 4146: Loss = 0.4884, ||Grad|| = 0.1321, ||W|| = 0.4262\n",
            "Iteration 4147: Loss = 0.4884, ||Grad|| = 0.1320, ||W|| = 0.4261\n",
            "Iteration 4148: Loss = 0.4884, ||Grad|| = 0.1319, ||W|| = 0.4261\n",
            "Iteration 4149: Loss = 0.4884, ||Grad|| = 0.1318, ||W|| = 0.4261\n",
            "Iteration 4150: Loss = 0.4884, ||Grad|| = 0.1317, ||W|| = 0.4261\n",
            "Iteration 4151: Loss = 0.4884, ||Grad|| = 0.1315, ||W|| = 0.4260\n",
            "Iteration 4152: Loss = 0.4884, ||Grad|| = 0.1314, ||W|| = 0.4260\n",
            "Iteration 4153: Loss = 0.4884, ||Grad|| = 0.1313, ||W|| = 0.4260\n",
            "Iteration 4154: Loss = 0.4884, ||Grad|| = 0.1312, ||W|| = 0.4260\n",
            "Iteration 4155: Loss = 0.4884, ||Grad|| = 0.1311, ||W|| = 0.4259\n",
            "Iteration 4156: Loss = 0.4883, ||Grad|| = 0.1310, ||W|| = 0.4259\n",
            "Iteration 4157: Loss = 0.4883, ||Grad|| = 0.1309, ||W|| = 0.4259\n",
            "Iteration 4158: Loss = 0.4883, ||Grad|| = 0.1308, ||W|| = 0.4259\n",
            "Iteration 4159: Loss = 0.4883, ||Grad|| = 0.1307, ||W|| = 0.4258\n",
            "Iteration 4160: Loss = 0.4883, ||Grad|| = 0.1306, ||W|| = 0.4258\n",
            "Iteration 4161: Loss = 0.4883, ||Grad|| = 0.1305, ||W|| = 0.4258\n",
            "Iteration 4162: Loss = 0.4883, ||Grad|| = 0.1304, ||W|| = 0.4258\n",
            "Iteration 4163: Loss = 0.4883, ||Grad|| = 0.1303, ||W|| = 0.4257\n",
            "Iteration 4164: Loss = 0.4883, ||Grad|| = 0.1302, ||W|| = 0.4257\n",
            "Iteration 4165: Loss = 0.4883, ||Grad|| = 0.1300, ||W|| = 0.4257\n",
            "Iteration 4166: Loss = 0.4882, ||Grad|| = 0.1299, ||W|| = 0.4257\n",
            "Iteration 4167: Loss = 0.4882, ||Grad|| = 0.1298, ||W|| = 0.4256\n",
            "Iteration 4168: Loss = 0.4882, ||Grad|| = 0.1297, ||W|| = 0.4256\n",
            "Iteration 4169: Loss = 0.4882, ||Grad|| = 0.1296, ||W|| = 0.4256\n",
            "Iteration 4170: Loss = 0.4882, ||Grad|| = 0.1295, ||W|| = 0.4256\n",
            "Iteration 4171: Loss = 0.4882, ||Grad|| = 0.1294, ||W|| = 0.4255\n",
            "Iteration 4172: Loss = 0.4882, ||Grad|| = 0.1293, ||W|| = 0.4255\n",
            "Iteration 4173: Loss = 0.4882, ||Grad|| = 0.1292, ||W|| = 0.4255\n",
            "Iteration 4174: Loss = 0.4882, ||Grad|| = 0.1291, ||W|| = 0.4255\n",
            "Iteration 4175: Loss = 0.4882, ||Grad|| = 0.1290, ||W|| = 0.4254\n",
            "Iteration 4176: Loss = 0.4881, ||Grad|| = 0.1289, ||W|| = 0.4254\n",
            "Iteration 4177: Loss = 0.4881, ||Grad|| = 0.1288, ||W|| = 0.4254\n",
            "Iteration 4178: Loss = 0.4881, ||Grad|| = 0.1287, ||W|| = 0.4254\n",
            "Iteration 4179: Loss = 0.4881, ||Grad|| = 0.1286, ||W|| = 0.4254\n",
            "Iteration 4180: Loss = 0.4881, ||Grad|| = 0.1285, ||W|| = 0.4253\n",
            "Iteration 4181: Loss = 0.4881, ||Grad|| = 0.1284, ||W|| = 0.4253\n",
            "Iteration 4182: Loss = 0.4881, ||Grad|| = 0.1283, ||W|| = 0.4253\n",
            "Iteration 4183: Loss = 0.4881, ||Grad|| = 0.1281, ||W|| = 0.4253\n",
            "Iteration 4184: Loss = 0.4881, ||Grad|| = 0.1280, ||W|| = 0.4252\n",
            "Iteration 4185: Loss = 0.4881, ||Grad|| = 0.1279, ||W|| = 0.4252\n",
            "Iteration 4186: Loss = 0.4881, ||Grad|| = 0.1278, ||W|| = 0.4252\n",
            "Iteration 4187: Loss = 0.4880, ||Grad|| = 0.1277, ||W|| = 0.4252\n",
            "Iteration 4188: Loss = 0.4880, ||Grad|| = 0.1276, ||W|| = 0.4251\n",
            "Iteration 4189: Loss = 0.4880, ||Grad|| = 0.1275, ||W|| = 0.4251\n",
            "Iteration 4190: Loss = 0.4880, ||Grad|| = 0.1274, ||W|| = 0.4251\n",
            "Iteration 4191: Loss = 0.4880, ||Grad|| = 0.1273, ||W|| = 0.4251\n",
            "Iteration 4192: Loss = 0.4880, ||Grad|| = 0.1272, ||W|| = 0.4250\n",
            "Iteration 4193: Loss = 0.4880, ||Grad|| = 0.1271, ||W|| = 0.4250\n",
            "Iteration 4194: Loss = 0.4880, ||Grad|| = 0.1270, ||W|| = 0.4250\n",
            "Iteration 4195: Loss = 0.4880, ||Grad|| = 0.1269, ||W|| = 0.4250\n",
            "Iteration 4196: Loss = 0.4880, ||Grad|| = 0.1268, ||W|| = 0.4250\n",
            "Iteration 4197: Loss = 0.4880, ||Grad|| = 0.1267, ||W|| = 0.4249\n",
            "Iteration 4198: Loss = 0.4879, ||Grad|| = 0.1266, ||W|| = 0.4249\n",
            "Iteration 4199: Loss = 0.4879, ||Grad|| = 0.1265, ||W|| = 0.4249\n",
            "Iteration 4200: Loss = 0.4879, ||Grad|| = 0.1264, ||W|| = 0.4249\n",
            "Iteration 4201: Loss = 0.4879, ||Grad|| = 0.1263, ||W|| = 0.4248\n",
            "Iteration 4202: Loss = 0.4879, ||Grad|| = 0.1262, ||W|| = 0.4248\n",
            "Iteration 4203: Loss = 0.4879, ||Grad|| = 0.1261, ||W|| = 0.4248\n",
            "Iteration 4204: Loss = 0.4879, ||Grad|| = 0.1260, ||W|| = 0.4248\n",
            "Iteration 4205: Loss = 0.4879, ||Grad|| = 0.1259, ||W|| = 0.4248\n",
            "Iteration 4206: Loss = 0.4879, ||Grad|| = 0.1258, ||W|| = 0.4247\n",
            "Iteration 4207: Loss = 0.4879, ||Grad|| = 0.1257, ||W|| = 0.4247\n",
            "Iteration 4208: Loss = 0.4879, ||Grad|| = 0.1256, ||W|| = 0.4247\n",
            "Iteration 4209: Loss = 0.4878, ||Grad|| = 0.1255, ||W|| = 0.4247\n",
            "Iteration 4210: Loss = 0.4878, ||Grad|| = 0.1254, ||W|| = 0.4246\n",
            "Iteration 4211: Loss = 0.4878, ||Grad|| = 0.1253, ||W|| = 0.4246\n",
            "Iteration 4212: Loss = 0.4878, ||Grad|| = 0.1252, ||W|| = 0.4246\n",
            "Iteration 4213: Loss = 0.4878, ||Grad|| = 0.1251, ||W|| = 0.4246\n",
            "Iteration 4214: Loss = 0.4878, ||Grad|| = 0.1250, ||W|| = 0.4245\n",
            "Iteration 4215: Loss = 0.4878, ||Grad|| = 0.1249, ||W|| = 0.4245\n",
            "Iteration 4216: Loss = 0.4878, ||Grad|| = 0.1248, ||W|| = 0.4245\n",
            "Iteration 4217: Loss = 0.4878, ||Grad|| = 0.1247, ||W|| = 0.4245\n",
            "Iteration 4218: Loss = 0.4878, ||Grad|| = 0.1246, ||W|| = 0.4245\n",
            "Iteration 4219: Loss = 0.4878, ||Grad|| = 0.1245, ||W|| = 0.4244\n",
            "Iteration 4220: Loss = 0.4877, ||Grad|| = 0.1244, ||W|| = 0.4244\n",
            "Iteration 4221: Loss = 0.4877, ||Grad|| = 0.1243, ||W|| = 0.4244\n",
            "Iteration 4222: Loss = 0.4877, ||Grad|| = 0.1242, ||W|| = 0.4244\n",
            "Iteration 4223: Loss = 0.4877, ||Grad|| = 0.1241, ||W|| = 0.4243\n",
            "Iteration 4224: Loss = 0.4877, ||Grad|| = 0.1240, ||W|| = 0.4243\n",
            "Iteration 4225: Loss = 0.4877, ||Grad|| = 0.1239, ||W|| = 0.4243\n",
            "Iteration 4226: Loss = 0.4877, ||Grad|| = 0.1238, ||W|| = 0.4243\n",
            "Iteration 4227: Loss = 0.4877, ||Grad|| = 0.1237, ||W|| = 0.4243\n",
            "Iteration 4228: Loss = 0.4877, ||Grad|| = 0.1236, ||W|| = 0.4242\n",
            "Iteration 4229: Loss = 0.4877, ||Grad|| = 0.1235, ||W|| = 0.4242\n",
            "Iteration 4230: Loss = 0.4877, ||Grad|| = 0.1234, ||W|| = 0.4242\n",
            "Iteration 4231: Loss = 0.4877, ||Grad|| = 0.1233, ||W|| = 0.4242\n",
            "Iteration 4232: Loss = 0.4876, ||Grad|| = 0.1232, ||W|| = 0.4242\n",
            "Iteration 4233: Loss = 0.4876, ||Grad|| = 0.1231, ||W|| = 0.4241\n",
            "Iteration 4234: Loss = 0.4876, ||Grad|| = 0.1230, ||W|| = 0.4241\n",
            "Iteration 4235: Loss = 0.4876, ||Grad|| = 0.1229, ||W|| = 0.4241\n",
            "Iteration 4236: Loss = 0.4876, ||Grad|| = 0.1228, ||W|| = 0.4241\n",
            "Iteration 4237: Loss = 0.4876, ||Grad|| = 0.1227, ||W|| = 0.4240\n",
            "Iteration 4238: Loss = 0.4876, ||Grad|| = 0.1226, ||W|| = 0.4240\n",
            "Iteration 4239: Loss = 0.4876, ||Grad|| = 0.1225, ||W|| = 0.4240\n",
            "Iteration 4240: Loss = 0.4876, ||Grad|| = 0.1224, ||W|| = 0.4240\n",
            "Iteration 4241: Loss = 0.4876, ||Grad|| = 0.1223, ||W|| = 0.4240\n",
            "Iteration 4242: Loss = 0.4876, ||Grad|| = 0.1222, ||W|| = 0.4239\n",
            "Iteration 4243: Loss = 0.4876, ||Grad|| = 0.1221, ||W|| = 0.4239\n",
            "Iteration 4244: Loss = 0.4875, ||Grad|| = 0.1220, ||W|| = 0.4239\n",
            "Iteration 4245: Loss = 0.4875, ||Grad|| = 0.1219, ||W|| = 0.4239\n",
            "Iteration 4246: Loss = 0.4875, ||Grad|| = 0.1218, ||W|| = 0.4239\n",
            "Iteration 4247: Loss = 0.4875, ||Grad|| = 0.1217, ||W|| = 0.4238\n",
            "Iteration 4248: Loss = 0.4875, ||Grad|| = 0.1216, ||W|| = 0.4238\n",
            "Iteration 4249: Loss = 0.4875, ||Grad|| = 0.1215, ||W|| = 0.4238\n",
            "Iteration 4250: Loss = 0.4875, ||Grad|| = 0.1214, ||W|| = 0.4238\n",
            "Iteration 4251: Loss = 0.4875, ||Grad|| = 0.1213, ||W|| = 0.4238\n",
            "Iteration 4252: Loss = 0.4875, ||Grad|| = 0.1212, ||W|| = 0.4237\n",
            "Iteration 4253: Loss = 0.4875, ||Grad|| = 0.1211, ||W|| = 0.4237\n",
            "Iteration 4254: Loss = 0.4875, ||Grad|| = 0.1210, ||W|| = 0.4237\n",
            "Iteration 4255: Loss = 0.4875, ||Grad|| = 0.1209, ||W|| = 0.4237\n",
            "Iteration 4256: Loss = 0.4874, ||Grad|| = 0.1208, ||W|| = 0.4236\n",
            "Iteration 4257: Loss = 0.4874, ||Grad|| = 0.1207, ||W|| = 0.4236\n",
            "Iteration 4258: Loss = 0.4874, ||Grad|| = 0.1206, ||W|| = 0.4236\n",
            "Iteration 4259: Loss = 0.4874, ||Grad|| = 0.1205, ||W|| = 0.4236\n",
            "Iteration 4260: Loss = 0.4874, ||Grad|| = 0.1204, ||W|| = 0.4236\n",
            "Iteration 4261: Loss = 0.4874, ||Grad|| = 0.1203, ||W|| = 0.4235\n",
            "Iteration 4262: Loss = 0.4874, ||Grad|| = 0.1202, ||W|| = 0.4235\n",
            "Iteration 4263: Loss = 0.4874, ||Grad|| = 0.1201, ||W|| = 0.4235\n",
            "Iteration 4264: Loss = 0.4874, ||Grad|| = 0.1200, ||W|| = 0.4235\n",
            "Iteration 4265: Loss = 0.4874, ||Grad|| = 0.1199, ||W|| = 0.4235\n",
            "Iteration 4266: Loss = 0.4874, ||Grad|| = 0.1198, ||W|| = 0.4234\n",
            "Iteration 4267: Loss = 0.4874, ||Grad|| = 0.1197, ||W|| = 0.4234\n",
            "Iteration 4268: Loss = 0.4873, ||Grad|| = 0.1197, ||W|| = 0.4234\n",
            "Iteration 4269: Loss = 0.4873, ||Grad|| = 0.1196, ||W|| = 0.4234\n",
            "Iteration 4270: Loss = 0.4873, ||Grad|| = 0.1195, ||W|| = 0.4234\n",
            "Iteration 4271: Loss = 0.4873, ||Grad|| = 0.1194, ||W|| = 0.4233\n",
            "Iteration 4272: Loss = 0.4873, ||Grad|| = 0.1193, ||W|| = 0.4233\n",
            "Iteration 4273: Loss = 0.4873, ||Grad|| = 0.1192, ||W|| = 0.4233\n",
            "Iteration 4274: Loss = 0.4873, ||Grad|| = 0.1191, ||W|| = 0.4233\n",
            "Iteration 4275: Loss = 0.4873, ||Grad|| = 0.1190, ||W|| = 0.4233\n",
            "Iteration 4276: Loss = 0.4873, ||Grad|| = 0.1189, ||W|| = 0.4232\n",
            "Iteration 4277: Loss = 0.4873, ||Grad|| = 0.1188, ||W|| = 0.4232\n",
            "Iteration 4278: Loss = 0.4873, ||Grad|| = 0.1187, ||W|| = 0.4232\n",
            "Iteration 4279: Loss = 0.4873, ||Grad|| = 0.1186, ||W|| = 0.4232\n",
            "Iteration 4280: Loss = 0.4873, ||Grad|| = 0.1185, ||W|| = 0.4232\n",
            "Iteration 4281: Loss = 0.4872, ||Grad|| = 0.1184, ||W|| = 0.4231\n",
            "Iteration 4282: Loss = 0.4872, ||Grad|| = 0.1183, ||W|| = 0.4231\n",
            "Iteration 4283: Loss = 0.4872, ||Grad|| = 0.1182, ||W|| = 0.4231\n",
            "Iteration 4284: Loss = 0.4872, ||Grad|| = 0.1181, ||W|| = 0.4231\n",
            "Iteration 4285: Loss = 0.4872, ||Grad|| = 0.1180, ||W|| = 0.4231\n",
            "Iteration 4286: Loss = 0.4872, ||Grad|| = 0.1179, ||W|| = 0.4230\n",
            "Iteration 4287: Loss = 0.4872, ||Grad|| = 0.1179, ||W|| = 0.4230\n",
            "Iteration 4288: Loss = 0.4872, ||Grad|| = 0.1178, ||W|| = 0.4230\n",
            "Iteration 4289: Loss = 0.4872, ||Grad|| = 0.1177, ||W|| = 0.4230\n",
            "Iteration 4290: Loss = 0.4872, ||Grad|| = 0.1176, ||W|| = 0.4230\n",
            "Iteration 4291: Loss = 0.4872, ||Grad|| = 0.1175, ||W|| = 0.4230\n",
            "Iteration 4292: Loss = 0.4872, ||Grad|| = 0.1174, ||W|| = 0.4229\n",
            "Iteration 4293: Loss = 0.4872, ||Grad|| = 0.1173, ||W|| = 0.4229\n",
            "Iteration 4294: Loss = 0.4871, ||Grad|| = 0.1172, ||W|| = 0.4229\n",
            "Iteration 4295: Loss = 0.4871, ||Grad|| = 0.1171, ||W|| = 0.4229\n",
            "Iteration 4296: Loss = 0.4871, ||Grad|| = 0.1170, ||W|| = 0.4229\n",
            "Iteration 4297: Loss = 0.4871, ||Grad|| = 0.1169, ||W|| = 0.4228\n",
            "Iteration 4298: Loss = 0.4871, ||Grad|| = 0.1168, ||W|| = 0.4228\n",
            "Iteration 4299: Loss = 0.4871, ||Grad|| = 0.1167, ||W|| = 0.4228\n",
            "Iteration 4300: Loss = 0.4871, ||Grad|| = 0.1166, ||W|| = 0.4228\n",
            "Iteration 4301: Loss = 0.4871, ||Grad|| = 0.1166, ||W|| = 0.4228\n",
            "Iteration 4302: Loss = 0.4871, ||Grad|| = 0.1165, ||W|| = 0.4227\n",
            "Iteration 4303: Loss = 0.4871, ||Grad|| = 0.1164, ||W|| = 0.4227\n",
            "Iteration 4304: Loss = 0.4871, ||Grad|| = 0.1163, ||W|| = 0.4227\n",
            "Iteration 4305: Loss = 0.4871, ||Grad|| = 0.1162, ||W|| = 0.4227\n",
            "Iteration 4306: Loss = 0.4871, ||Grad|| = 0.1161, ||W|| = 0.4227\n",
            "Iteration 4307: Loss = 0.4870, ||Grad|| = 0.1160, ||W|| = 0.4226\n",
            "Iteration 4308: Loss = 0.4870, ||Grad|| = 0.1159, ||W|| = 0.4226\n",
            "Iteration 4309: Loss = 0.4870, ||Grad|| = 0.1158, ||W|| = 0.4226\n",
            "Iteration 4310: Loss = 0.4870, ||Grad|| = 0.1157, ||W|| = 0.4226\n",
            "Iteration 4311: Loss = 0.4870, ||Grad|| = 0.1156, ||W|| = 0.4226\n",
            "Iteration 4312: Loss = 0.4870, ||Grad|| = 0.1155, ||W|| = 0.4226\n",
            "Iteration 4313: Loss = 0.4870, ||Grad|| = 0.1155, ||W|| = 0.4225\n",
            "Iteration 4314: Loss = 0.4870, ||Grad|| = 0.1154, ||W|| = 0.4225\n",
            "Iteration 4315: Loss = 0.4870, ||Grad|| = 0.1153, ||W|| = 0.4225\n",
            "Iteration 4316: Loss = 0.4870, ||Grad|| = 0.1152, ||W|| = 0.4225\n",
            "Iteration 4317: Loss = 0.4870, ||Grad|| = 0.1151, ||W|| = 0.4225\n",
            "Iteration 4318: Loss = 0.4870, ||Grad|| = 0.1150, ||W|| = 0.4224\n",
            "Iteration 4319: Loss = 0.4870, ||Grad|| = 0.1149, ||W|| = 0.4224\n",
            "Iteration 4320: Loss = 0.4870, ||Grad|| = 0.1148, ||W|| = 0.4224\n",
            "Iteration 4321: Loss = 0.4869, ||Grad|| = 0.1147, ||W|| = 0.4224\n",
            "Iteration 4322: Loss = 0.4869, ||Grad|| = 0.1146, ||W|| = 0.4224\n",
            "Iteration 4323: Loss = 0.4869, ||Grad|| = 0.1145, ||W|| = 0.4224\n",
            "Iteration 4324: Loss = 0.4869, ||Grad|| = 0.1145, ||W|| = 0.4223\n",
            "Iteration 4325: Loss = 0.4869, ||Grad|| = 0.1144, ||W|| = 0.4223\n",
            "Iteration 4326: Loss = 0.4869, ||Grad|| = 0.1143, ||W|| = 0.4223\n",
            "Iteration 4327: Loss = 0.4869, ||Grad|| = 0.1142, ||W|| = 0.4223\n",
            "Iteration 4328: Loss = 0.4869, ||Grad|| = 0.1141, ||W|| = 0.4223\n",
            "Iteration 4329: Loss = 0.4869, ||Grad|| = 0.1140, ||W|| = 0.4222\n",
            "Iteration 4330: Loss = 0.4869, ||Grad|| = 0.1139, ||W|| = 0.4222\n",
            "Iteration 4331: Loss = 0.4869, ||Grad|| = 0.1138, ||W|| = 0.4222\n",
            "Iteration 4332: Loss = 0.4869, ||Grad|| = 0.1137, ||W|| = 0.4222\n",
            "Iteration 4333: Loss = 0.4869, ||Grad|| = 0.1136, ||W|| = 0.4222\n",
            "Iteration 4334: Loss = 0.4869, ||Grad|| = 0.1136, ||W|| = 0.4222\n",
            "Iteration 4335: Loss = 0.4868, ||Grad|| = 0.1135, ||W|| = 0.4221\n",
            "Iteration 4336: Loss = 0.4868, ||Grad|| = 0.1134, ||W|| = 0.4221\n",
            "Iteration 4337: Loss = 0.4868, ||Grad|| = 0.1133, ||W|| = 0.4221\n",
            "Iteration 4338: Loss = 0.4868, ||Grad|| = 0.1132, ||W|| = 0.4221\n",
            "Iteration 4339: Loss = 0.4868, ||Grad|| = 0.1131, ||W|| = 0.4221\n",
            "Iteration 4340: Loss = 0.4868, ||Grad|| = 0.1130, ||W|| = 0.4220\n",
            "Iteration 4341: Loss = 0.4868, ||Grad|| = 0.1129, ||W|| = 0.4220\n",
            "Iteration 4342: Loss = 0.4868, ||Grad|| = 0.1128, ||W|| = 0.4220\n",
            "Iteration 4343: Loss = 0.4868, ||Grad|| = 0.1128, ||W|| = 0.4220\n",
            "Iteration 4344: Loss = 0.4868, ||Grad|| = 0.1127, ||W|| = 0.4220\n",
            "Iteration 4345: Loss = 0.4868, ||Grad|| = 0.1126, ||W|| = 0.4220\n",
            "Iteration 4346: Loss = 0.4868, ||Grad|| = 0.1125, ||W|| = 0.4219\n",
            "Iteration 4347: Loss = 0.4868, ||Grad|| = 0.1124, ||W|| = 0.4219\n",
            "Iteration 4348: Loss = 0.4868, ||Grad|| = 0.1123, ||W|| = 0.4219\n",
            "Iteration 4349: Loss = 0.4867, ||Grad|| = 0.1122, ||W|| = 0.4219\n",
            "Iteration 4350: Loss = 0.4867, ||Grad|| = 0.1121, ||W|| = 0.4219\n",
            "Iteration 4351: Loss = 0.4867, ||Grad|| = 0.1121, ||W|| = 0.4219\n",
            "Iteration 4352: Loss = 0.4867, ||Grad|| = 0.1120, ||W|| = 0.4218\n",
            "Iteration 4353: Loss = 0.4867, ||Grad|| = 0.1119, ||W|| = 0.4218\n",
            "Iteration 4354: Loss = 0.4867, ||Grad|| = 0.1118, ||W|| = 0.4218\n",
            "Iteration 4355: Loss = 0.4867, ||Grad|| = 0.1117, ||W|| = 0.4218\n",
            "Iteration 4356: Loss = 0.4867, ||Grad|| = 0.1116, ||W|| = 0.4218\n",
            "Iteration 4357: Loss = 0.4867, ||Grad|| = 0.1115, ||W|| = 0.4218\n",
            "Iteration 4358: Loss = 0.4867, ||Grad|| = 0.1114, ||W|| = 0.4217\n",
            "Iteration 4359: Loss = 0.4867, ||Grad|| = 0.1114, ||W|| = 0.4217\n",
            "Iteration 4360: Loss = 0.4867, ||Grad|| = 0.1113, ||W|| = 0.4217\n",
            "Iteration 4361: Loss = 0.4867, ||Grad|| = 0.1112, ||W|| = 0.4217\n",
            "Iteration 4362: Loss = 0.4867, ||Grad|| = 0.1111, ||W|| = 0.4217\n",
            "Iteration 4363: Loss = 0.4867, ||Grad|| = 0.1110, ||W|| = 0.4216\n",
            "Iteration 4364: Loss = 0.4866, ||Grad|| = 0.1109, ||W|| = 0.4216\n",
            "Iteration 4365: Loss = 0.4866, ||Grad|| = 0.1108, ||W|| = 0.4216\n",
            "Iteration 4366: Loss = 0.4866, ||Grad|| = 0.1107, ||W|| = 0.4216\n",
            "Iteration 4367: Loss = 0.4866, ||Grad|| = 0.1107, ||W|| = 0.4216\n",
            "Iteration 4368: Loss = 0.4866, ||Grad|| = 0.1106, ||W|| = 0.4216\n",
            "Iteration 4369: Loss = 0.4866, ||Grad|| = 0.1105, ||W|| = 0.4215\n",
            "Iteration 4370: Loss = 0.4866, ||Grad|| = 0.1104, ||W|| = 0.4215\n",
            "Iteration 4371: Loss = 0.4866, ||Grad|| = 0.1103, ||W|| = 0.4215\n",
            "Iteration 4372: Loss = 0.4866, ||Grad|| = 0.1102, ||W|| = 0.4215\n",
            "Iteration 4373: Loss = 0.4866, ||Grad|| = 0.1101, ||W|| = 0.4215\n",
            "Iteration 4374: Loss = 0.4866, ||Grad|| = 0.1101, ||W|| = 0.4215\n",
            "Iteration 4375: Loss = 0.4866, ||Grad|| = 0.1100, ||W|| = 0.4214\n",
            "Iteration 4376: Loss = 0.4866, ||Grad|| = 0.1099, ||W|| = 0.4214\n",
            "Iteration 4377: Loss = 0.4866, ||Grad|| = 0.1098, ||W|| = 0.4214\n",
            "Iteration 4378: Loss = 0.4866, ||Grad|| = 0.1097, ||W|| = 0.4214\n",
            "Iteration 4379: Loss = 0.4865, ||Grad|| = 0.1096, ||W|| = 0.4214\n",
            "Iteration 4380: Loss = 0.4865, ||Grad|| = 0.1095, ||W|| = 0.4214\n",
            "Iteration 4381: Loss = 0.4865, ||Grad|| = 0.1095, ||W|| = 0.4213\n",
            "Iteration 4382: Loss = 0.4865, ||Grad|| = 0.1094, ||W|| = 0.4213\n",
            "Iteration 4383: Loss = 0.4865, ||Grad|| = 0.1093, ||W|| = 0.4213\n",
            "Iteration 4384: Loss = 0.4865, ||Grad|| = 0.1092, ||W|| = 0.4213\n",
            "Iteration 4385: Loss = 0.4865, ||Grad|| = 0.1091, ||W|| = 0.4213\n",
            "Iteration 4386: Loss = 0.4865, ||Grad|| = 0.1090, ||W|| = 0.4213\n",
            "Iteration 4387: Loss = 0.4865, ||Grad|| = 0.1090, ||W|| = 0.4213\n",
            "Iteration 4388: Loss = 0.4865, ||Grad|| = 0.1089, ||W|| = 0.4212\n",
            "Iteration 4389: Loss = 0.4865, ||Grad|| = 0.1088, ||W|| = 0.4212\n",
            "Iteration 4390: Loss = 0.4865, ||Grad|| = 0.1087, ||W|| = 0.4212\n",
            "Iteration 4391: Loss = 0.4865, ||Grad|| = 0.1086, ||W|| = 0.4212\n",
            "Iteration 4392: Loss = 0.4865, ||Grad|| = 0.1085, ||W|| = 0.4212\n",
            "Iteration 4393: Loss = 0.4865, ||Grad|| = 0.1085, ||W|| = 0.4212\n",
            "Iteration 4394: Loss = 0.4865, ||Grad|| = 0.1084, ||W|| = 0.4211\n",
            "Iteration 4395: Loss = 0.4864, ||Grad|| = 0.1083, ||W|| = 0.4211\n",
            "Iteration 4396: Loss = 0.4864, ||Grad|| = 0.1082, ||W|| = 0.4211\n",
            "Iteration 4397: Loss = 0.4864, ||Grad|| = 0.1081, ||W|| = 0.4211\n",
            "Iteration 4398: Loss = 0.4864, ||Grad|| = 0.1080, ||W|| = 0.4211\n",
            "Iteration 4399: Loss = 0.4864, ||Grad|| = 0.1079, ||W|| = 0.4211\n",
            "Iteration 4400: Loss = 0.4864, ||Grad|| = 0.1079, ||W|| = 0.4210\n",
            "Iteration 4401: Loss = 0.4864, ||Grad|| = 0.1078, ||W|| = 0.4210\n",
            "Iteration 4402: Loss = 0.4864, ||Grad|| = 0.1077, ||W|| = 0.4210\n",
            "Iteration 4403: Loss = 0.4864, ||Grad|| = 0.1076, ||W|| = 0.4210\n",
            "Iteration 4404: Loss = 0.4864, ||Grad|| = 0.1075, ||W|| = 0.4210\n",
            "Iteration 4405: Loss = 0.4864, ||Grad|| = 0.1074, ||W|| = 0.4210\n",
            "Iteration 4406: Loss = 0.4864, ||Grad|| = 0.1074, ||W|| = 0.4209\n",
            "Iteration 4407: Loss = 0.4864, ||Grad|| = 0.1073, ||W|| = 0.4209\n",
            "Iteration 4408: Loss = 0.4864, ||Grad|| = 0.1072, ||W|| = 0.4209\n",
            "Iteration 4409: Loss = 0.4864, ||Grad|| = 0.1071, ||W|| = 0.4209\n",
            "Iteration 4410: Loss = 0.4864, ||Grad|| = 0.1070, ||W|| = 0.4209\n",
            "Iteration 4411: Loss = 0.4863, ||Grad|| = 0.1070, ||W|| = 0.4209\n",
            "Iteration 4412: Loss = 0.4863, ||Grad|| = 0.1069, ||W|| = 0.4209\n",
            "Iteration 4413: Loss = 0.4863, ||Grad|| = 0.1068, ||W|| = 0.4208\n",
            "Iteration 4414: Loss = 0.4863, ||Grad|| = 0.1067, ||W|| = 0.4208\n",
            "Iteration 4415: Loss = 0.4863, ||Grad|| = 0.1066, ||W|| = 0.4208\n",
            "Iteration 4416: Loss = 0.4863, ||Grad|| = 0.1065, ||W|| = 0.4208\n",
            "Iteration 4417: Loss = 0.4863, ||Grad|| = 0.1065, ||W|| = 0.4208\n",
            "Iteration 4418: Loss = 0.4863, ||Grad|| = 0.1064, ||W|| = 0.4208\n",
            "Iteration 4419: Loss = 0.4863, ||Grad|| = 0.1063, ||W|| = 0.4207\n",
            "Iteration 4420: Loss = 0.4863, ||Grad|| = 0.1062, ||W|| = 0.4207\n",
            "Iteration 4421: Loss = 0.4863, ||Grad|| = 0.1061, ||W|| = 0.4207\n",
            "Iteration 4422: Loss = 0.4863, ||Grad|| = 0.1061, ||W|| = 0.4207\n",
            "Iteration 4423: Loss = 0.4863, ||Grad|| = 0.1060, ||W|| = 0.4207\n",
            "Iteration 4424: Loss = 0.4863, ||Grad|| = 0.1059, ||W|| = 0.4207\n",
            "Iteration 4425: Loss = 0.4863, ||Grad|| = 0.1058, ||W|| = 0.4207\n",
            "Iteration 4426: Loss = 0.4863, ||Grad|| = 0.1057, ||W|| = 0.4206\n",
            "Iteration 4427: Loss = 0.4862, ||Grad|| = 0.1056, ||W|| = 0.4206\n",
            "Iteration 4428: Loss = 0.4862, ||Grad|| = 0.1056, ||W|| = 0.4206\n",
            "Iteration 4429: Loss = 0.4862, ||Grad|| = 0.1055, ||W|| = 0.4206\n",
            "Iteration 4430: Loss = 0.4862, ||Grad|| = 0.1054, ||W|| = 0.4206\n",
            "Iteration 4431: Loss = 0.4862, ||Grad|| = 0.1053, ||W|| = 0.4206\n",
            "Iteration 4432: Loss = 0.4862, ||Grad|| = 0.1052, ||W|| = 0.4206\n",
            "Iteration 4433: Loss = 0.4862, ||Grad|| = 0.1052, ||W|| = 0.4205\n",
            "Iteration 4434: Loss = 0.4862, ||Grad|| = 0.1051, ||W|| = 0.4205\n",
            "Iteration 4435: Loss = 0.4862, ||Grad|| = 0.1050, ||W|| = 0.4205\n",
            "Iteration 4436: Loss = 0.4862, ||Grad|| = 0.1049, ||W|| = 0.4205\n",
            "Iteration 4437: Loss = 0.4862, ||Grad|| = 0.1048, ||W|| = 0.4205\n",
            "Iteration 4438: Loss = 0.4862, ||Grad|| = 0.1048, ||W|| = 0.4205\n",
            "Iteration 4439: Loss = 0.4862, ||Grad|| = 0.1047, ||W|| = 0.4204\n",
            "Iteration 4440: Loss = 0.4862, ||Grad|| = 0.1046, ||W|| = 0.4204\n",
            "Iteration 4441: Loss = 0.4862, ||Grad|| = 0.1045, ||W|| = 0.4204\n",
            "Iteration 4442: Loss = 0.4862, ||Grad|| = 0.1044, ||W|| = 0.4204\n",
            "Iteration 4443: Loss = 0.4862, ||Grad|| = 0.1044, ||W|| = 0.4204\n",
            "Iteration 4444: Loss = 0.4861, ||Grad|| = 0.1043, ||W|| = 0.4204\n",
            "Iteration 4445: Loss = 0.4861, ||Grad|| = 0.1042, ||W|| = 0.4204\n",
            "Iteration 4446: Loss = 0.4861, ||Grad|| = 0.1041, ||W|| = 0.4203\n",
            "Iteration 4447: Loss = 0.4861, ||Grad|| = 0.1040, ||W|| = 0.4203\n",
            "Iteration 4448: Loss = 0.4861, ||Grad|| = 0.1040, ||W|| = 0.4203\n",
            "Iteration 4449: Loss = 0.4861, ||Grad|| = 0.1039, ||W|| = 0.4203\n",
            "Iteration 4450: Loss = 0.4861, ||Grad|| = 0.1038, ||W|| = 0.4203\n",
            "Iteration 4451: Loss = 0.4861, ||Grad|| = 0.1037, ||W|| = 0.4203\n",
            "Iteration 4452: Loss = 0.4861, ||Grad|| = 0.1036, ||W|| = 0.4203\n",
            "Iteration 4453: Loss = 0.4861, ||Grad|| = 0.1036, ||W|| = 0.4202\n",
            "Iteration 4454: Loss = 0.4861, ||Grad|| = 0.1035, ||W|| = 0.4202\n",
            "Iteration 4455: Loss = 0.4861, ||Grad|| = 0.1034, ||W|| = 0.4202\n",
            "Iteration 4456: Loss = 0.4861, ||Grad|| = 0.1033, ||W|| = 0.4202\n",
            "Iteration 4457: Loss = 0.4861, ||Grad|| = 0.1033, ||W|| = 0.4202\n",
            "Iteration 4458: Loss = 0.4861, ||Grad|| = 0.1032, ||W|| = 0.4202\n",
            "Iteration 4459: Loss = 0.4861, ||Grad|| = 0.1031, ||W|| = 0.4202\n",
            "Iteration 4460: Loss = 0.4861, ||Grad|| = 0.1030, ||W|| = 0.4201\n",
            "Iteration 4461: Loss = 0.4861, ||Grad|| = 0.1029, ||W|| = 0.4201\n",
            "Iteration 4462: Loss = 0.4860, ||Grad|| = 0.1029, ||W|| = 0.4201\n",
            "Iteration 4463: Loss = 0.4860, ||Grad|| = 0.1028, ||W|| = 0.4201\n",
            "Iteration 4464: Loss = 0.4860, ||Grad|| = 0.1027, ||W|| = 0.4201\n",
            "Iteration 4465: Loss = 0.4860, ||Grad|| = 0.1026, ||W|| = 0.4201\n",
            "Iteration 4466: Loss = 0.4860, ||Grad|| = 0.1025, ||W|| = 0.4201\n",
            "Iteration 4467: Loss = 0.4860, ||Grad|| = 0.1025, ||W|| = 0.4200\n",
            "Iteration 4468: Loss = 0.4860, ||Grad|| = 0.1024, ||W|| = 0.4200\n",
            "Iteration 4469: Loss = 0.4860, ||Grad|| = 0.1023, ||W|| = 0.4200\n",
            "Iteration 4470: Loss = 0.4860, ||Grad|| = 0.1022, ||W|| = 0.4200\n",
            "Iteration 4471: Loss = 0.4860, ||Grad|| = 0.1022, ||W|| = 0.4200\n",
            "Iteration 4472: Loss = 0.4860, ||Grad|| = 0.1021, ||W|| = 0.4200\n",
            "Iteration 4473: Loss = 0.4860, ||Grad|| = 0.1020, ||W|| = 0.4200\n",
            "Iteration 4474: Loss = 0.4860, ||Grad|| = 0.1019, ||W|| = 0.4199\n",
            "Iteration 4475: Loss = 0.4860, ||Grad|| = 0.1019, ||W|| = 0.4199\n",
            "Iteration 4476: Loss = 0.4860, ||Grad|| = 0.1018, ||W|| = 0.4199\n",
            "Iteration 4477: Loss = 0.4860, ||Grad|| = 0.1017, ||W|| = 0.4199\n",
            "Iteration 4478: Loss = 0.4860, ||Grad|| = 0.1016, ||W|| = 0.4199\n",
            "Iteration 4479: Loss = 0.4860, ||Grad|| = 0.1015, ||W|| = 0.4199\n",
            "Iteration 4480: Loss = 0.4859, ||Grad|| = 0.1015, ||W|| = 0.4199\n",
            "Iteration 4481: Loss = 0.4859, ||Grad|| = 0.1014, ||W|| = 0.4198\n",
            "Iteration 4482: Loss = 0.4859, ||Grad|| = 0.1013, ||W|| = 0.4198\n",
            "Iteration 4483: Loss = 0.4859, ||Grad|| = 0.1012, ||W|| = 0.4198\n",
            "Iteration 4484: Loss = 0.4859, ||Grad|| = 0.1012, ||W|| = 0.4198\n",
            "Iteration 4485: Loss = 0.4859, ||Grad|| = 0.1011, ||W|| = 0.4198\n",
            "Iteration 4486: Loss = 0.4859, ||Grad|| = 0.1010, ||W|| = 0.4198\n",
            "Iteration 4487: Loss = 0.4859, ||Grad|| = 0.1009, ||W|| = 0.4198\n",
            "Iteration 4488: Loss = 0.4859, ||Grad|| = 0.1009, ||W|| = 0.4198\n",
            "Iteration 4489: Loss = 0.4859, ||Grad|| = 0.1008, ||W|| = 0.4197\n",
            "Iteration 4490: Loss = 0.4859, ||Grad|| = 0.1007, ||W|| = 0.4197\n",
            "Iteration 4491: Loss = 0.4859, ||Grad|| = 0.1006, ||W|| = 0.4197\n",
            "Iteration 4492: Loss = 0.4859, ||Grad|| = 0.1006, ||W|| = 0.4197\n",
            "Iteration 4493: Loss = 0.4859, ||Grad|| = 0.1005, ||W|| = 0.4197\n",
            "Iteration 4494: Loss = 0.4859, ||Grad|| = 0.1004, ||W|| = 0.4197\n",
            "Iteration 4495: Loss = 0.4859, ||Grad|| = 0.1003, ||W|| = 0.4197\n",
            "Iteration 4496: Loss = 0.4859, ||Grad|| = 0.1002, ||W|| = 0.4196\n",
            "Iteration 4497: Loss = 0.4859, ||Grad|| = 0.1002, ||W|| = 0.4196\n",
            "Iteration 4498: Loss = 0.4858, ||Grad|| = 0.1001, ||W|| = 0.4196\n",
            "Iteration 4499: Loss = 0.4858, ||Grad|| = 0.1000, ||W|| = 0.4196\n",
            "Iteration 4500: Loss = 0.4858, ||Grad|| = 0.0999, ||W|| = 0.4196\n"
          ]
        }
      ],
      "source": [
        "learning_rate = 0.001\n",
        "lambda_ = 1.0\n",
        "\n",
        "model = fit(xtrain_normal, ytrain, learning_rate, lambda_, 10000, verbose=1) #keep the verbose on here for your submissions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-AiarpzOhIvE",
        "outputId": "960e22bc-f440-4977-fab0-36959ab16c01"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train accuracy:  0.8476923076923077\n"
          ]
        }
      ],
      "source": [
        "print(\"Train accuracy: \", accuracy(xtrain_normal, ytrain, model))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nrU6Tr7mhIvE",
        "outputId": "6d0e64d5-70d3-41f2-8296-5fcfad9e46b5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-64-8e0f850aa7f3>:4: RuntimeWarning: overflow encountered in exp\n",
            "  return 1.0 / (1+np.exp(-v))\n",
            "<ipython-input-68-4ab4a9d7ede4>:12: RuntimeWarning: overflow encountered in multiply\n",
            "  grad_w = (np.dot(x.T, (y_prob - y_true)) / m) + (lambda_ * w)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1 5 0.6093906093906094\n",
            "1 4 0.6093906093906094\n",
            "1 3 0.6093906093906094\n",
            "1 2 0.1918081918081918\n",
            "1 1 0.48951048951048953\n",
            "1 0.3 0.9110889110889111\n",
            "1 0.2 0.9170829170829171\n",
            "1 0.15 0.9180819180819181\n",
            "1 0.05 0.916083916083916\n",
            "1 0.025 0.9270729270729271\n",
            "1 0.02 0.916083916083916\n",
            "0.1 5 0.8481518481518482\n",
            "0.1 4 0.6813186813186813\n",
            "0.1 3 0.8841158841158842\n",
            "0.1 2 0.8891108891108891\n",
            "0.1 1 0.8681318681318682\n",
            "0.1 0.3 0.9050949050949051\n",
            "0.1 0.2 0.9100899100899101\n",
            "0.1 0.15 0.919080919080919\n",
            "0.1 0.05 0.919080919080919\n",
            "0.1 0.025 0.9050949050949051\n",
            "0.1 0.02 0.9150849150849151\n",
            "0.01 5 0.6553446553446554\n",
            "0.01 4 0.8781218781218781\n",
            "0.01 3 0.7162837162837162\n",
            "0.01 2 0.8701298701298701\n",
            "0.01 1 0.8951048951048951\n",
            "0.01 0.3 0.8931068931068931\n",
            "0.01 0.2 0.9150849150849151\n",
            "0.01 0.15 0.9170829170829171\n",
            "0.01 0.05 0.9150849150849151\n",
            "0.01 0.025 0.9090909090909091\n",
            "0.01 0.02 0.913086913086913\n",
            "0.001 5 0.7182817182817183\n",
            "0.001 4 0.8771228771228772\n",
            "0.001 3 0.7072927072927073\n",
            "0.001 2 0.8061938061938062\n",
            "0.001 1 0.8921078921078921\n",
            "0.001 0.3 0.8971028971028971\n",
            "0.001 0.2 0.9150849150849151\n",
            "0.001 0.15 0.9200799200799201\n",
            "0.001 0.05 0.8891108891108891\n",
            "0.001 0.025 0.8841158841158842\n",
            "0.001 0.02 0.8551448551448552\n",
            "0.0001 5 0.6733266733266733\n",
            "0.0001 4 0.8521478521478522\n",
            "0.0001 3 0.8741258741258742\n",
            "0.0001 2 0.8511488511488512\n",
            "0.0001 1 0.6833166833166833\n",
            "0.0001 0.3 0.7162837162837162\n",
            "0.0001 0.2 0.5854145854145855\n",
            "0.0001 0.15 0.7522477522477522\n",
            "0.0001 0.05 0.7742257742257742\n",
            "0.0001 0.025 0.5024975024975025\n",
            "0.0001 0.02 0.6973026973026973\n"
          ]
        }
      ],
      "source": [
        "#grid search for finding the best hyperparams and model\n",
        "\n",
        "best_model = None\n",
        "best_val = -1\n",
        "for lr in [1,0.1,0.01, 0.001, 0.0001]:\n",
        "    for la in [5,4,3, 2,1 ,0.3 ,0.2 , 0.15 , 0.05 , 0.025 , 0.02]:\n",
        "        model = fit(xtrain_normal, ytrain, lr, la, 15000, verbose=0)\n",
        "        val_acc = accuracy(xval_normal, yval, model)\n",
        "        print(lr, la, val_acc)\n",
        "        if val_acc > best_val:\n",
        "            best_val = val_acc\n",
        "            best_model = model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n5zNZCNVhIvE",
        "outputId": "3a562711-2808-4446-a82d-8683388f7961"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test accuracy:  0.941\n"
          ]
        }
      ],
      "source": [
        "print(\"Test accuracy: \", accuracy(xtest_normal, ytest, best_model))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}